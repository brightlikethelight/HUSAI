# Training Dynamics Analysis: Critical New Finding

**Date:** December 5, 2025
**Status:** ✅ VERIFIED

---

## Executive Summary

Training dynamics analysis reveals that **SAE features CONVERGE during training**, contrary to the assumption that they remain at random baseline.

| Metric | Value |
|--------|-------|
| Initial PWMCC (epoch 0) | 0.300 (random baseline) |
| Final PWMCC (epoch 50) | 0.358 (~20% above random) |
| Change | +0.058 |
| Trend | Monotonically increasing |

---

## Key Finding

**Features START at random baseline and CONVERGE during training!**

This means:
1. SAE training DOES improve feature stability
2. The improvement is ~20% above random baseline
3. PWMCC increases monotonically throughout training
4. No divergence or instability during training

---

## Detailed Results

### Seed Pair Analysis

| Seed Pair | Initial PWMCC | Final PWMCC | Change |
|-----------|---------------|-------------|--------|
| 42 vs 123 | 0.3011 | 0.3613 | +0.0602 |
| 42 vs 456 | 0.3007 | 0.3576 | +0.0569 |
| 42 vs 789 | 0.2986 | 0.3560 | +0.0574 |
| **Average** | **0.3001** | **0.3583** | **+0.0582** |

### PWMCC Evolution Over Training

```
Epoch  0: 0.300 (random baseline)
Epoch  5: 0.305
Epoch 10: 0.309
Epoch 15: 0.314
Epoch 20: 0.320
Epoch 25: 0.326
Epoch 30: 0.333
Epoch 35: 0.340
Epoch 40: 0.346
Epoch 45: 0.352
Epoch 50: 0.358
```

---

## Reconciliation with Previous Findings

### Previous Finding
- Trained PWMCC = 0.309 ≈ Random PWMCC = 0.300
- Conclusion: "Training provides zero stability above chance"

### New Finding
- Initial PWMCC = 0.300 (random)
- Final PWMCC (50 epochs) = 0.358 (20% above random)
- Conclusion: "Training DOES improve stability, but not to high levels"

### Explanation

The original SAEs were trained for **20 epochs** (per config), not 50 epochs.

At epoch 20, PWMCC ≈ 0.32, which is only ~7% above random - consistent with the "practically zero" interpretation.

With longer training (50 epochs), PWMCC reaches 0.36 (~20% above random).

---

## Revised Interpretation

### Old Narrative
> "SAE features match random baseline - training provides zero stability above chance."

### New Narrative
> "SAE features start at random baseline (0.30) and converge during training. After 50 epochs, PWMCC reaches 0.36 (~20% above random). Training DOES improve stability, but the improvement is modest and far below the 0.70 threshold for high stability."

---

## Implications

1. **Training duration matters** - Longer training = higher stability
2. **Stability is learnable** - SAEs can learn some consistent structure
3. **The gap is still large** - 0.36 vs 0.70 target = 0.34 gap remaining
4. **Underconstrained hypothesis still holds** - Many solutions exist, but training biases toward more similar ones

---

## Recommendations

1. **Update paper** with training dynamics finding
2. **Report PWMCC at specific epochs** for reproducibility
3. **Consider longer training** for stability-focused applications
4. **Investigate** why PWMCC plateaus around 0.36

---

## Files Generated

- `results/training_dynamics/training_dynamics_results.json` - Raw data
- `results/training_dynamics/training_dynamics.png` - Visualization
- `TRAINING_DYNAMICS_FINDING.md` - This document

---

*Generated by training dynamics analysis (Phase 4.3)*
