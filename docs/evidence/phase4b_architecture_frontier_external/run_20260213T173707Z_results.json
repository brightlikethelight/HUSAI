{
  "timestamp_utc": "2026-02-13T17:49:08+00:00",
  "command": "python /workspace/HUSAI/scripts/experiments/run_architecture_frontier_external.py --activation-cache-dir /tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped --activation-glob *_blocks.0.hook_resid_pre.pt --architectures topk,relu,batchtopk,jumprelu --seeds 42 --d-sae 1024 --k 32 --epochs 6 --batch-size 4096 --learning-rate 0.001 --device cuda --run-saebench --run-cebench --cebench-repo /workspace/CE-Bench --cebench-max-rows 200 --saebench-model-cache-path /tmp/sae_bench_model_cache --saebench-dataset-limit 8 --output-dir /workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external",
  "config": {
    "activation_cache_dir": "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped",
    "activation_glob": "*_blocks.0.hook_resid_pre.pt",
    "max_files": 80,
    "max_rows_per_file": 2048,
    "max_total_rows": 150000,
    "architectures": [
      "topk",
      "relu",
      "batchtopk",
      "jumprelu"
    ],
    "seeds": [
      42
    ],
    "d_sae": 1024,
    "k": 32,
    "epochs": 6,
    "batch_size": 4096,
    "learning_rate": 0.001,
    "device": "cuda",
    "dtype": "float32",
    "model_name": "pythia-70m-deduped",
    "hook_layer": 0,
    "hook_name": "blocks.0.hook_resid_pre",
    "run_saebench": true,
    "run_cebench": true,
    "cebench_repo": "/workspace/CE-Bench",
    "cebench_max_rows": 200,
    "saebench_datasets": [],
    "saebench_dataset_limit": 8,
    "relu_l1_coef": 0.001,
    "jumprelu_l0_coef": 0.001,
    "saebench_results_path": "/workspace/HUSAI/results/cache/external_benchmarks/husai_saebench_probe_results_frontier",
    "saebench_model_cache_path": "/tmp/sae_bench_model_cache",
    "cebench_artifacts_path": "/workspace/HUSAI/results/cache/external_benchmarks/ce_bench_artifacts_frontier",
    "data_meta": {
      "num_files_discovered": 113,
      "num_files_used": 80,
      "total_rows": 144042,
      "d_model": 512
    },
    "source_files": [
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/100_news_fake_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/105_click_bait_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/106_hate_hate_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/107_hate_offensive_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/110_aimade_humangpt3_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/113_movie_sent_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/114_nyc_borough_Manhattan_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/115_nyc_borough_Brooklyn_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/116_nyc_borough_Bronx_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/117_us_state_FL_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/118_us_state_CA_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/119_us_state_TX_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/120_us_timezone_Chicago_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/121_us_timezone_New_York_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/122_us_timezone_Los_Angeles_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/123_world_country_United_Kingdom_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/124_world_country_United_States_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/125_world_country_Italy_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/126_art_type_book_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/127_art_type_song_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/128_art_type_movie_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/129_arith_mc_A_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/130_temp_cat_Frequency_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/131_temp_cat_Typical Time_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/132_temp_cat_Event Ordering_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/133_context_type_Causality_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/134_context_type_Belief_states_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/135_context_type_Event_duration_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/136_glue_mnli_entailment_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/137_glue_mnli_neutral_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/138_glue_mnli_contradiction_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/139_news_class_Politics_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/140_news_class_Technology_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/141_news_class_Entertainment_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/142_cancer_cat_Thyroid_Cancer_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/143_cancer_cat_Lung_Cancer_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/144_cancer_cat_Colon_Cancer_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/145_disease_class_digestive system diseases_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/146_disease_class_cardiovascular diseases_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/147_disease_class_nervous system diseases_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/148_twt_emotion_worry_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/149_twt_emotion_happiness_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/150_twt_emotion_sadness_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/151_it_tick_HR Support_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/152_it_tick_Hardware_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/153_it_tick_Administrative rights_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/154_athlete_sport_football_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/155_athlete_sport_basketball_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/156_athlete_sport_baseball_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/157_amazon_5star_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/158_code_C_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/159_code_Python_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/160_code_HTML_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/161_agnews_0_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/162_agnews_1_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/163_agnews_2_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/21_headline_istrump_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/22_headline_isobama_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/23_headline_ischina_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/24_headline_isiran_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/26_headline_isfrontpage_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/36_sciq_tf_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/41_truthqa_tf_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/42_temp_sense_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/44_phys_tf_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/47_reasoning_tf_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/48_cm_correct_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/49_cm_isshort_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/50_deon_isvalid_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/51_just_is_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/52_virtue_is_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/54_cs_tf_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/56_wikidatasex_or_gender_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/57_wikidatais_alive_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/58_wikidatapolitical_party_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/59_wikidata_occupation_isjournalist_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/5_hist_fig_ismale_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/60_wikidata_occupation_isathlete_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/61_wikidata_occupation_isactor_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/62_wikidata_occupation_ispolitician_blocks.0.hook_resid_pre.pt"
    ],
    "dataset_names_count": 8,
    "run_id": "run_20260213T173707Z"
  },
  "records": [
    {
      "architecture": "topk",
      "seed": 42,
      "checkpoint": "results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/topk_seed42/sae_final.pt",
      "train_metrics": {
        "mse": 0.00021257683692965657,
        "explained_variance": 0.7437508538331046,
        "l0": 32.0
      },
      "saebench": {
        "timestamp_utc": "2026-02-13T17:37:34+00:00",
        "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/topk_seed42/sae_final.pt --architecture topk --sae-release husai_topk_seed42 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /workspace/HUSAI/results/cache/external_benchmarks/husai_saebench_probe_results_frontier --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/topk_seed42/saebench --force-rerun --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn",
        "config": {
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/topk_seed42/sae_final.pt",
          "architecture_override": "topk",
          "sae_release": "husai_topk_seed42",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "reg_type": "l1",
          "setting": "normal",
          "ks": [
            1,
            2,
            5
          ],
          "dataset_names": [
            "100_news_fake",
            "105_click_bait",
            "106_hate_hate",
            "107_hate_offensive",
            "110_aimade_humangpt3",
            "113_movie_sent",
            "114_nyc_borough_Manhattan",
            "115_nyc_borough_Brooklyn"
          ],
          "dataset_names_inferred_from_cache": false,
          "dataset_count": 8,
          "binarize": false,
          "device": "cuda",
          "dtype": "float32",
          "results_path": "/workspace/HUSAI/results/cache/external_benchmarks/husai_saebench_probe_results_frontier",
          "model_cache_path": "/tmp/sae_bench_model_cache",
          "force_rerun": true
        },
        "config_hash": "a45482946eea1b7ad818f90f82bfa1fd54fb90f5c22343ec8f8f294aa1c9ba89",
        "sae_meta": {
          "architecture": "topk",
          "d_model": 512,
          "d_sae": 1024,
          "k": 32
        },
        "summary": {
          "result_key": "husai_topk_seed42_custom_sae",
          "llm_metrics": {
            "llm_test_accuracy": 0.6894223197965762,
            "llm_test_auc": 0.723007634330488,
            "llm_test_f1": 0.6792727146636758
          },
          "sae_metrics_by_k": [
            {
              "k": 1,
              "test_accuracy": 0.5545588377570202,
              "test_auc": 0.5556127207776871,
              "test_f1": 0.47204942803485084
            },
            {
              "k": 2,
              "test_accuracy": 0.5632899268148089,
              "test_auc": 0.5673881494505297,
              "test_f1": 0.4938763108117386
            },
            {
              "k": 5,
              "test_accuracy": 0.5769017422386294,
              "test_auc": 0.5901720547175472,
              "test_f1": 0.5228507213041932
            }
          ],
          "best_by_auc": {
            "k": 5,
            "test_accuracy": 0.5769017422386294,
            "test_auc": 0.5901720547175472,
            "test_f1": 0.5228507213041932
          },
          "best_minus_llm_auc": -0.1328355796129408
        }
      },
      "cebench": {
        "timestamp_utc": "2026-02-13T17:40:00+00:00",
        "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/topk_seed42/sae_final.pt --architecture topk --sae-release husai_topk_seed42 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/topk_seed42/cebench --artifacts-path /workspace/HUSAI/results/cache/external_benchmarks/ce_bench_artifacts_frontier --max-rows 200",
        "config_hash": "54254d3d32f482b38ec60c034427ccfd6f6baf2806503f0252e601e40adeb694",
        "config": {
          "cebench_repo": "/workspace/CE-Bench",
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/topk_seed42/sae_final.pt",
          "architecture_override": "topk",
          "checkpoint_sha256": "0340244b549dc6ed2c80a1c9135b15009ad5d24cf481ac6a38d91fb97e718bea",
          "sae_release": "husai_topk_seed42",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "device": "cuda",
          "sae_dtype": "float32",
          "llm_batch_size": 512,
          "llm_dtype": "float32",
          "random_seed": 42,
          "dataset_name": "GulkoA/contrastive-stories-v4",
          "dataset_rows_total": 5000,
          "dataset_rows_used": 200,
          "max_rows": 200,
          "output_folder": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/topk_seed42/cebench",
          "artifacts_path": "/workspace/HUSAI/results/cache/external_benchmarks/ce_bench_artifacts_frontier",
          "matched_baseline_summary": null
        },
        "sae_meta": {
          "architecture": "topk",
          "d_model": 512,
          "d_sae": 1024,
          "k": 32
        },
        "cebench_summary": {
          "output_folder": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/topk_seed42/cebench",
          "results_json": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/topk_seed42/cebench/interpretability_eval/husai_topk_seed42/custom_sae/results.json",
          "scores_dump": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/topk_seed42/cebench/scores_dump.txt",
          "total_rows": 200,
          "contrastive_score_mean_max": 7.901997175216675,
          "independent_score_mean_max": 9.000797727108,
          "interpretability_score_mean_max": 7.585395152568817,
          "sae_release": "husai_topk_seed42",
          "sae_id": "custom_sae",
          "date": "2026-02-13 17:40:00",
          "scores_dump_line_count": 200
        },
        "custom_metrics": {
          "contrastive_score_mean_max": 7.901997175216675,
          "independent_score_mean_max": 9.000797727108,
          "interpretability_score_mean_max": 7.585395152568817
        },
        "matched_baseline_metrics": null,
        "delta_vs_matched_baseline": null,
        "matched_baseline_payload": null,
        "artifacts": {
          "cebench_metrics_summary_json": "results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/topk_seed42/cebench/cebench_metrics_summary.json",
          "cebench_metrics_summary_md": "results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/topk_seed42/cebench/cebench_metrics_summary.md"
        }
      },
      "saebench_returncode": 0,
      "cebench_returncode": 0
    },
    {
      "architecture": "relu",
      "seed": 42,
      "checkpoint": "results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/relu_seed42/sae_final.pt",
      "train_metrics": {
        "mse": 3.863715846819105e-06,
        "explained_variance": 0.9953425196668417,
        "l0": 654.0625
      },
      "saebench": {
        "timestamp_utc": "2026-02-13T17:40:38+00:00",
        "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/relu_seed42/sae_final.pt --architecture relu --sae-release husai_relu_seed42 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /workspace/HUSAI/results/cache/external_benchmarks/husai_saebench_probe_results_frontier --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/relu_seed42/saebench --force-rerun --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn",
        "config": {
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/relu_seed42/sae_final.pt",
          "architecture_override": "relu",
          "sae_release": "husai_relu_seed42",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "reg_type": "l1",
          "setting": "normal",
          "ks": [
            1,
            2,
            5
          ],
          "dataset_names": [
            "100_news_fake",
            "105_click_bait",
            "106_hate_hate",
            "107_hate_offensive",
            "110_aimade_humangpt3",
            "113_movie_sent",
            "114_nyc_borough_Manhattan",
            "115_nyc_borough_Brooklyn"
          ],
          "dataset_names_inferred_from_cache": false,
          "dataset_count": 8,
          "binarize": false,
          "device": "cuda",
          "dtype": "float32",
          "results_path": "/workspace/HUSAI/results/cache/external_benchmarks/husai_saebench_probe_results_frontier",
          "model_cache_path": "/tmp/sae_bench_model_cache",
          "force_rerun": true
        },
        "config_hash": "8a0b2bf2b8d948800904599cf734956f4e6702481c73792bceadf3b217539731",
        "sae_meta": {
          "architecture": "relu",
          "d_model": 512,
          "d_sae": 1024,
          "k": null
        },
        "summary": {
          "result_key": "husai_relu_seed42_custom_sae",
          "llm_metrics": {
            "llm_test_accuracy": 0.6894223197965762,
            "llm_test_auc": 0.723007634330488,
            "llm_test_f1": 0.6792727146636758
          },
          "sae_metrics_by_k": [
            {
              "k": 1,
              "test_accuracy": 0.6388064523049178,
              "test_auc": 0.637551937767731,
              "test_f1": 0.5974885448867371
            },
            {
              "k": 2,
              "test_accuracy": 0.6572728762544484,
              "test_auc": 0.6696793806599756,
              "test_f1": 0.6384237879418574
            },
            {
              "k": 5,
              "test_accuracy": 0.6638735036927684,
              "test_auc": 0.688367505246788,
              "test_f1": 0.6439479106296234
            }
          ],
          "best_by_auc": {
            "k": 5,
            "test_accuracy": 0.6638735036927684,
            "test_auc": 0.688367505246788,
            "test_f1": 0.6439479106296234
          },
          "best_minus_llm_auc": -0.034640129083699955
        }
      },
      "cebench": {
        "timestamp_utc": "2026-02-13T17:43:05+00:00",
        "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/relu_seed42/sae_final.pt --architecture relu --sae-release husai_relu_seed42 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/relu_seed42/cebench --artifacts-path /workspace/HUSAI/results/cache/external_benchmarks/ce_bench_artifacts_frontier --max-rows 200",
        "config_hash": "d3b94349a79c3339882bcfcde17684c2e4c8339c18c1539c4f10392a4771c183",
        "config": {
          "cebench_repo": "/workspace/CE-Bench",
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/relu_seed42/sae_final.pt",
          "architecture_override": "relu",
          "checkpoint_sha256": "fe206d2ac6464912bb1f855c8249cf7434b6034e7a6d9cb4146a2181fd327a17",
          "sae_release": "husai_relu_seed42",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "device": "cuda",
          "sae_dtype": "float32",
          "llm_batch_size": 512,
          "llm_dtype": "float32",
          "random_seed": 42,
          "dataset_name": "GulkoA/contrastive-stories-v4",
          "dataset_rows_total": 5000,
          "dataset_rows_used": 200,
          "max_rows": 200,
          "output_folder": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/relu_seed42/cebench",
          "artifacts_path": "/workspace/HUSAI/results/cache/external_benchmarks/ce_bench_artifacts_frontier",
          "matched_baseline_summary": null
        },
        "sae_meta": {
          "architecture": "relu",
          "d_model": 512,
          "d_sae": 1024,
          "k": null
        },
        "cebench_summary": {
          "output_folder": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/relu_seed42/cebench",
          "results_json": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/relu_seed42/cebench/interpretability_eval/husai_relu_seed42/custom_sae/results.json",
          "scores_dump": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/relu_seed42/cebench/scores_dump.txt",
          "total_rows": 200,
          "contrastive_score_mean_max": 4.484524784088134,
          "independent_score_mean_max": 4.622185326814652,
          "interpretability_score_mean_max": 4.228144862651825,
          "sae_release": "husai_relu_seed42",
          "sae_id": "custom_sae",
          "date": "2026-02-13 17:43:05",
          "scores_dump_line_count": 200
        },
        "custom_metrics": {
          "contrastive_score_mean_max": 4.484524784088134,
          "independent_score_mean_max": 4.622185326814652,
          "interpretability_score_mean_max": 4.228144862651825
        },
        "matched_baseline_metrics": null,
        "delta_vs_matched_baseline": null,
        "matched_baseline_payload": null,
        "artifacts": {
          "cebench_metrics_summary_json": "results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/relu_seed42/cebench/cebench_metrics_summary.json",
          "cebench_metrics_summary_md": "results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/relu_seed42/cebench/cebench_metrics_summary.md"
        }
      },
      "saebench_returncode": 0,
      "cebench_returncode": 0
    },
    {
      "architecture": "batchtopk",
      "seed": 42,
      "checkpoint": "results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/batchtopk_seed42/sae_final.pt",
      "train_metrics": {
        "mse": 0.00026667225756682456,
        "explained_variance": 0.6785504213576471,
        "l0": 79.89453887939453
      },
      "saebench": {
        "timestamp_utc": "2026-02-13T17:43:38+00:00",
        "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/batchtopk_seed42/sae_final.pt --architecture batchtopk --sae-release husai_batchtopk_seed42 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /workspace/HUSAI/results/cache/external_benchmarks/husai_saebench_probe_results_frontier --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/batchtopk_seed42/saebench --force-rerun --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn",
        "config": {
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/batchtopk_seed42/sae_final.pt",
          "architecture_override": "batchtopk",
          "sae_release": "husai_batchtopk_seed42",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "reg_type": "l1",
          "setting": "normal",
          "ks": [
            1,
            2,
            5
          ],
          "dataset_names": [
            "100_news_fake",
            "105_click_bait",
            "106_hate_hate",
            "107_hate_offensive",
            "110_aimade_humangpt3",
            "113_movie_sent",
            "114_nyc_borough_Manhattan",
            "115_nyc_borough_Brooklyn"
          ],
          "dataset_names_inferred_from_cache": false,
          "dataset_count": 8,
          "binarize": false,
          "device": "cuda",
          "dtype": "float32",
          "results_path": "/workspace/HUSAI/results/cache/external_benchmarks/husai_saebench_probe_results_frontier",
          "model_cache_path": "/tmp/sae_bench_model_cache",
          "force_rerun": true
        },
        "config_hash": "e53ff40f95670f6b00ae2b79347bae869ca4a2556907c0245ecbdd4fc508307b",
        "sae_meta": {
          "architecture": "batchtopk",
          "d_model": 512,
          "d_sae": 1024,
          "k": 32
        },
        "summary": {
          "result_key": "husai_batchtopk_seed42_custom_sae",
          "llm_metrics": {
            "llm_test_accuracy": 0.6894223197965762,
            "llm_test_auc": 0.723007634330488,
            "llm_test_f1": 0.6792727146636758
          },
          "sae_metrics_by_k": [
            {
              "k": 1,
              "test_accuracy": 0.6241997694925336,
              "test_auc": 0.6408079631745889,
              "test_f1": 0.5868766191329755
            },
            {
              "k": 2,
              "test_accuracy": 0.6246730297256962,
              "test_auc": 0.6407326041690029,
              "test_f1": 0.5713708422807529
            },
            {
              "k": 5,
              "test_accuracy": 0.6483575954723662,
              "test_auc": 0.6600292441574206,
              "test_f1": 0.6029917904803057
            }
          ],
          "best_by_auc": {
            "k": 5,
            "test_accuracy": 0.6483575954723662,
            "test_auc": 0.6600292441574206,
            "test_f1": 0.6029917904803057
          },
          "best_minus_llm_auc": -0.06297839017306739
        }
      },
      "cebench": {
        "timestamp_utc": "2026-02-13T17:46:05+00:00",
        "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/batchtopk_seed42/sae_final.pt --architecture batchtopk --sae-release husai_batchtopk_seed42 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/batchtopk_seed42/cebench --artifacts-path /workspace/HUSAI/results/cache/external_benchmarks/ce_bench_artifacts_frontier --max-rows 200",
        "config_hash": "34e54904b823072f6cf435ce88fdb22c7a59b9d381d30c8d88dcf0622cc0cdb9",
        "config": {
          "cebench_repo": "/workspace/CE-Bench",
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/batchtopk_seed42/sae_final.pt",
          "architecture_override": "batchtopk",
          "checkpoint_sha256": "2a2ee3c2ac2e74bb9388a1267e3af5341d3ab3f43ed9d5656fba3e972a68b2e1",
          "sae_release": "husai_batchtopk_seed42",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "device": "cuda",
          "sae_dtype": "float32",
          "llm_batch_size": 512,
          "llm_dtype": "float32",
          "random_seed": 42,
          "dataset_name": "GulkoA/contrastive-stories-v4",
          "dataset_rows_total": 5000,
          "dataset_rows_used": 200,
          "max_rows": 200,
          "output_folder": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/batchtopk_seed42/cebench",
          "artifacts_path": "/workspace/HUSAI/results/cache/external_benchmarks/ce_bench_artifacts_frontier",
          "matched_baseline_summary": null
        },
        "sae_meta": {
          "architecture": "batchtopk",
          "d_model": 512,
          "d_sae": 1024,
          "k": 32
        },
        "cebench_summary": {
          "output_folder": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/batchtopk_seed42/cebench",
          "results_json": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/batchtopk_seed42/cebench/interpretability_eval/husai_batchtopk_seed42/custom_sae/results.json",
          "scores_dump": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/batchtopk_seed42/cebench/scores_dump.txt",
          "total_rows": 200,
          "contrastive_score_mean_max": 6.804405152797699,
          "independent_score_mean_max": 7.664323370456696,
          "interpretability_score_mean_max": 6.4668281817436215,
          "sae_release": "husai_batchtopk_seed42",
          "sae_id": "custom_sae",
          "date": "2026-02-13 17:46:05",
          "scores_dump_line_count": 200
        },
        "custom_metrics": {
          "contrastive_score_mean_max": 6.804405152797699,
          "independent_score_mean_max": 7.664323370456696,
          "interpretability_score_mean_max": 6.4668281817436215
        },
        "matched_baseline_metrics": null,
        "delta_vs_matched_baseline": null,
        "matched_baseline_payload": null,
        "artifacts": {
          "cebench_metrics_summary_json": "results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/batchtopk_seed42/cebench/cebench_metrics_summary.json",
          "cebench_metrics_summary_md": "results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/batchtopk_seed42/cebench/cebench_metrics_summary.md"
        }
      },
      "saebench_returncode": 0,
      "cebench_returncode": 0
    },
    {
      "architecture": "jumprelu",
      "seed": 42,
      "checkpoint": "results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/jumprelu_seed42/sae_final.pt",
      "train_metrics": {
        "mse": 3.885285877913702e-06,
        "explained_variance": 0.9953188298546644,
        "l0": 974.9674072265625
      },
      "saebench": {
        "timestamp_utc": "2026-02-13T17:46:42+00:00",
        "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/jumprelu_seed42/sae_final.pt --architecture jumprelu --sae-release husai_jumprelu_seed42 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /workspace/HUSAI/results/cache/external_benchmarks/husai_saebench_probe_results_frontier --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/jumprelu_seed42/saebench --force-rerun --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn",
        "config": {
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/jumprelu_seed42/sae_final.pt",
          "architecture_override": "jumprelu",
          "sae_release": "husai_jumprelu_seed42",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "reg_type": "l1",
          "setting": "normal",
          "ks": [
            1,
            2,
            5
          ],
          "dataset_names": [
            "100_news_fake",
            "105_click_bait",
            "106_hate_hate",
            "107_hate_offensive",
            "110_aimade_humangpt3",
            "113_movie_sent",
            "114_nyc_borough_Manhattan",
            "115_nyc_borough_Brooklyn"
          ],
          "dataset_names_inferred_from_cache": false,
          "dataset_count": 8,
          "binarize": false,
          "device": "cuda",
          "dtype": "float32",
          "results_path": "/workspace/HUSAI/results/cache/external_benchmarks/husai_saebench_probe_results_frontier",
          "model_cache_path": "/tmp/sae_bench_model_cache",
          "force_rerun": true
        },
        "config_hash": "76c630a6aec9a73da4d0cc0aea917b4af59ab2be9df036687a6428631563d981",
        "sae_meta": {
          "architecture": "jumprelu",
          "d_model": 512,
          "d_sae": 1024,
          "k": null
        },
        "summary": {
          "result_key": "husai_jumprelu_seed42_custom_sae",
          "llm_metrics": {
            "llm_test_accuracy": 0.6894223197965762,
            "llm_test_auc": 0.723007634330488,
            "llm_test_f1": 0.6792727146636758
          },
          "sae_metrics_by_k": [
            {
              "k": 1,
              "test_accuracy": 0.6526212119953946,
              "test_auc": 0.662551885228811,
              "test_f1": 0.6166819854759481
            },
            {
              "k": 2,
              "test_accuracy": 0.659245147036593,
              "test_auc": 0.6697764585897433,
              "test_f1": 0.6404011191751582
            },
            {
              "k": 5,
              "test_accuracy": 0.6625109917390476,
              "test_auc": 0.6741640133042202,
              "test_f1": 0.6438175872635046
            }
          ],
          "best_by_auc": {
            "k": 5,
            "test_accuracy": 0.6625109917390476,
            "test_auc": 0.6741640133042202,
            "test_f1": 0.6438175872635046
          },
          "best_minus_llm_auc": -0.048843621026267825
        }
      },
      "cebench": {
        "timestamp_utc": "2026-02-13T17:49:06+00:00",
        "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/jumprelu_seed42/sae_final.pt --architecture jumprelu --sae-release husai_jumprelu_seed42 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/jumprelu_seed42/cebench --artifacts-path /workspace/HUSAI/results/cache/external_benchmarks/ce_bench_artifacts_frontier --max-rows 200",
        "config_hash": "b6ca8d79cad13c08b73c9de374c7e382fd1f23d8ee7b6eb4eeb6fec1a0bded96",
        "config": {
          "cebench_repo": "/workspace/CE-Bench",
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/checkpoints/jumprelu_seed42/sae_final.pt",
          "architecture_override": "jumprelu",
          "checkpoint_sha256": "7d8c81a22578b73ac36c02d122256c648abe876601b158d195581e9afef80f2c",
          "sae_release": "husai_jumprelu_seed42",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "device": "cuda",
          "sae_dtype": "float32",
          "llm_batch_size": 512,
          "llm_dtype": "float32",
          "random_seed": 42,
          "dataset_name": "GulkoA/contrastive-stories-v4",
          "dataset_rows_total": 5000,
          "dataset_rows_used": 200,
          "max_rows": 200,
          "output_folder": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/jumprelu_seed42/cebench",
          "artifacts_path": "/workspace/HUSAI/results/cache/external_benchmarks/ce_bench_artifacts_frontier",
          "matched_baseline_summary": null
        },
        "sae_meta": {
          "architecture": "jumprelu",
          "d_model": 512,
          "d_sae": 1024,
          "k": null
        },
        "cebench_summary": {
          "output_folder": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/jumprelu_seed42/cebench",
          "results_json": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/jumprelu_seed42/cebench/interpretability_eval/husai_jumprelu_seed42/custom_sae/results.json",
          "scores_dump": "/workspace/HUSAI/results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/jumprelu_seed42/cebench/scores_dump.txt",
          "total_rows": 200,
          "contrastive_score_mean_max": 4.5816484069824215,
          "independent_score_mean_max": 4.6479918885231015,
          "interpretability_score_mean_max": 4.350986768007278,
          "sae_release": "husai_jumprelu_seed42",
          "sae_id": "custom_sae",
          "date": "2026-02-13 17:49:06",
          "scores_dump_line_count": 200
        },
        "custom_metrics": {
          "contrastive_score_mean_max": 4.5816484069824215,
          "independent_score_mean_max": 4.6479918885231015,
          "interpretability_score_mean_max": 4.350986768007278
        },
        "matched_baseline_metrics": null,
        "delta_vs_matched_baseline": null,
        "matched_baseline_payload": null,
        "artifacts": {
          "cebench_metrics_summary_json": "results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/jumprelu_seed42/cebench/cebench_metrics_summary.json",
          "cebench_metrics_summary_md": "results/experiments/phase4b_architecture_frontier_external/run_20260213T173707Z/external_eval/jumprelu_seed42/cebench/cebench_metrics_summary.md"
        }
      },
      "saebench_returncode": 0,
      "cebench_returncode": 0
    }
  ],
  "aggregate": {
    "topk": {
      "train_mse": {
        "mean": 0.00021257683692965657,
        "std": 0.0,
        "min": 0.00021257683692965657,
        "max": 0.00021257683692965657,
        "n": 1
      },
      "train_ev": {
        "mean": 0.7437508538331046,
        "std": 0.0,
        "min": 0.7437508538331046,
        "max": 0.7437508538331046,
        "n": 1
      },
      "train_l0": {
        "mean": 32.0,
        "std": 0.0,
        "min": 32.0,
        "max": 32.0,
        "n": 1
      },
      "saebench_best_auc": {
        "mean": 0.5901720547175472,
        "std": 0.0,
        "min": 0.5901720547175472,
        "max": 0.5901720547175472,
        "n": 1
      },
      "saebench_best_minus_llm_auc": {
        "mean": -0.1328355796129408,
        "std": 0.0,
        "min": -0.1328355796129408,
        "max": -0.1328355796129408,
        "n": 1
      },
      "cebench_contrastive_max": {
        "mean": 7.901997175216675,
        "std": 0.0,
        "min": 7.901997175216675,
        "max": 7.901997175216675,
        "n": 1
      },
      "cebench_independent_max": {
        "mean": 9.000797727108,
        "std": 0.0,
        "min": 9.000797727108,
        "max": 9.000797727108,
        "n": 1
      },
      "cebench_interpretability_max": {
        "mean": 7.585395152568817,
        "std": 0.0,
        "min": 7.585395152568817,
        "max": 7.585395152568817,
        "n": 1
      }
    },
    "relu": {
      "train_mse": {
        "mean": 3.863715846819105e-06,
        "std": 0.0,
        "min": 3.863715846819105e-06,
        "max": 3.863715846819105e-06,
        "n": 1
      },
      "train_ev": {
        "mean": 0.9953425196668417,
        "std": 0.0,
        "min": 0.9953425196668417,
        "max": 0.9953425196668417,
        "n": 1
      },
      "train_l0": {
        "mean": 654.0625,
        "std": 0.0,
        "min": 654.0625,
        "max": 654.0625,
        "n": 1
      },
      "saebench_best_auc": {
        "mean": 0.688367505246788,
        "std": 0.0,
        "min": 0.688367505246788,
        "max": 0.688367505246788,
        "n": 1
      },
      "saebench_best_minus_llm_auc": {
        "mean": -0.034640129083699955,
        "std": 0.0,
        "min": -0.034640129083699955,
        "max": -0.034640129083699955,
        "n": 1
      },
      "cebench_contrastive_max": {
        "mean": 4.484524784088134,
        "std": 0.0,
        "min": 4.484524784088134,
        "max": 4.484524784088134,
        "n": 1
      },
      "cebench_independent_max": {
        "mean": 4.622185326814652,
        "std": 0.0,
        "min": 4.622185326814652,
        "max": 4.622185326814652,
        "n": 1
      },
      "cebench_interpretability_max": {
        "mean": 4.228144862651825,
        "std": 0.0,
        "min": 4.228144862651825,
        "max": 4.228144862651825,
        "n": 1
      }
    },
    "batchtopk": {
      "train_mse": {
        "mean": 0.00026667225756682456,
        "std": 0.0,
        "min": 0.00026667225756682456,
        "max": 0.00026667225756682456,
        "n": 1
      },
      "train_ev": {
        "mean": 0.6785504213576471,
        "std": 0.0,
        "min": 0.6785504213576471,
        "max": 0.6785504213576471,
        "n": 1
      },
      "train_l0": {
        "mean": 79.89453887939453,
        "std": 0.0,
        "min": 79.89453887939453,
        "max": 79.89453887939453,
        "n": 1
      },
      "saebench_best_auc": {
        "mean": 0.6600292441574206,
        "std": 0.0,
        "min": 0.6600292441574206,
        "max": 0.6600292441574206,
        "n": 1
      },
      "saebench_best_minus_llm_auc": {
        "mean": -0.06297839017306739,
        "std": 0.0,
        "min": -0.06297839017306739,
        "max": -0.06297839017306739,
        "n": 1
      },
      "cebench_contrastive_max": {
        "mean": 6.804405152797699,
        "std": 0.0,
        "min": 6.804405152797699,
        "max": 6.804405152797699,
        "n": 1
      },
      "cebench_independent_max": {
        "mean": 7.664323370456696,
        "std": 0.0,
        "min": 7.664323370456696,
        "max": 7.664323370456696,
        "n": 1
      },
      "cebench_interpretability_max": {
        "mean": 6.4668281817436215,
        "std": 0.0,
        "min": 6.4668281817436215,
        "max": 6.4668281817436215,
        "n": 1
      }
    },
    "jumprelu": {
      "train_mse": {
        "mean": 3.885285877913702e-06,
        "std": 0.0,
        "min": 3.885285877913702e-06,
        "max": 3.885285877913702e-06,
        "n": 1
      },
      "train_ev": {
        "mean": 0.9953188298546644,
        "std": 0.0,
        "min": 0.9953188298546644,
        "max": 0.9953188298546644,
        "n": 1
      },
      "train_l0": {
        "mean": 974.9674072265625,
        "std": 0.0,
        "min": 974.9674072265625,
        "max": 974.9674072265625,
        "n": 1
      },
      "saebench_best_auc": {
        "mean": 0.6741640133042202,
        "std": 0.0,
        "min": 0.6741640133042202,
        "max": 0.6741640133042202,
        "n": 1
      },
      "saebench_best_minus_llm_auc": {
        "mean": -0.048843621026267825,
        "std": 0.0,
        "min": -0.048843621026267825,
        "max": -0.048843621026267825,
        "n": 1
      },
      "cebench_contrastive_max": {
        "mean": 4.5816484069824215,
        "std": 0.0,
        "min": 4.5816484069824215,
        "max": 4.5816484069824215,
        "n": 1
      },
      "cebench_independent_max": {
        "mean": 4.6479918885231015,
        "std": 0.0,
        "min": 4.6479918885231015,
        "max": 4.6479918885231015,
        "n": 1
      },
      "cebench_interpretability_max": {
        "mean": 4.350986768007278,
        "std": 0.0,
        "min": 4.350986768007278,
        "max": 4.350986768007278,
        "n": 1
      }
    }
  }
}
