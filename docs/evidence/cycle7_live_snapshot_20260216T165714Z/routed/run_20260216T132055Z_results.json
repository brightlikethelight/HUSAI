{
  "timestamp_utc": "2026-02-16T13:36:50+00:00",
  "command": "python scripts/experiments/run_routed_frontier_external.py --activation-cache-dir /tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped --activation-glob *_blocks.0.hook_resid_pre.pt --max-files 80 --max-rows-per-file 2048 --max-total-rows 150000 --seeds 42,123,456,789,1011 --d-sae 2048 --k 48 --epochs 12 --batch-size 4096 --learning-rate 0.0007 --num-experts 8 --route-balance-coef 0.02 --route-entropy-coef 0.02 --route-topk-mode expert_topk --device cuda --dtype float32 --run-saebench --run-cebench --cebench-repo /workspace/CE-Bench --cebench-max-rows 200 --cebench-matched-baseline-summary docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json --saebench-datasets 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --saebench-results-path /tmp/husai_saebench_probe_results_cycle7_routed --saebench-model-cache-path /tmp/sae_bench_model_cache --cebench-artifacts-path /tmp/ce_bench_artifacts_cycle7_routed --output-dir results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto",
  "config": {
    "activation_cache_dir": "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped",
    "activation_glob": "*_blocks.0.hook_resid_pre.pt",
    "max_files": 80,
    "max_rows_per_file": 2048,
    "max_total_rows": 150000,
    "architecture": "routed_topk",
    "seeds": [
      42,
      123,
      456,
      789,
      1011
    ],
    "d_sae": 2048,
    "k": 48,
    "epochs": 12,
    "batch_size": 4096,
    "learning_rate": 0.0007,
    "device": "cuda",
    "dtype": "float32",
    "model_name": "pythia-70m-deduped",
    "hook_layer": 0,
    "hook_name": "blocks.0.hook_resid_pre",
    "num_experts": 8,
    "route_balance_coef": 0.02,
    "route_entropy_coef": 0.02,
    "route_topk_mode": "expert_topk",
    "run_saebench": true,
    "run_cebench": true,
    "cebench_repo": "/workspace/CE-Bench",
    "cebench_max_rows": 200,
    "cebench_matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
    "saebench_datasets": [
      "100_news_fake",
      "105_click_bait",
      "106_hate_hate",
      "107_hate_offensive",
      "110_aimade_humangpt3",
      "113_movie_sent",
      "114_nyc_borough_Manhattan",
      "115_nyc_borough_Brooklyn",
      "116_nyc_borough_Bronx",
      "117_us_state_FL",
      "118_us_state_CA",
      "119_us_state_TX",
      "120_us_timezone_Chicago",
      "121_us_timezone_New_York",
      "122_us_timezone_Los_Angeles",
      "123_world_country_United_Kingdom"
    ],
    "saebench_dataset_limit": 0,
    "saebench_results_path": "/tmp/husai_saebench_probe_results_cycle7_routed",
    "saebench_model_cache_path": "/tmp/sae_bench_model_cache",
    "cebench_artifacts_path": "/tmp/ce_bench_artifacts_cycle7_routed",
    "data_meta": {
      "num_files_discovered": 113,
      "num_files_used": 80,
      "total_rows": 144042,
      "d_model": 512
    },
    "source_files": [
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/100_news_fake_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/105_click_bait_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/106_hate_hate_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/107_hate_offensive_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/110_aimade_humangpt3_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/113_movie_sent_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/114_nyc_borough_Manhattan_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/115_nyc_borough_Brooklyn_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/116_nyc_borough_Bronx_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/117_us_state_FL_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/118_us_state_CA_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/119_us_state_TX_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/120_us_timezone_Chicago_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/121_us_timezone_New_York_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/122_us_timezone_Los_Angeles_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/123_world_country_United_Kingdom_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/124_world_country_United_States_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/125_world_country_Italy_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/126_art_type_book_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/127_art_type_song_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/128_art_type_movie_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/129_arith_mc_A_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/130_temp_cat_Frequency_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/131_temp_cat_Typical Time_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/132_temp_cat_Event Ordering_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/133_context_type_Causality_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/134_context_type_Belief_states_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/135_context_type_Event_duration_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/136_glue_mnli_entailment_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/137_glue_mnli_neutral_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/138_glue_mnli_contradiction_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/139_news_class_Politics_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/140_news_class_Technology_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/141_news_class_Entertainment_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/142_cancer_cat_Thyroid_Cancer_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/143_cancer_cat_Lung_Cancer_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/144_cancer_cat_Colon_Cancer_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/145_disease_class_digestive system diseases_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/146_disease_class_cardiovascular diseases_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/147_disease_class_nervous system diseases_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/148_twt_emotion_worry_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/149_twt_emotion_happiness_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/150_twt_emotion_sadness_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/151_it_tick_HR Support_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/152_it_tick_Hardware_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/153_it_tick_Administrative rights_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/154_athlete_sport_football_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/155_athlete_sport_basketball_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/156_athlete_sport_baseball_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/157_amazon_5star_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/158_code_C_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/159_code_Python_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/160_code_HTML_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/161_agnews_0_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/162_agnews_1_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/163_agnews_2_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/21_headline_istrump_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/22_headline_isobama_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/23_headline_ischina_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/24_headline_isiran_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/26_headline_isfrontpage_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/36_sciq_tf_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/41_truthqa_tf_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/42_temp_sense_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/44_phys_tf_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/47_reasoning_tf_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/48_cm_correct_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/49_cm_isshort_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/50_deon_isvalid_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/51_just_is_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/52_virtue_is_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/54_cs_tf_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/56_wikidatasex_or_gender_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/57_wikidatais_alive_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/58_wikidatapolitical_party_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/59_wikidata_occupation_isjournalist_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/5_hist_fig_ismale_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/60_wikidata_occupation_isathlete_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/61_wikidata_occupation_isactor_blocks.0.hook_resid_pre.pt",
      "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/62_wikidata_occupation_ispolitician_blocks.0.hook_resid_pre.pt"
    ],
    "dataset_names_count": 16,
    "run_id": "run_20260216T132055Z"
  },
  "records": [
    {
      "architecture": "routed_topk",
      "seed": 42,
      "checkpoint": "results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed42/sae_final.pt",
      "train_metrics": {
        "mse": 0.0005382864619605243,
        "explained_variance": 0.351126694834593,
        "l0": 48.0,
        "routing_entropy": 2.079441547393799,
        "routing_balance_l2": 5.1881670515285805e-06
      },
      "route_diagnostics": {
        "expert_usage": [
          0.1250009536743164,
          0.1250019371509552,
          0.12499628216028214,
          0.12499983608722687,
          0.12499967217445374,
          0.1250026822090149,
          0.12499957531690598,
          0.124999038875103
        ],
        "num_experts": 8,
        "group_size_mean": 256.0
      },
      "saebench": {
        "timestamp_utc": "2026-02-16T13:21:52+00:00",
        "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed42/sae_final.pt --architecture routed_topk --sae-release husai_run_20260216T132055Z_routed_topk_seed42 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle7_routed --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed42/saebench --force-rerun --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom",
        "config": {
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed42/sae_final.pt",
          "architecture_override": "routed_topk",
          "sae_release": "husai_run_20260216T132055Z_routed_topk_seed42",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "reg_type": "l1",
          "setting": "normal",
          "ks": [
            1,
            2,
            5
          ],
          "dataset_names": [
            "100_news_fake",
            "105_click_bait",
            "106_hate_hate",
            "107_hate_offensive",
            "110_aimade_humangpt3",
            "113_movie_sent",
            "114_nyc_borough_Manhattan",
            "115_nyc_borough_Brooklyn",
            "116_nyc_borough_Bronx",
            "117_us_state_FL",
            "118_us_state_CA",
            "119_us_state_TX",
            "120_us_timezone_Chicago",
            "121_us_timezone_New_York",
            "122_us_timezone_Los_Angeles",
            "123_world_country_United_Kingdom"
          ],
          "dataset_names_inferred_from_cache": false,
          "dataset_count": 16,
          "binarize": false,
          "device": "cuda",
          "dtype": "float32",
          "results_path": "/tmp/husai_saebench_probe_results_cycle7_routed",
          "model_cache_path": "/tmp/sae_bench_model_cache",
          "force_rerun": true
        },
        "config_hash": "b41eae24c54a386e1a944b96a8964d14a049681c926483dcb327dc79f0b80ce2",
        "sae_meta": {
          "architecture": "routed_topk",
          "eval_architecture": "topk",
          "d_model": 512,
          "d_sae": 2048,
          "k": 48,
          "dead_features_repaired": 0,
          "decoder_norm_max_deviation": 1.1920928955078125e-07
        },
        "summary": {
          "result_key": "husai_run_20260216T132055Z_routed_topk_seed42_custom_sae",
          "llm_metrics": {
            "llm_test_accuracy": 0.6605360072070458,
            "llm_test_auc": 0.6928164663947145,
            "llm_test_f1": 0.6491238078533221
          },
          "sae_metrics_by_k": [
            {
              "k": 1,
              "test_accuracy": 0.5935826290685964,
              "test_auc": 0.606701977481711,
              "test_f1": 0.5304962869373888
            },
            {
              "k": 2,
              "test_accuracy": 0.6099516677120554,
              "test_auc": 0.6267472208080808,
              "test_f1": 0.5686532716226087
            },
            {
              "k": 5,
              "test_accuracy": 0.620635622092927,
              "test_auc": 0.6420859286870655,
              "test_f1": 0.5915140471222464
            }
          ],
          "best_by_auc": {
            "k": 5,
            "test_accuracy": 0.620635622092927,
            "test_auc": 0.6420859286870655,
            "test_f1": 0.5915140471222464
          },
          "best_minus_llm_auc": -0.050730537707649015
        }
      },
      "cebench": {
        "timestamp_utc": "2026-02-16T13:24:10+00:00",
        "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed42/sae_final.pt --architecture routed_topk --sae-release husai_run_20260216T132055Z_routed_topk_seed42 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed42/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle7_routed --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
        "config_hash": "72450d7f838a88adf4e99236c559ce9e1c7145d21b1d213c0758f03cd9544aae",
        "config": {
          "cebench_repo": "/workspace/CE-Bench",
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed42/sae_final.pt",
          "architecture_override": "routed_topk",
          "checkpoint_sha256": "51038a2dc75d99f7f94cb24772d67ab045cd854944d85abbb69fe5ae79554fe3",
          "sae_release": "husai_run_20260216T132055Z_routed_topk_seed42",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "device": "cuda",
          "sae_dtype": "float32",
          "llm_batch_size": 512,
          "llm_dtype": "float32",
          "random_seed": 42,
          "dataset_name": "GulkoA/contrastive-stories-v4",
          "dataset_rows_total": 5000,
          "dataset_rows_used": 200,
          "max_rows": 200,
          "output_folder": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed42/cebench",
          "artifacts_path": "/tmp/ce_bench_artifacts_cycle7_routed",
          "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
        },
        "sae_meta": {
          "architecture": "routed_topk",
          "eval_architecture": "topk",
          "d_model": 512,
          "d_sae": 2048,
          "k": 48,
          "dead_features_repaired": 0,
          "decoder_norm_max_deviation": 1.1920928955078125e-07
        },
        "cebench_summary": {
          "output_folder": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed42/cebench",
          "results_json": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed42/cebench/interpretability_eval/husai_run_20260216T132055Z_routed_topk_seed42/custom_sae/results.json",
          "scores_dump": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed42/cebench/scores_dump.txt",
          "total_rows": 200,
          "contrastive_score_mean_max": 10.960096957683563,
          "independent_score_mean_max": 11.282248549461364,
          "interpretability_score_mean_max": 11.64863579273224,
          "sae_release": "husai_run_20260216T132055Z_routed_topk_seed42",
          "sae_id": "custom_sae",
          "date": "2026-02-16 13:24:09",
          "scores_dump_line_count": 200
        },
        "custom_metrics": {
          "contrastive_score_mean_max": 10.960096957683563,
          "independent_score_mean_max": 11.282248549461364,
          "interpretability_score_mean_max": 11.64863579273224
        },
        "matched_baseline_metrics": {
          "contrastive_score_mean_max": 50.51130743026734,
          "independent_score_mean_max": 50.99926634788513,
          "interpretability_score_mean_max": 47.951611585617066
        },
        "delta_vs_matched_baseline": {
          "contrastive_score_mean_max": -39.551210472583776,
          "independent_score_mean_max": -39.71701779842377,
          "interpretability_score_mean_max": -36.30297579288482
        },
        "matched_baseline_payload": {
          "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
          "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
          "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
          "total_rows": 200,
          "contrastive_score_mean_max": 50.51130743026734,
          "independent_score_mean_max": 50.99926634788513,
          "interpretability_score_mean_max": 47.951611585617066,
          "sae_release": "pythia-70m-deduped-res-sm",
          "sae_id": "blocks.0.hook_resid_pre",
          "date": "2026-02-13 18:59:31",
          "scores_dump_line_count": 200
        },
        "artifacts": {
          "cebench_metrics_summary_json": "results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed42/cebench/cebench_metrics_summary.json",
          "cebench_metrics_summary_md": "results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed42/cebench/cebench_metrics_summary.md"
        }
      },
      "saebench_returncode": 0,
      "cebench_returncode": 0
    },
    {
      "architecture": "routed_topk",
      "seed": 123,
      "checkpoint": "results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed123/sae_final.pt",
      "train_metrics": {
        "mse": 0.0005054944776929915,
        "explained_variance": 0.3906550190090351,
        "l0": 48.0,
        "routing_entropy": 2.0794413089752197,
        "routing_balance_l2": 1.5976478607626632e-05
      },
      "route_diagnostics": {
        "expert_usage": [
          0.12499730288982391,
          0.1249995082616806,
          0.12499921023845673,
          0.12499429285526276,
          0.12499909102916718,
          0.1250142902135849,
          0.12499933689832687,
          0.12499698996543884
        ],
        "num_experts": 8,
        "group_size_mean": 256.0
      },
      "saebench": {
        "timestamp_utc": "2026-02-16T13:25:04+00:00",
        "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed123/sae_final.pt --architecture routed_topk --sae-release husai_run_20260216T132055Z_routed_topk_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle7_routed --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed123/saebench --force-rerun --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom",
        "config": {
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed123/sae_final.pt",
          "architecture_override": "routed_topk",
          "sae_release": "husai_run_20260216T132055Z_routed_topk_seed123",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "reg_type": "l1",
          "setting": "normal",
          "ks": [
            1,
            2,
            5
          ],
          "dataset_names": [
            "100_news_fake",
            "105_click_bait",
            "106_hate_hate",
            "107_hate_offensive",
            "110_aimade_humangpt3",
            "113_movie_sent",
            "114_nyc_borough_Manhattan",
            "115_nyc_borough_Brooklyn",
            "116_nyc_borough_Bronx",
            "117_us_state_FL",
            "118_us_state_CA",
            "119_us_state_TX",
            "120_us_timezone_Chicago",
            "121_us_timezone_New_York",
            "122_us_timezone_Los_Angeles",
            "123_world_country_United_Kingdom"
          ],
          "dataset_names_inferred_from_cache": false,
          "dataset_count": 16,
          "binarize": false,
          "device": "cuda",
          "dtype": "float32",
          "results_path": "/tmp/husai_saebench_probe_results_cycle7_routed",
          "model_cache_path": "/tmp/sae_bench_model_cache",
          "force_rerun": true
        },
        "config_hash": "e7e71e3f7b8e0a8de899a02b313d4e7492562922a289302f591d253aec8e57b7",
        "sae_meta": {
          "architecture": "routed_topk",
          "eval_architecture": "topk",
          "d_model": 512,
          "d_sae": 2048,
          "k": 48,
          "dead_features_repaired": 0,
          "decoder_norm_max_deviation": 1.1920928955078125e-07
        },
        "summary": {
          "result_key": "husai_run_20260216T132055Z_routed_topk_seed123_custom_sae",
          "llm_metrics": {
            "llm_test_accuracy": 0.6605360072070458,
            "llm_test_auc": 0.6928164663947145,
            "llm_test_f1": 0.6491238078533221
          },
          "sae_metrics_by_k": [
            {
              "k": 1,
              "test_accuracy": 0.5864571190350932,
              "test_auc": 0.592495027547539,
              "test_f1": 0.5264049505204214
            },
            {
              "k": 2,
              "test_accuracy": 0.5951913359997842,
              "test_auc": 0.6029139130076594,
              "test_f1": 0.5527810430307742
            },
            {
              "k": 5,
              "test_accuracy": 0.6002635418669188,
              "test_auc": 0.6152394563360967,
              "test_f1": 0.5705369897200271
            }
          ],
          "best_by_auc": {
            "k": 5,
            "test_accuracy": 0.6002635418669188,
            "test_auc": 0.6152394563360967,
            "test_f1": 0.5705369897200271
          },
          "best_minus_llm_auc": -0.07757701005861783
        }
      },
      "cebench": {
        "timestamp_utc": "2026-02-16T13:27:21+00:00",
        "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed123/sae_final.pt --architecture routed_topk --sae-release husai_run_20260216T132055Z_routed_topk_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle7_routed --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
        "config_hash": "16046ee3cc881b12fc6c4752813e95faabe5f6cbd124fd32e198465ef6a015bd",
        "config": {
          "cebench_repo": "/workspace/CE-Bench",
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed123/sae_final.pt",
          "architecture_override": "routed_topk",
          "checkpoint_sha256": "e12c0e8cdfebb4c4c023756789c7d745b5d0dd8f8925f6f52c9c3833b34153b7",
          "sae_release": "husai_run_20260216T132055Z_routed_topk_seed123",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "device": "cuda",
          "sae_dtype": "float32",
          "llm_batch_size": 512,
          "llm_dtype": "float32",
          "random_seed": 42,
          "dataset_name": "GulkoA/contrastive-stories-v4",
          "dataset_rows_total": 5000,
          "dataset_rows_used": 200,
          "max_rows": 200,
          "output_folder": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed123/cebench",
          "artifacts_path": "/tmp/ce_bench_artifacts_cycle7_routed",
          "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
        },
        "sae_meta": {
          "architecture": "routed_topk",
          "eval_architecture": "topk",
          "d_model": 512,
          "d_sae": 2048,
          "k": 48,
          "dead_features_repaired": 0,
          "decoder_norm_max_deviation": 1.1920928955078125e-07
        },
        "cebench_summary": {
          "output_folder": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed123/cebench",
          "results_json": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed123/cebench/interpretability_eval/husai_run_20260216T132055Z_routed_topk_seed123/custom_sae/results.json",
          "scores_dump": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed123/cebench/scores_dump.txt",
          "total_rows": 200,
          "contrastive_score_mean_max": 10.125545425415039,
          "independent_score_mean_max": 11.175611550807952,
          "interpretability_score_mean_max": 11.154164438247681,
          "sae_release": "husai_run_20260216T132055Z_routed_topk_seed123",
          "sae_id": "custom_sae",
          "date": "2026-02-16 13:27:21",
          "scores_dump_line_count": 200
        },
        "custom_metrics": {
          "contrastive_score_mean_max": 10.125545425415039,
          "independent_score_mean_max": 11.175611550807952,
          "interpretability_score_mean_max": 11.154164438247681
        },
        "matched_baseline_metrics": {
          "contrastive_score_mean_max": 50.51130743026734,
          "independent_score_mean_max": 50.99926634788513,
          "interpretability_score_mean_max": 47.951611585617066
        },
        "delta_vs_matched_baseline": {
          "contrastive_score_mean_max": -40.385762004852296,
          "independent_score_mean_max": -39.82365479707718,
          "interpretability_score_mean_max": -36.79744714736938
        },
        "matched_baseline_payload": {
          "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
          "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
          "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
          "total_rows": 200,
          "contrastive_score_mean_max": 50.51130743026734,
          "independent_score_mean_max": 50.99926634788513,
          "interpretability_score_mean_max": 47.951611585617066,
          "sae_release": "pythia-70m-deduped-res-sm",
          "sae_id": "blocks.0.hook_resid_pre",
          "date": "2026-02-13 18:59:31",
          "scores_dump_line_count": 200
        },
        "artifacts": {
          "cebench_metrics_summary_json": "results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed123/cebench/cebench_metrics_summary.json",
          "cebench_metrics_summary_md": "results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed123/cebench/cebench_metrics_summary.md"
        }
      },
      "saebench_returncode": 0,
      "cebench_returncode": 0
    },
    {
      "architecture": "routed_topk",
      "seed": 456,
      "checkpoint": "results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed456/sae_final.pt",
      "train_metrics": {
        "mse": 0.0005607273778878152,
        "explained_variance": 0.32407564826236934,
        "l0": 48.0,
        "routing_entropy": 2.079441547393799,
        "routing_balance_l2": 8.745296327106189e-06
      },
      "route_diagnostics": {
        "expert_usage": [
          0.12499867379665375,
          0.12500128149986267,
          0.12500569224357605,
          0.12500081956386566,
          0.1249958798289299,
          0.1250024139881134,
          0.12499935925006866,
          0.12499590218067169
        ],
        "num_experts": 8,
        "group_size_mean": 256.0
      },
      "saebench": {
        "timestamp_utc": "2026-02-16T13:28:16+00:00",
        "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed456/sae_final.pt --architecture routed_topk --sae-release husai_run_20260216T132055Z_routed_topk_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle7_routed --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed456/saebench --force-rerun --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom",
        "config": {
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed456/sae_final.pt",
          "architecture_override": "routed_topk",
          "sae_release": "husai_run_20260216T132055Z_routed_topk_seed456",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "reg_type": "l1",
          "setting": "normal",
          "ks": [
            1,
            2,
            5
          ],
          "dataset_names": [
            "100_news_fake",
            "105_click_bait",
            "106_hate_hate",
            "107_hate_offensive",
            "110_aimade_humangpt3",
            "113_movie_sent",
            "114_nyc_borough_Manhattan",
            "115_nyc_borough_Brooklyn",
            "116_nyc_borough_Bronx",
            "117_us_state_FL",
            "118_us_state_CA",
            "119_us_state_TX",
            "120_us_timezone_Chicago",
            "121_us_timezone_New_York",
            "122_us_timezone_Los_Angeles",
            "123_world_country_United_Kingdom"
          ],
          "dataset_names_inferred_from_cache": false,
          "dataset_count": 16,
          "binarize": false,
          "device": "cuda",
          "dtype": "float32",
          "results_path": "/tmp/husai_saebench_probe_results_cycle7_routed",
          "model_cache_path": "/tmp/sae_bench_model_cache",
          "force_rerun": true
        },
        "config_hash": "aae9c0736ba4ae56e8fe9ffb49a2fd594f0913d92570b32a013fa5e6892e95d1",
        "sae_meta": {
          "architecture": "routed_topk",
          "eval_architecture": "topk",
          "d_model": 512,
          "d_sae": 2048,
          "k": 48,
          "dead_features_repaired": 0,
          "decoder_norm_max_deviation": 1.1920928955078125e-07
        },
        "summary": {
          "result_key": "husai_run_20260216T132055Z_routed_topk_seed456_custom_sae",
          "llm_metrics": {
            "llm_test_accuracy": 0.6605360072070458,
            "llm_test_auc": 0.6928164663947145,
            "llm_test_f1": 0.6491238078533221
          },
          "sae_metrics_by_k": [
            {
              "k": 1,
              "test_accuracy": 0.5836053104887191,
              "test_auc": 0.591757109624327,
              "test_f1": 0.5261399869109971
            },
            {
              "k": 2,
              "test_accuracy": 0.5880205652080222,
              "test_auc": 0.5967739510982264,
              "test_f1": 0.5391244036774074
            },
            {
              "k": 5,
              "test_accuracy": 0.5908329381600478,
              "test_auc": 0.6007601786756146,
              "test_f1": 0.5378320095459361
            }
          ],
          "best_by_auc": {
            "k": 5,
            "test_accuracy": 0.5908329381600478,
            "test_auc": 0.6007601786756146,
            "test_f1": 0.5378320095459361
          },
          "best_minus_llm_auc": -0.0920562877190999
        }
      },
      "cebench": {
        "timestamp_utc": "2026-02-16T13:30:34+00:00",
        "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed456/sae_final.pt --architecture routed_topk --sae-release husai_run_20260216T132055Z_routed_topk_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle7_routed --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
        "config_hash": "ccc144ab5dfbeadfd87e96109418b4349e95c69bb216077aecb9551a8750ef05",
        "config": {
          "cebench_repo": "/workspace/CE-Bench",
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed456/sae_final.pt",
          "architecture_override": "routed_topk",
          "checkpoint_sha256": "3283759c5219d84a50d9b27731cec7dcebf2f2dddd570ea84bf36aeb9097aebc",
          "sae_release": "husai_run_20260216T132055Z_routed_topk_seed456",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "device": "cuda",
          "sae_dtype": "float32",
          "llm_batch_size": 512,
          "llm_dtype": "float32",
          "random_seed": 42,
          "dataset_name": "GulkoA/contrastive-stories-v4",
          "dataset_rows_total": 5000,
          "dataset_rows_used": 200,
          "max_rows": 200,
          "output_folder": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed456/cebench",
          "artifacts_path": "/tmp/ce_bench_artifacts_cycle7_routed",
          "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
        },
        "sae_meta": {
          "architecture": "routed_topk",
          "eval_architecture": "topk",
          "d_model": 512,
          "d_sae": 2048,
          "k": 48,
          "dead_features_repaired": 0,
          "decoder_norm_max_deviation": 1.1920928955078125e-07
        },
        "cebench_summary": {
          "output_folder": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed456/cebench",
          "results_json": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed456/cebench/interpretability_eval/husai_run_20260216T132055Z_routed_topk_seed456/custom_sae/results.json",
          "scores_dump": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed456/cebench/scores_dump.txt",
          "total_rows": 200,
          "contrastive_score_mean_max": 9.526584732532502,
          "independent_score_mean_max": 9.087147283554078,
          "interpretability_score_mean_max": 9.508990712165833,
          "sae_release": "husai_run_20260216T132055Z_routed_topk_seed456",
          "sae_id": "custom_sae",
          "date": "2026-02-16 13:30:34",
          "scores_dump_line_count": 200
        },
        "custom_metrics": {
          "contrastive_score_mean_max": 9.526584732532502,
          "independent_score_mean_max": 9.087147283554078,
          "interpretability_score_mean_max": 9.508990712165833
        },
        "matched_baseline_metrics": {
          "contrastive_score_mean_max": 50.51130743026734,
          "independent_score_mean_max": 50.99926634788513,
          "interpretability_score_mean_max": 47.951611585617066
        },
        "delta_vs_matched_baseline": {
          "contrastive_score_mean_max": -40.98472269773484,
          "independent_score_mean_max": -41.91211906433105,
          "interpretability_score_mean_max": -38.44262087345123
        },
        "matched_baseline_payload": {
          "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
          "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
          "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
          "total_rows": 200,
          "contrastive_score_mean_max": 50.51130743026734,
          "independent_score_mean_max": 50.99926634788513,
          "interpretability_score_mean_max": 47.951611585617066,
          "sae_release": "pythia-70m-deduped-res-sm",
          "sae_id": "blocks.0.hook_resid_pre",
          "date": "2026-02-13 18:59:31",
          "scores_dump_line_count": 200
        },
        "artifacts": {
          "cebench_metrics_summary_json": "results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed456/cebench/cebench_metrics_summary.json",
          "cebench_metrics_summary_md": "results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed456/cebench/cebench_metrics_summary.md"
        }
      },
      "saebench_returncode": 0,
      "cebench_returncode": 0
    },
    {
      "architecture": "routed_topk",
      "seed": 789,
      "checkpoint": "results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed789/sae_final.pt",
      "train_metrics": {
        "mse": 0.000500905909575522,
        "explained_variance": 0.3961866997869127,
        "l0": 48.0,
        "routing_entropy": 2.0794410705566406,
        "routing_balance_l2": 2.923782631114591e-05
      },
      "route_diagnostics": {
        "expert_usage": [
          0.12498562783002853,
          0.12499967217445374,
          0.12500368058681488,
          0.12502411007881165,
          0.1249968409538269,
          0.12499921023845673,
          0.12499620020389557,
          0.1249946802854538
        ],
        "num_experts": 8,
        "group_size_mean": 256.0
      },
      "saebench": {
        "timestamp_utc": "2026-02-16T13:31:22+00:00",
        "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed789/sae_final.pt --architecture routed_topk --sae-release husai_run_20260216T132055Z_routed_topk_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle7_routed --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed789/saebench --force-rerun --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom",
        "config": {
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed789/sae_final.pt",
          "architecture_override": "routed_topk",
          "sae_release": "husai_run_20260216T132055Z_routed_topk_seed789",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "reg_type": "l1",
          "setting": "normal",
          "ks": [
            1,
            2,
            5
          ],
          "dataset_names": [
            "100_news_fake",
            "105_click_bait",
            "106_hate_hate",
            "107_hate_offensive",
            "110_aimade_humangpt3",
            "113_movie_sent",
            "114_nyc_borough_Manhattan",
            "115_nyc_borough_Brooklyn",
            "116_nyc_borough_Bronx",
            "117_us_state_FL",
            "118_us_state_CA",
            "119_us_state_TX",
            "120_us_timezone_Chicago",
            "121_us_timezone_New_York",
            "122_us_timezone_Los_Angeles",
            "123_world_country_United_Kingdom"
          ],
          "dataset_names_inferred_from_cache": false,
          "dataset_count": 16,
          "binarize": false,
          "device": "cuda",
          "dtype": "float32",
          "results_path": "/tmp/husai_saebench_probe_results_cycle7_routed",
          "model_cache_path": "/tmp/sae_bench_model_cache",
          "force_rerun": true
        },
        "config_hash": "a025f5b64829e3c36dc962ec38b6ac6160299fdeac9634ccc52ea27df3cf1415",
        "sae_meta": {
          "architecture": "routed_topk",
          "eval_architecture": "topk",
          "d_model": 512,
          "d_sae": 2048,
          "k": 48,
          "dead_features_repaired": 0,
          "decoder_norm_max_deviation": 1.1920928955078125e-07
        },
        "summary": {
          "result_key": "husai_run_20260216T132055Z_routed_topk_seed789_custom_sae",
          "llm_metrics": {
            "llm_test_accuracy": 0.6605360072070458,
            "llm_test_auc": 0.6928164663947145,
            "llm_test_f1": 0.6491238078533221
          },
          "sae_metrics_by_k": [
            {
              "k": 1,
              "test_accuracy": 0.5874494772713021,
              "test_auc": 0.5973049697503957,
              "test_f1": 0.5316580252990489
            },
            {
              "k": 2,
              "test_accuracy": 0.5912201112611472,
              "test_auc": 0.6056335706743122,
              "test_f1": 0.5439621746266587
            },
            {
              "k": 5,
              "test_accuracy": 0.5939322437823994,
              "test_auc": 0.6152480082677455,
              "test_f1": 0.5630411421603888
            }
          ],
          "best_by_auc": {
            "k": 5,
            "test_accuracy": 0.5939322437823994,
            "test_auc": 0.6152480082677455,
            "test_f1": 0.5630411421603888
          },
          "best_minus_llm_auc": -0.077568458126969
        }
      },
      "cebench": {
        "timestamp_utc": "2026-02-16T13:33:42+00:00",
        "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed789/sae_final.pt --architecture routed_topk --sae-release husai_run_20260216T132055Z_routed_topk_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle7_routed --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
        "config_hash": "99575836b5a428fd0639055b93fdf9fb2300ad1f734c70933893d13887ac10b3",
        "config": {
          "cebench_repo": "/workspace/CE-Bench",
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed789/sae_final.pt",
          "architecture_override": "routed_topk",
          "checkpoint_sha256": "2daee0d6417bc8bc5ac7656799032dfa82e1d15147596d346d32bd51af46e876",
          "sae_release": "husai_run_20260216T132055Z_routed_topk_seed789",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "device": "cuda",
          "sae_dtype": "float32",
          "llm_batch_size": 512,
          "llm_dtype": "float32",
          "random_seed": 42,
          "dataset_name": "GulkoA/contrastive-stories-v4",
          "dataset_rows_total": 5000,
          "dataset_rows_used": 200,
          "max_rows": 200,
          "output_folder": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed789/cebench",
          "artifacts_path": "/tmp/ce_bench_artifacts_cycle7_routed",
          "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
        },
        "sae_meta": {
          "architecture": "routed_topk",
          "eval_architecture": "topk",
          "d_model": 512,
          "d_sae": 2048,
          "k": 48,
          "dead_features_repaired": 0,
          "decoder_norm_max_deviation": 1.1920928955078125e-07
        },
        "cebench_summary": {
          "output_folder": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed789/cebench",
          "results_json": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed789/cebench/interpretability_eval/husai_run_20260216T132055Z_routed_topk_seed789/custom_sae/results.json",
          "scores_dump": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed789/cebench/scores_dump.txt",
          "total_rows": 200,
          "contrastive_score_mean_max": 9.82414303302765,
          "independent_score_mean_max": 10.340128011703491,
          "interpretability_score_mean_max": 10.155457589626312,
          "sae_release": "husai_run_20260216T132055Z_routed_topk_seed789",
          "sae_id": "custom_sae",
          "date": "2026-02-16 13:33:42",
          "scores_dump_line_count": 200
        },
        "custom_metrics": {
          "contrastive_score_mean_max": 9.82414303302765,
          "independent_score_mean_max": 10.340128011703491,
          "interpretability_score_mean_max": 10.155457589626312
        },
        "matched_baseline_metrics": {
          "contrastive_score_mean_max": 50.51130743026734,
          "independent_score_mean_max": 50.99926634788513,
          "interpretability_score_mean_max": 47.951611585617066
        },
        "delta_vs_matched_baseline": {
          "contrastive_score_mean_max": -40.687164397239684,
          "independent_score_mean_max": -40.65913833618164,
          "interpretability_score_mean_max": -37.79615399599075
        },
        "matched_baseline_payload": {
          "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
          "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
          "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
          "total_rows": 200,
          "contrastive_score_mean_max": 50.51130743026734,
          "independent_score_mean_max": 50.99926634788513,
          "interpretability_score_mean_max": 47.951611585617066,
          "sae_release": "pythia-70m-deduped-res-sm",
          "sae_id": "blocks.0.hook_resid_pre",
          "date": "2026-02-13 18:59:31",
          "scores_dump_line_count": 200
        },
        "artifacts": {
          "cebench_metrics_summary_json": "results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed789/cebench/cebench_metrics_summary.json",
          "cebench_metrics_summary_md": "results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed789/cebench/cebench_metrics_summary.md"
        }
      },
      "saebench_returncode": 0,
      "cebench_returncode": 0
    },
    {
      "architecture": "routed_topk",
      "seed": 1011,
      "checkpoint": "results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed1011/sae_final.pt",
      "train_metrics": {
        "mse": 0.0005702368216589093,
        "explained_variance": 0.31261262089347064,
        "l0": 48.0,
        "routing_entropy": 2.079441547393799,
        "routing_balance_l2": 5.571659585257294e-06
      },
      "route_diagnostics": {
        "expert_usage": [
          0.12500007450580597,
          0.12499778717756271,
          0.12499929219484329,
          0.12500078976154327,
          0.12499980628490448,
          0.12499839812517166,
          0.12500466406345367,
          0.12499918788671494
        ],
        "num_experts": 8,
        "group_size_mean": 256.0
      },
      "saebench": {
        "timestamp_utc": "2026-02-16T13:34:29+00:00",
        "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed1011/sae_final.pt --architecture routed_topk --sae-release husai_run_20260216T132055Z_routed_topk_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle7_routed --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed1011/saebench --force-rerun --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom",
        "config": {
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed1011/sae_final.pt",
          "architecture_override": "routed_topk",
          "sae_release": "husai_run_20260216T132055Z_routed_topk_seed1011",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "reg_type": "l1",
          "setting": "normal",
          "ks": [
            1,
            2,
            5
          ],
          "dataset_names": [
            "100_news_fake",
            "105_click_bait",
            "106_hate_hate",
            "107_hate_offensive",
            "110_aimade_humangpt3",
            "113_movie_sent",
            "114_nyc_borough_Manhattan",
            "115_nyc_borough_Brooklyn",
            "116_nyc_borough_Bronx",
            "117_us_state_FL",
            "118_us_state_CA",
            "119_us_state_TX",
            "120_us_timezone_Chicago",
            "121_us_timezone_New_York",
            "122_us_timezone_Los_Angeles",
            "123_world_country_United_Kingdom"
          ],
          "dataset_names_inferred_from_cache": false,
          "dataset_count": 16,
          "binarize": false,
          "device": "cuda",
          "dtype": "float32",
          "results_path": "/tmp/husai_saebench_probe_results_cycle7_routed",
          "model_cache_path": "/tmp/sae_bench_model_cache",
          "force_rerun": true
        },
        "config_hash": "59bf65fbc4c6b4d36e7dae517d6c0ee595aa8ddfc4f9a58497c08c8659934a7a",
        "sae_meta": {
          "architecture": "routed_topk",
          "eval_architecture": "topk",
          "d_model": 512,
          "d_sae": 2048,
          "k": 48,
          "dead_features_repaired": 0,
          "decoder_norm_max_deviation": 1.1920928955078125e-07
        },
        "summary": {
          "result_key": "husai_run_20260216T132055Z_routed_topk_seed1011_custom_sae",
          "llm_metrics": {
            "llm_test_accuracy": 0.6605360072070458,
            "llm_test_auc": 0.6928164663947145,
            "llm_test_f1": 0.6491238078533221
          },
          "sae_metrics_by_k": [
            {
              "k": 1,
              "test_accuracy": 0.587354604104227,
              "test_auc": 0.5924430682725305,
              "test_f1": 0.5354053424853491
            },
            {
              "k": 2,
              "test_accuracy": 0.6025070338448335,
              "test_auc": 0.6226246530988723,
              "test_f1": 0.5607665784037765
            },
            {
              "k": 5,
              "test_accuracy": 0.6149124073869942,
              "test_auc": 0.6325312517271683,
              "test_f1": 0.5868387763436291
            }
          ],
          "best_by_auc": {
            "k": 5,
            "test_accuracy": 0.6149124073869942,
            "test_auc": 0.6325312517271683,
            "test_f1": 0.5868387763436291
          },
          "best_minus_llm_auc": -0.060285214667546216
        }
      },
      "cebench": {
        "timestamp_utc": "2026-02-16T13:36:48+00:00",
        "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed1011/sae_final.pt --architecture routed_topk --sae-release husai_run_20260216T132055Z_routed_topk_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle7_routed --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
        "config_hash": "5319218c9bc597c2b4d99b29e6353b09272bec93a765862290d758f3095d4e6f",
        "config": {
          "cebench_repo": "/workspace/CE-Bench",
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/checkpoints/routed_topk_seed1011/sae_final.pt",
          "architecture_override": "routed_topk",
          "checkpoint_sha256": "fadac5cac99725bf4d105eba305b90d21ad5021b26091d5a45c38a5b0ef176d7",
          "sae_release": "husai_run_20260216T132055Z_routed_topk_seed1011",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "device": "cuda",
          "sae_dtype": "float32",
          "llm_batch_size": 512,
          "llm_dtype": "float32",
          "random_seed": 42,
          "dataset_name": "GulkoA/contrastive-stories-v4",
          "dataset_rows_total": 5000,
          "dataset_rows_used": 200,
          "max_rows": 200,
          "output_folder": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed1011/cebench",
          "artifacts_path": "/tmp/ce_bench_artifacts_cycle7_routed",
          "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
        },
        "sae_meta": {
          "architecture": "routed_topk",
          "eval_architecture": "topk",
          "d_model": 512,
          "d_sae": 2048,
          "k": 48,
          "dead_features_repaired": 0,
          "decoder_norm_max_deviation": 1.1920928955078125e-07
        },
        "cebench_summary": {
          "output_folder": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed1011/cebench",
          "results_json": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed1011/cebench/interpretability_eval/husai_run_20260216T132055Z_routed_topk_seed1011/custom_sae/results.json",
          "scores_dump": "/workspace/HUSAI/results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed1011/cebench/scores_dump.txt",
          "total_rows": 200,
          "contrastive_score_mean_max": 10.073811500072479,
          "independent_score_mean_max": 10.735614266395569,
          "interpretability_score_mean_max": 10.506506028175354,
          "sae_release": "husai_run_20260216T132055Z_routed_topk_seed1011",
          "sae_id": "custom_sae",
          "date": "2026-02-16 13:36:48",
          "scores_dump_line_count": 200
        },
        "custom_metrics": {
          "contrastive_score_mean_max": 10.073811500072479,
          "independent_score_mean_max": 10.735614266395569,
          "interpretability_score_mean_max": 10.506506028175354
        },
        "matched_baseline_metrics": {
          "contrastive_score_mean_max": 50.51130743026734,
          "independent_score_mean_max": 50.99926634788513,
          "interpretability_score_mean_max": 47.951611585617066
        },
        "delta_vs_matched_baseline": {
          "contrastive_score_mean_max": -40.437495930194856,
          "independent_score_mean_max": -40.26365208148957,
          "interpretability_score_mean_max": -37.445105557441714
        },
        "matched_baseline_payload": {
          "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
          "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
          "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
          "total_rows": 200,
          "contrastive_score_mean_max": 50.51130743026734,
          "independent_score_mean_max": 50.99926634788513,
          "interpretability_score_mean_max": 47.951611585617066,
          "sae_release": "pythia-70m-deduped-res-sm",
          "sae_id": "blocks.0.hook_resid_pre",
          "date": "2026-02-13 18:59:31",
          "scores_dump_line_count": 200
        },
        "artifacts": {
          "cebench_metrics_summary_json": "results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed1011/cebench/cebench_metrics_summary.json",
          "cebench_metrics_summary_md": "results/experiments/phase4b_routed_frontier_external_sweep_cycle7_pareto/run_20260216T132055Z/external_eval/routed_topk_seed1011/cebench/cebench_metrics_summary.md"
        }
      },
      "saebench_returncode": 0,
      "cebench_returncode": 0
    }
  ],
  "aggregate": {
    "train_mse": {
      "mean": 0.0005351302097551525,
      "std": 3.141349423974662e-05,
      "min": 0.000500905909575522,
      "max": 0.0005702368216589093,
      "n": 5
    },
    "train_ev": {
      "mean": 0.3549313365572761,
      "std": 0.03786690169972916,
      "min": 0.31261262089347064,
      "max": 0.3961866997869127,
      "n": 5
    },
    "train_l0": {
      "mean": 48.0,
      "std": 0.0,
      "min": 48.0,
      "max": 48.0,
      "n": 5
    },
    "routing_entropy": {
      "mean": 2.0794414043426515,
      "std": 2.132480599880018e-07,
      "min": 2.0794410705566406,
      "max": 2.079441547393799,
      "n": 5
    },
    "routing_balance_l2": {
      "mean": 1.294388557653292e-05,
      "std": 1.0084866914667934e-05,
      "min": 5.1881670515285805e-06,
      "max": 2.923782631114591e-05,
      "n": 5
    },
    "saebench_best_minus_llm_auc": {
      "mean": -0.0716435016559764,
      "std": 0.016227724812969056,
      "min": -0.0920562877190999,
      "max": -0.050730537707649015,
      "n": 5
    },
    "cebench_interpretability_max": {
      "mean": 10.594750912189483,
      "std": 0.8371466163898862,
      "min": 9.508990712165833,
      "max": 11.64863579273224,
      "n": 5
    },
    "cebench_interp_delta_vs_baseline": {
      "mean": -37.35686067342758,
      "std": 0.8371466163898871,
      "min": -38.44262087345123,
      "max": -36.30297579288482,
      "n": 5
    }
  }
}
