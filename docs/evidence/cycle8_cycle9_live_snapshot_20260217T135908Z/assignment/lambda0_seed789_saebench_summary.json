{
  "timestamp_utc": "2026-02-17T13:52:30+00:00",
  "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
  "config": {
    "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt",
    "architecture_override": "topk",
    "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed789",
    "model_name": "pythia-70m-deduped",
    "hook_layer": 0,
    "hook_name": "blocks.0.hook_resid_pre",
    "reg_type": "l1",
    "setting": "normal",
    "ks": [
      1,
      2,
      5
    ],
    "dataset_names": [
      "100_news_fake",
      "105_click_bait",
      "106_hate_hate",
      "107_hate_offensive",
      "110_aimade_humangpt3",
      "113_movie_sent",
      "114_nyc_borough_Manhattan",
      "115_nyc_borough_Brooklyn",
      "116_nyc_borough_Bronx",
      "117_us_state_FL",
      "118_us_state_CA",
      "119_us_state_TX",
      "120_us_timezone_Chicago",
      "121_us_timezone_New_York",
      "122_us_timezone_Los_Angeles",
      "123_world_country_United_Kingdom"
    ],
    "dataset_names_inferred_from_cache": false,
    "dataset_count": 16,
    "binarize": false,
    "device": "cuda",
    "dtype": "float32",
    "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
    "model_cache_path": "/tmp/sae_bench_model_cache",
    "force_rerun": true
  },
  "config_hash": "dabf1952126fd34801d502577b7f5b2aedd0752e3ecf2ae26b6a7f124daf4ff1",
  "sae_meta": {
    "architecture": "topk",
    "eval_architecture": "topk",
    "d_model": 512,
    "d_sae": 3072,
    "k": 48,
    "dead_features_repaired": 0,
    "decoder_norm_max_deviation": 1.1920928955078125e-07
  },
  "summary": {
    "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed789_custom_sae",
    "llm_metrics": {
      "llm_test_accuracy": 0.6605360072070458,
      "llm_test_auc": 0.6928164663947145,
      "llm_test_f1": 0.6491238078533221
    },
    "sae_metrics_by_k": [
      {
        "k": 1,
        "test_accuracy": 0.5813078403928299,
        "test_auc": 0.5910117571295512,
        "test_f1": 0.49264823545271164
      },
      {
        "k": 2,
        "test_accuracy": 0.5804280390427752,
        "test_auc": 0.6059040932864593,
        "test_f1": 0.5129210078643981
      },
      {
        "k": 5,
        "test_accuracy": 0.5902378746011774,
        "test_auc": 0.6180760062642267,
        "test_f1": 0.5388127078496961
      }
    ],
    "best_by_auc": {
      "k": 5,
      "test_accuracy": 0.5902378746011774,
      "test_auc": 0.6180760062642267,
      "test_f1": 0.5388127078496961
    },
    "best_minus_llm_auc": -0.07474046013048785
  }
}
