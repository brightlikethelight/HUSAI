{
  "run_metadata": {
    "timestamp_utc": "2026-02-17T15:11:08+00:00",
    "git_commit": "d1ac12d98d9d3f4ff96101cb16d6f54543be55ad",
    "command": "python scripts/experiments/run_assignment_consistency_v3.py --activation-cache-dir /tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped --activation-glob *_blocks.0.hook_resid_pre.pt --max-files 80 --max-rows-per-file 2048 --max-total-rows 150000 --d-sae 3072 --k 48 --device cuda --epochs 24 --batch-size 4096 --learning-rate 0.0004 --train-seeds 123,456,789,1011 --lambdas 0.0,0.03,0.05,0.08,0.1,0.15,0.2 --run-saebench --run-cebench --cebench-repo /workspace/CE-Bench --cebench-max-rows 200 --cebench-matched-baseline-summary docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json --saebench-datasets 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --saebench-results-path /tmp/husai_saebench_probe_results_cycle8_assignment --saebench-model-cache-path /tmp/sae_bench_model_cache --cebench-artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --external-checkpoint-policy external_score --external-checkpoint-candidates-per-lambda 4 --external-candidate-require-both --external-candidate-min-saebench-delta -0.04 --external-candidate-min-cebench-delta -35.5 --external-candidate-weight-saebench 0.75 --external-candidate-weight-cebench 0.15 --external-candidate-weight-alignment 0.05 --external-candidate-weight-ev 0.05 --weight-internal-lcb 0.20 --weight-ev 0.05 --weight-saebench 0.55 --weight-cebench 0.20 --force-rerun-external --require-external --min-saebench-delta -0.02 --min-cebench-delta -35.5 --output-dir results/experiments/phase4d_assignment_consistency_v3_cycle8_robust",
    "config_hash": "39ce382d0f34ac8b10e344e786dd07b557e5edd011f590f4abd89fe18a52c22b",
    "run_id": "run_20260217T111709Z"
  },
  "config": {
    "transformer_checkpoint": "/workspace/HUSAI/results/transformer_5000ep/transformer_best.pt",
    "activation_cache": "/workspace/HUSAI/results/cache/assignment_consistency_v3/layer1_answer_acts.pt",
    "activation_source": {
      "source": "external_cache",
      "activation_cache_dir": "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped",
      "activation_glob": "*_blocks.0.hook_resid_pre.pt",
      "max_files": 80,
      "max_rows_per_file": 2048,
      "max_total_rows": 150000,
      "source_cache_seed": 42,
      "data_meta": {
        "num_files_discovered": 113,
        "num_files_used": 80,
        "total_rows": 144042,
        "d_model": 512
      },
      "source_files": [
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/100_news_fake_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/105_click_bait_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/106_hate_hate_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/107_hate_offensive_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/110_aimade_humangpt3_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/113_movie_sent_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/114_nyc_borough_Manhattan_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/115_nyc_borough_Brooklyn_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/116_nyc_borough_Bronx_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/117_us_state_FL_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/118_us_state_CA_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/119_us_state_TX_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/120_us_timezone_Chicago_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/121_us_timezone_New_York_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/122_us_timezone_Los_Angeles_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/123_world_country_United_Kingdom_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/124_world_country_United_States_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/125_world_country_Italy_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/126_art_type_book_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/127_art_type_song_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/128_art_type_movie_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/129_arith_mc_A_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/130_temp_cat_Frequency_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/131_temp_cat_Typical Time_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/132_temp_cat_Event Ordering_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/133_context_type_Causality_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/134_context_type_Belief_states_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/135_context_type_Event_duration_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/136_glue_mnli_entailment_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/137_glue_mnli_neutral_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/138_glue_mnli_contradiction_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/139_news_class_Politics_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/140_news_class_Technology_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/141_news_class_Entertainment_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/142_cancer_cat_Thyroid_Cancer_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/143_cancer_cat_Lung_Cancer_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/144_cancer_cat_Colon_Cancer_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/145_disease_class_digestive system diseases_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/146_disease_class_cardiovascular diseases_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/147_disease_class_nervous system diseases_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/148_twt_emotion_worry_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/149_twt_emotion_happiness_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/150_twt_emotion_sadness_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/151_it_tick_HR Support_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/152_it_tick_Hardware_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/153_it_tick_Administrative rights_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/154_athlete_sport_football_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/155_athlete_sport_basketball_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/156_athlete_sport_baseball_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/157_amazon_5star_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/158_code_C_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/159_code_Python_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/160_code_HTML_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/161_agnews_0_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/162_agnews_1_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/163_agnews_2_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/21_headline_istrump_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/22_headline_isobama_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/23_headline_ischina_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/24_headline_isiran_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/26_headline_isfrontpage_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/36_sciq_tf_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/41_truthqa_tf_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/42_temp_sense_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/44_phys_tf_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/47_reasoning_tf_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/48_cm_correct_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/49_cm_isshort_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/50_deon_isvalid_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/51_just_is_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/52_virtue_is_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/54_cs_tf_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/56_wikidatasex_or_gender_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/57_wikidatais_alive_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/58_wikidatapolitical_party_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/59_wikidata_occupation_isjournalist_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/5_hist_fig_ismale_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/60_wikidata_occupation_isathlete_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/61_wikidata_occupation_isactor_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/62_wikidata_occupation_ispolitician_blocks.0.hook_resid_pre.pt"
      ]
    },
    "layer": 1,
    "modulus": 113,
    "seed_ref": 42,
    "train_seeds": [
      123,
      456,
      789,
      1011
    ],
    "lambdas": [
      0.0,
      0.03,
      0.05,
      0.08,
      0.1,
      0.15,
      0.2
    ],
    "d_sae": 3072,
    "k": 48,
    "epochs": 24,
    "batch_size": 4096,
    "learning_rate": 0.0004,
    "assignment_update_interval": 1,
    "supervised_proxy_mode": "none",
    "supervised_proxy_weight": 0.0,
    "supervised_proxy_num_classes": 0,
    "supervised_proxy_meta": null,
    "device": "cuda",
    "bootstrap_samples": 10000,
    "run_saebench": true,
    "run_cebench": true,
    "cebench_repo": "/workspace/CE-Bench",
    "cebench_max_rows": 200,
    "cebench_matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
    "saebench_datasets": [
      "100_news_fake",
      "105_click_bait",
      "106_hate_hate",
      "107_hate_offensive",
      "110_aimade_humangpt3",
      "113_movie_sent",
      "114_nyc_borough_Manhattan",
      "115_nyc_borough_Brooklyn",
      "116_nyc_borough_Bronx",
      "117_us_state_FL",
      "118_us_state_CA",
      "119_us_state_TX",
      "120_us_timezone_Chicago",
      "121_us_timezone_New_York",
      "122_us_timezone_Los_Angeles",
      "123_world_country_United_Kingdom"
    ],
    "model_name": "pythia-70m-deduped",
    "hook_layer": 0,
    "hook_name": "blocks.0.hook_resid_pre",
    "dtype": "float32",
    "external_checkpoint_policy": "external_score",
    "external_checkpoint_candidates_per_lambda": 4,
    "external_checkpoint_include_ref": false,
    "external_candidate_require_both": true,
    "external_candidate_thresholds": {
      "min_saebench_delta": -0.04,
      "min_cebench_delta": -35.5
    },
    "weights": {
      "internal_lcb": 0.2,
      "ev_neg_drop": 0.05,
      "saebench_delta": 0.55,
      "cebench_delta": 0.2
    },
    "external_checkpoint_weights": {
      "saebench": 0.75,
      "cebench": 0.15,
      "alignment": 0.05,
      "explained_variance": 0.05
    }
  },
  "records": [
    {
      "lambda_consistency": 0.0,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.18844734728336335,
        "std": 0.0003059837005938743,
        "min": 0.18794596940279007,
        "max": 0.18887364864349365,
        "median": 0.1885439231991768,
        "ci95_low": 0.18826177448034287,
        "ci95_high": 0.18862040981650355,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.024422124773263942,
      "delta_pwmcc_ci_low_conservative": 0.024064482245594265,
      "ratio_pwmcc": 1.1488924959194018,
      "explained_variance": {
        "mean": 0.8527127146720886,
        "std": 0.00029619645172861494,
        "min": 0.8522933721542358,
        "max": 0.8531134128570557,
        "median": 0.8526833057403564,
        "ci95_low": 0.8524707198143006,
        "ci95_high": 0.8529362440109253,
        "n": 5
      },
      "mse": {
        "mean": 0.00012218514020787553,
        "std": 2.457315501250927e-07,
        "min": 0.00012185269588371739,
        "max": 0.00012253301974851638,
        "median": 0.00012220953067298979,
        "ci95_low": 0.00012199542979942634,
        "ci95_high": 0.00012238164199516178,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.17893202230334282,
        "std": 0.00025345869798676964,
        "min": 0.17862744629383087,
        "max": 0.17914609611034393,
        "median": 0.17897727340459824,
        "ci95_low": 0.1787232756614685,
        "ci95_high": 0.17914076894521713,
        "n": 4
      },
      "runtime_sec": 130.26984858512878,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.17862744629383087,
          "mse": 0.00012209962005726993,
          "explained_variance": 0.8528158068656921,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.17913544178009033,
          "mse": 0.00012220953067298979,
          "explained_variance": 0.8526833057403564,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.17881910502910614,
          "mse": 0.00012253301974851638,
          "explained_variance": 0.8522933721542358,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.17914609611034393,
          "mse": 0.00012223083467688411,
          "explained_variance": 0.852657675743103,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.18794596940279007,
        0.18825341761112213,
        0.18811380118131638,
        0.1886357069015503,
        0.18847618252038956,
        0.18817367404699326,
        0.18861166387796402,
        0.1887010708451271,
        0.18868833780288696,
        0.18887364864349365
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
      "selected_checkpoint_seed": 456,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
          "alignment_to_ref": 0.17913544178009033,
          "explained_variance": 0.8526833057403564,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T13:49:43+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "cf080d6390d2ad3f2e25945fb5827bb778fa0ad5d2cf8c3f26b44bc7e39d6083",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5922339463042303,
                    "test_auc": 0.5977728124763309,
                    "test_f1": 0.513670665689709
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5939358844384306,
                    "test_auc": 0.6044448816311556,
                    "test_f1": 0.5224244083386272
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.5990433882190835,
                    "test_auc": 0.6216382091990383,
                    "test_f1": 0.5512589180003198
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.5990433882190835,
                  "test_auc": 0.6216382091990383,
                  "test_f1": 0.5512589180003198
                },
                "best_minus_llm_auc": -0.07117825719567616
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T13:51:53+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "06b88d0f2f18c557770a146ecb8e2d83967709b413840f8445e09e42f34ce1b4",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "11a07de24fcf49207b4de552f9a2ef897603f80e1ef3d2b58099257f877e0a85",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.0_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 10.196092100143433,
                "independent_score_mean_max": 10.429015238285064,
                "interpretability_score_mean_max": 10.441005325317382,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 13:51:53",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 10.196092100143433,
                "independent_score_mean_max": 10.429015238285064,
                "interpretability_score_mean_max": 10.441005325317382
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -40.315215330123905,
                "independent_score_mean_max": -40.570251109600065,
                "interpretability_score_mean_max": -37.51060626029968
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.07117825719567616,
          "cebench_delta": -37.51060626029968,
          "cebench_interpretability_max": 10.441005325317382,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9172841854463769,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.5399495019351912,
              "alignment": 0.9794575647876803,
              "explained_variance": 0.746377638334284
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt",
          "alignment_to_ref": 0.17881910502910614,
          "explained_variance": 0.8522933721542358,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T13:52:30+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "dabf1952126fd34801d502577b7f5b2aedd0752e3ecf2ae26b6a7f124daf4ff1",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5813078403928299,
                    "test_auc": 0.5910117571295512,
                    "test_f1": 0.49264823545271164
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5804280390427752,
                    "test_auc": 0.6059040932864593,
                    "test_f1": 0.5129210078643981
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.5902378746011774,
                    "test_auc": 0.6180760062642267,
                    "test_f1": 0.5388127078496961
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.5902378746011774,
                  "test_auc": 0.6180760062642267,
                  "test_f1": 0.5388127078496961
                },
                "best_minus_llm_auc": -0.07474046013048785
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T13:54:55+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "889c7e6e11e80271a57fe5a0a579fc83d19f9ee3d2bc7351e314f3273daf94e3",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "f10967e9f0e131861579845b90183a4cd6658ebb5f950c479d914e580b7fd64a",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.0_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 10.361549708843231,
                "independent_score_mean_max": 10.78331934928894,
                "interpretability_score_mean_max": 10.674233231544495,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 13:54:55",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 10.361549708843231,
                "independent_score_mean_max": 10.78331934928894,
                "interpretability_score_mean_max": 10.674233231544495
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -40.14975772142411,
                "independent_score_mean_max": -40.215946998596195,
                "interpretability_score_mean_max": -37.27737835407257
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.07474046013048785,
          "cebench_delta": -37.27737835407257,
          "cebench_interpretability_max": 10.674233231544495,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.5896514948808999,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.5615663939483461,
              "cebench": 1.0,
              "alignment": 0.3695339883928058,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt",
          "alignment_to_ref": 0.17914609611034393,
          "explained_variance": 0.852657675743103,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T13:46:42+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "acd3f245f48d0a140e64700576a688bdcbf8e10e8769973c24c9332b8234bcb5",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5704222937912591,
                    "test_auc": 0.5759697473068347,
                    "test_f1": 0.4755615746549608
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5869041249394854,
                    "test_auc": 0.6080147834373766,
                    "test_f1": 0.5204035619485314
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.598790133810647,
                    "test_auc": 0.6182154097797055,
                    "test_f1": 0.5422254688402578
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.598790133810647,
                  "test_auc": 0.6182154097797055,
                  "test_f1": 0.5422254688402578
                },
                "best_minus_llm_auc": -0.07460105661500904
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T13:49:06+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "7c9ca32c42ff6e3b266995da4b58a7199686291e5fe60ed966fe13fd887d17cd",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "8639d97807bff9b8fcbe6a3e6ae2159fc1f33cafc1c31f46d6b5eb8969b451b4",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.877204098701476,
                "independent_score_mean_max": 11.0145872092247,
                "interpretability_score_mean_max": 10.16727169752121,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 13:49:06",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.877204098701476,
                "independent_score_mean_max": 11.0145872092247,
                "interpretability_score_mean_max": 10.16727169752121
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -40.63410333156586,
                "independent_score_mean_max": -39.98467913866043,
                "interpretability_score_mean_max": -37.78433988809586
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.07460105661500904,
          "cebench_delta": -37.78433988809586,
          "cebench_interpretability_max": 10.16727169752121,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.5189090096499562,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.5787240874054941,
              "cebench": 0.0,
              "alignment": 1.0,
              "explained_variance": 0.6973188819167142
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt",
          "alignment_to_ref": 0.17862744629383087,
          "explained_variance": 0.8528158068656921,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T13:55:33+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "333a0757af9a572d88217bf513073c02c9499907e9b0bbef4f16bad0c405d0ae",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5844798733918964,
                    "test_auc": 0.5879168889685746,
                    "test_f1": 0.5085568718667245
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5917775648840801,
                    "test_auc": 0.5961223460293172,
                    "test_f1": 0.5254993035676552
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.5978387803822386,
                    "test_auc": 0.6135133691191654,
                    "test_f1": 0.5527361780240143
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.5978387803822386,
                  "test_auc": 0.6135133691191654,
                  "test_f1": 0.5527361780240143
                },
                "best_minus_llm_auc": -0.07930309727554907
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T13:57:59+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "2b1c9f207a8583f6bc3aa028ece6cde940459abb7e10e89b6b8b92de51f593cd",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "d7f2012fdda5cd84a5f892f20c9d7af72d9c4604c0341614dc8e09dfa4e95aae",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.0_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 10.35431608915329,
                "independent_score_mean_max": 10.762057542800903,
                "interpretability_score_mean_max": 10.65065663099289,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 13:57:59",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 10.35431608915329,
                "independent_score_mean_max": 10.762057542800903,
                "interpretability_score_mean_max": 10.65065663099289
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -40.15699134111405,
                "independent_score_mean_max": -40.23720880508423,
                "interpretability_score_mean_max": -37.300954954624174
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.07930309727554907,
          "cebench_delta": -37.300954954624174,
          "cebench_interpretability_max": 10.65065663099289,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.19302414513646599,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.9534943009097732,
              "alignment": 0.0,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
        "candidate_tag": "seed456",
        "saebench": {
          "timestamp_utc": "2026-02-17T13:49:43+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "cf080d6390d2ad3f2e25945fb5827bb778fa0ad5d2cf8c3f26b44bc7e39d6083",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.5922339463042303,
                "test_auc": 0.5977728124763309,
                "test_f1": 0.513670665689709
              },
              {
                "k": 2,
                "test_accuracy": 0.5939358844384306,
                "test_auc": 0.6044448816311556,
                "test_f1": 0.5224244083386272
              },
              {
                "k": 5,
                "test_accuracy": 0.5990433882190835,
                "test_auc": 0.6216382091990383,
                "test_f1": 0.5512589180003198
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.5990433882190835,
              "test_auc": 0.6216382091990383,
              "test_f1": 0.5512589180003198
            },
            "best_minus_llm_auc": -0.07117825719567616
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T13:51:53+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "06b88d0f2f18c557770a146ecb8e2d83967709b413840f8445e09e42f34ce1b4",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "11a07de24fcf49207b4de552f9a2ef897603f80e1ef3d2b58099257f877e0a85",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.0_seed456/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 10.196092100143433,
            "independent_score_mean_max": 10.429015238285064,
            "interpretability_score_mean_max": 10.441005325317382,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456",
            "sae_id": "custom_sae",
            "date": "2026-02-17 13:51:53",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 10.196092100143433,
            "independent_score_mean_max": 10.429015238285064,
            "interpretability_score_mean_max": 10.441005325317382
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -40.315215330123905,
            "independent_score_mean_max": -40.570251109600065,
            "interpretability_score_mean_max": -37.51060626029968
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.024064482245594265,
        "ev_drop": 0.0,
        "ev_neg_drop": -0.0,
        "saebench_delta": -0.07117825719567616,
        "cebench_delta": -37.51060626029968,
        "cebench_interpretability_max": 10.441005325317382
      },
      "selection": {
        "joint_score": 0.05,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    },
    {
      "lambda_consistency": 0.03,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9978271931409836,
        "std": 0.0006739460976970869,
        "min": 0.9972622096538544,
        "max": 0.998632937669754,
        "median": 0.9973331391811371,
        "ci95_low": 0.9974357336759567,
        "ci95_high": 0.9982214707136153,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.8338019706308841,
      "delta_pwmcc_ci_low_conservative": 0.8332384414412082,
      "ratio_pwmcc": 6.083376555575439,
      "explained_variance": {
        "mean": 0.6137382864952088,
        "std": 0.13381697521634336,
        "min": 0.5529702305793762,
        "max": 0.8531134128570557,
        "median": 0.553804874420166,
        "ci95_low": 0.553428053855896,
        "ci95_high": 0.7334831833839417,
        "n": 5
      },
      "mse": {
        "mean": 0.0003204313092282973,
        "std": 0.00011101065404439031,
        "min": 0.00012185269588371739,
        "max": 0.00037084275390952826,
        "median": 0.0003701501991599798,
        "ci95_low": 0.00022109446726972237,
        "ci95_high": 0.00037046290235593916,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9986097514629364,
        "std": 1.8901878731606503e-05,
        "min": 0.9985896944999695,
        "max": 0.9986329078674316,
        "median": 0.9986082017421722,
        "ci95_low": 0.9985949397087097,
        "ci95_high": 0.9986247271299362,
        "n": 4
      },
      "runtime_sec": 1431.7777667045593,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt",
          "lambda_consistency": 0.03,
          "alignment_to_ref": 0.9985896944999695,
          "mse": 0.00036907149478793144,
          "explained_variance": 0.555105447769165,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9091940732431356,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
          "lambda_consistency": 0.03,
          "alignment_to_ref": 0.9986162185668945,
          "mse": 0.00037084275390952826,
          "explained_variance": 0.5529702305793762,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9091687868866656,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt",
          "lambda_consistency": 0.03,
          "alignment_to_ref": 0.9986329078674316,
          "mse": 0.0003702394024003297,
          "explained_variance": 0.5536974668502808,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9092401030852839,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt",
          "lambda_consistency": 0.03,
          "alignment_to_ref": 0.99860018491745,
          "mse": 0.0003701501991599798,
          "explained_variance": 0.553804874420166,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9092095805745986,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9985897541046143,
        0.9986162185668945,
        0.998632937669754,
        0.99860018491745,
        0.9973362684249878,
        0.9973001182079315,
        0.9972622096538544,
        0.9973300099372864,
        0.997287929058075,
        0.997316300868988
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
      "selected_checkpoint_seed": 456,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
          "alignment_to_ref": 0.9986162185668945,
          "explained_variance": 0.5529702305793762,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:01:38+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "f6f5f2d8d0cd0d8f9e058c249e76fb8e968a3f73ac94aa7f3172758cd8fe1986",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5894021379898293,
                    "test_auc": 0.6041184861654619,
                    "test_f1": 0.5498710508381413
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5984883739823331,
                    "test_auc": 0.6151961788330417,
                    "test_f1": 0.5603444631865563
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.622710819433242,
                    "test_auc": 0.6434387555393835,
                    "test_f1": 0.6054708336806258
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.622710819433242,
                  "test_auc": 0.6434387555393835,
                  "test_f1": 0.6054708336806258
                },
                "best_minus_llm_auc": -0.04937771085533105
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:04:31+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "bc30efca5430344f341c2bdc9b02cd2924e67ea0f35f959b383239dcdac6b808",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "8b2f1900460b956886cb4a8bf160b1c347bd2e10d4bb90c4e995664d2ca82904",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.03_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.624090700149535,
                "independent_score_mean_max": 15.732642364501952,
                "interpretability_score_mean_max": 14.12977129459381,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:04:31",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.624090700149535,
                "independent_score_mean_max": 15.732642364501952,
                "interpretability_score_mean_max": 14.12977129459381
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.8872167301178,
                "independent_score_mean_max": -35.266623983383184,
                "interpretability_score_mean_max": -33.82184029102326
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04937771085533105,
          "cebench_delta": -33.82184029102326,
          "cebench_interpretability_max": 14.12977129459381,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8639712255756447,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.5552104693548718,
              "alignment": 0.6137931034482759,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt",
          "alignment_to_ref": 0.99860018491745,
          "explained_variance": 0.553804874420166,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:05:06+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "49f2139ee60ada7f85a4780374f6f9fbf423a90714e36f1d4c6fc2119edcceda",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.599030064376878,
                    "test_auc": 0.6085647594940361,
                    "test_f1": 0.5528062786696007
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6128467688667418,
                    "test_auc": 0.6302196507820805,
                    "test_f1": 0.5894119791327191
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6190131699376694,
                    "test_auc": 0.6410805881005667,
                    "test_f1": 0.6036582437167475
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6190131699376694,
                  "test_auc": 0.6410805881005667,
                  "test_f1": 0.6036582437167475
                },
                "best_minus_llm_auc": -0.05173587829414783
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:07:26+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "30d1f69c0fb022872713ac4f3b33282c52748b8a37ecab72ae78c74da2f7a044",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "d435a6c9b9a88f1b84153de0462330aa0333f22e078df378336f3f4dc7a65bbd",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.02915442466736,
                "independent_score_mean_max": 15.24943531036377,
                "interpretability_score_mean_max": 13.719969158172608,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:07:26",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.02915442466736,
                "independent_score_mean_max": 15.24943531036377,
                "interpretability_score_mean_max": 13.719969158172608
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.482153005599976,
                "independent_score_mean_max": -35.74983103752136,
                "interpretability_score_mean_max": -34.231642427444456
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05173587829414783,
          "cebench_delta": -34.231642427444456,
          "cebench_interpretability_max": 13.719969158172608,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6104065996361289,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.7716319502486025,
              "cebench": 0.0,
              "alignment": 0.24275862068965517,
              "explained_variance": 0.390894118303883
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt",
          "alignment_to_ref": 0.9985896944999695,
          "explained_variance": 0.555105447769165,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:08:00+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "67ce7fb4a5cdd8c31f95895ba0837437b3b21033a771280eab45ad04df4a367d",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5755048683417479,
                    "test_auc": 0.5798039493835621,
                    "test_f1": 0.5359674936844536
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5923725598616915,
                    "test_auc": 0.6194176905019874,
                    "test_f1": 0.5675971476136623
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6152991094073653,
                    "test_auc": 0.6357177802286724,
                    "test_f1": 0.5843968326969083
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6152991094073653,
                  "test_auc": 0.6357177802286724,
                  "test_f1": 0.5843968326969083
                },
                "best_minus_llm_auc": -0.05709868616604208
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:10:01+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "7641e68540aad135706ee63f07bb2269836aa0e3d2ab7989d0a3454ec0d374d7",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "469ec2dd0489f3481a662a1823a1004349b663472d10857ea7bc4d98fdca4cc6",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.03_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 15.085028817653656,
                "independent_score_mean_max": 16.178657956123352,
                "interpretability_score_mean_max": 14.458071479797363,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:10:01",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 15.085028817653656,
                "independent_score_mean_max": 16.178657956123352,
                "interpretability_score_mean_max": 14.458071479797363
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.42627861261368,
                "independent_score_mean_max": -34.82060839176178,
                "interpretability_score_mean_max": -33.493540105819704
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05709868616604208,
          "cebench_delta": -33.493540105819704,
          "cebench_interpretability_max": 14.458071479797363,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.3892179140265573,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.2522905520354098,
              "cebench": 1.0,
              "alignment": 0.0,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt",
          "alignment_to_ref": 0.9986329078674316,
          "explained_variance": 0.5536974668502808,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T13:58:33+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "316aee73acf2010d68edefd109a6cb7406f514c978079559808417a38f5f71c0",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5892651752726169,
                    "test_auc": 0.6071717086300038,
                    "test_f1": 0.5472773606127306
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6075098526371968,
                    "test_auc": 0.6278448729043701,
                    "test_f1": 0.5750274170193598
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6082202142364151,
                    "test_auc": 0.6331125849503545,
                    "test_f1": 0.5870829717832178
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6082202142364151,
                  "test_auc": 0.6331125849503545,
                  "test_f1": 0.5870829717832178
                },
                "best_minus_llm_auc": -0.05970388144436001
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:01:02+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "42cb60f6e7dfbfa0ac8afa91db4c93b7acd505fd423582c64b0c45eacf65fd61",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "ce4452af4b791ec9db9845e612cf755aad04bd6ed729ed0fefb3b33e958a0b55",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.03_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.651202373504638,
                "independent_score_mean_max": 15.845165600776673,
                "interpretability_score_mean_max": 13.908076062202454,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:01:02",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.651202373504638,
                "independent_score_mean_max": 15.845165600776673,
                "interpretability_score_mean_max": 13.908076062202454
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.8601050567627,
                "independent_score_mean_max": -35.15410074710846,
                "interpretability_score_mean_max": -34.04353552341461
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05970388144436001,
          "cebench_delta": -34.04353552341461,
          "cebench_interpretability_max": 13.908076062202454,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.10525737240998803,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.2548520693117087,
              "alignment": 1.0,
              "explained_variance": 0.34059124026463444
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
        "candidate_tag": "seed456",
        "saebench": {
          "timestamp_utc": "2026-02-17T14:01:38+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "f6f5f2d8d0cd0d8f9e058c249e76fb8e968a3f73ac94aa7f3172758cd8fe1986",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.5894021379898293,
                "test_auc": 0.6041184861654619,
                "test_f1": 0.5498710508381413
              },
              {
                "k": 2,
                "test_accuracy": 0.5984883739823331,
                "test_auc": 0.6151961788330417,
                "test_f1": 0.5603444631865563
              },
              {
                "k": 5,
                "test_accuracy": 0.622710819433242,
                "test_auc": 0.6434387555393835,
                "test_f1": 0.6054708336806258
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.622710819433242,
              "test_auc": 0.6434387555393835,
              "test_f1": 0.6054708336806258
            },
            "best_minus_llm_auc": -0.04937771085533105
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T14:04:31+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "bc30efca5430344f341c2bdc9b02cd2924e67ea0f35f959b383239dcdac6b808",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "8b2f1900460b956886cb4a8bf160b1c347bd2e10d4bb90c4e995664d2ca82904",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.03_seed456/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 14.624090700149535,
            "independent_score_mean_max": 15.732642364501952,
            "interpretability_score_mean_max": 14.12977129459381,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456",
            "sae_id": "custom_sae",
            "date": "2026-02-17 14:04:31",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 14.624090700149535,
            "independent_score_mean_max": 15.732642364501952,
            "interpretability_score_mean_max": 14.12977129459381
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -35.8872167301178,
            "independent_score_mean_max": -35.266623983383184,
            "interpretability_score_mean_max": -33.82184029102326
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8332384414412082,
        "ev_drop": 0.23897442817687986,
        "ev_neg_drop": -0.23897442817687986,
        "saebench_delta": -0.04937771085533105,
        "cebench_delta": -33.82184029102326,
        "cebench_interpretability_max": 14.12977129459381
      },
      "selection": {
        "joint_score": 0.8404448355747316,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    },
    {
      "lambda_consistency": 0.05,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9986905753612518,
        "std": 0.0004090263797073315,
        "min": 0.9983469843864441,
        "max": 0.9991788864135742,
        "median": 0.998396247625351,
        "ci95_low": 0.9984527111053467,
        "ci95_high": 0.9989304366707802,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.8346653528511524,
      "delta_pwmcc_ci_low_conservative": 0.8342554188705982,
      "ratio_pwmcc": 6.088640271771375,
      "explained_variance": {
        "mean": 0.5981857657432557,
        "std": 0.14251887039387154,
        "min": 0.5322084426879883,
        "max": 0.8531134128570557,
        "median": 0.5345327854156494,
        "ci95_low": 0.5334399938583374,
        "ci95_high": 0.7256995439529419,
        "n": 5
      },
      "mse": {
        "mean": 0.0003333334097987972,
        "std": 0.00011822959124170233,
        "min": 0.00012185269588371739,
        "max": 0.000388066255254671,
        "median": 0.000386137719033286,
        "ci95_low": 0.00022755175159545616,
        "ci95_high": 0.00038704443140886725,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.999165415763855,
        "std": 1.5007513714984594e-05,
        "min": 0.9991464018821716,
        "max": 0.9991788864135742,
        "median": 0.999168187379837,
        "ci95_low": 0.9991534650325775,
        "ci95_high": 0.9991773664951324,
        "n": 4
      },
      "runtime_sec": 1447.2789540290833,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt",
          "lambda_consistency": 0.05,
          "alignment_to_ref": 0.9991605281829834,
          "mse": 0.0003841344150714576,
          "explained_variance": 0.5369490385055542,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9114554998188935,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
          "lambda_consistency": 0.05,
          "alignment_to_ref": 0.9991758465766907,
          "mse": 0.000388066255254671,
          "explained_variance": 0.5322084426879883,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9114441092264045,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt",
          "lambda_consistency": 0.05,
          "alignment_to_ref": 0.9991788864135742,
          "mse": 0.00038647596375085413,
          "explained_variance": 0.5341251492500305,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9114961447366686,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt",
          "lambda_consistency": 0.05,
          "alignment_to_ref": 0.9991464018821716,
          "mse": 0.000386137719033286,
          "explained_variance": 0.5345327854156494,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.911461247217462,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9991605281829834,
        0.9991758465766907,
        0.9991788864135742,
        0.9991463422775269,
        0.998396098613739,
        0.9983784556388855,
        0.9983469843864441,
        0.9983963966369629,
        0.9983612895011902,
        0.9983649253845215
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
      "selected_checkpoint_seed": 456,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
          "alignment_to_ref": 0.9991758465766907,
          "explained_variance": 0.5322084426879883,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:13:38+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "4773e30e98f44ee609650551de315061ab3dd52a6857f726e95869f81c866ac2",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6066061815256624,
                    "test_auc": 0.6152878961043359,
                    "test_f1": 0.5739939756288097
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.610098491375921,
                    "test_auc": 0.6269119516763866,
                    "test_f1": 0.5785955816164129
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6171247429726339,
                    "test_auc": 0.6429864501391557,
                    "test_f1": 0.6009772361813108
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6171247429726339,
                  "test_auc": 0.6429864501391557,
                  "test_f1": 0.6009772361813108
                },
                "best_minus_llm_auc": -0.04983001625555883
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:16:06+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "c0524dd5e4a52b9bd42897cb0ce8e81d7981ea7a6898486b16f2c59f3de5012e",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "13b9297851db0cdc43c8b597151cd17d967a640d934c6df4b83a884c538dade9",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.05_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.763310737609864,
                "independent_score_mean_max": 16.00711371898651,
                "interpretability_score_mean_max": 14.432394185066222,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:16:06",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.763310737609864,
                "independent_score_mean_max": 16.00711371898651,
                "interpretability_score_mean_max": 14.432394185066222
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.74799669265747,
                "independent_score_mean_max": -34.99215262889862,
                "interpretability_score_mean_max": -33.51921740055084
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04983001625555883,
          "cebench_delta": -33.51921740055084,
          "cebench_interpretability_max": 14.432394185066222,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9453211009174313,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 1.0,
              "alignment": 0.9064220183486239,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt",
          "alignment_to_ref": 0.9991788864135742,
          "explained_variance": 0.5341251492500305,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:10:36+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "1a3e16a786a2860ac515cc16e2bf0b3c20c5b93b98dad076cd21bb8ff6e0926b",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5968626797281039,
                    "test_auc": 0.6113969524408849,
                    "test_f1": 0.5655017971229078
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.597283077860725,
                    "test_auc": 0.6225565634691657,
                    "test_f1": 0.5657513530281966
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6161741448508103,
                    "test_auc": 0.6381718088654948,
                    "test_f1": 0.5944126233949023
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6161741448508103,
                  "test_auc": 0.6381718088654948,
                  "test_f1": 0.5944126233949023
                },
                "best_minus_llm_auc": -0.05464465752921965
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:13:04+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "f6cf87d2df6e1ee5103f5c952433c85ebb5d67e543b76617b4aca89f9e3e4418",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "b25f1aca2f19e6664a8f6d44324bb1bf515b46d237051d450f1616a4d9e1a279",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.05_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.56902340888977,
                "independent_score_mean_max": 16.1038503074646,
                "interpretability_score_mean_max": 14.256655421257019,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:13:04",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.56902340888977,
                "independent_score_mean_max": 16.1038503074646,
                "interpretability_score_mean_max": 14.256655421257019
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.94228402137757,
                "independent_score_mean_max": -34.89541604042053,
                "interpretability_score_mean_max": -33.69495616436005
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05464465752921965,
          "cebench_delta": -33.69495616436005,
          "cebench_interpretability_max": 14.256655421257019,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6759284759150354,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.6865571741667299,
              "cebench": 0.6052980851622284,
              "alignment": 1.0,
              "explained_variance": 0.40431765031307365
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt",
          "alignment_to_ref": 0.9991464018821716,
          "explained_variance": 0.5345327854156494,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:20:09+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "59549040ce3b997726ecd1f1b7961b34aba0951c69c830fd911c0d0e95639638",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.607632068525092,
                    "test_auc": 0.6233378465884156,
                    "test_f1": 0.5778571732655139
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6100462681076082,
                    "test_auc": 0.6291616940012972,
                    "test_f1": 0.5829058628387733
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6128017932111576,
                    "test_auc": 0.6396893866434897,
                    "test_f1": 0.5935148767411194
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6128017932111576,
                  "test_auc": 0.6396893866434897,
                  "test_f1": 0.5935148767411194
                },
                "best_minus_llm_auc": -0.05312707975122477
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:22:42+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "a152204971b4bf53d7222f04c0e6d6c50e1abbb0d1490b9bad4a07b523f0f1c7",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "2a0205d34d8b860390bc897ed75730d4a2362bdb139032fbea03b705d65e8f21",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.194043025970458,
                "independent_score_mean_max": 15.576153869628905,
                "interpretability_score_mean_max": 13.987149920463562,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:22:42",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.194043025970458,
                "independent_score_mean_max": 15.576153869628905,
                "interpretability_score_mean_max": 13.987149920463562
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.31726440429688,
                "independent_score_mean_max": -35.42311247825623,
                "interpretability_score_mean_max": -33.96446166515351
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05312707975122477,
          "cebench_delta": -33.96446166515351,
          "cebench_interpretability_max": 13.987149920463562,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6135312053681524,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.7853545383148612,
              "cebench": 0.0,
              "alignment": 0.0,
              "explained_variance": 0.49030603264012873
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt",
          "alignment_to_ref": 0.9991605281829834,
          "explained_variance": 0.5369490385055542,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:16:41+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "d6a755bf9b293b33a8e45fc1e60c8ac91a6f65b2145bafa468aacaa013099a6e",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5862263257211054,
                    "test_auc": 0.5905524079472635,
                    "test_f1": 0.5497188208926932
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5957760266028238,
                    "test_auc": 0.6138050266229562,
                    "test_f1": 0.5606819447105547
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6010810986155259,
                    "test_auc": 0.6276259413737648,
                    "test_f1": 0.567838180692527
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6010810986155259,
                  "test_auc": 0.6276259413737648,
                  "test_f1": 0.567838180692527
                },
                "best_minus_llm_auc": -0.06519052502094969
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:19:34+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "85beef7db8f01bef5448c12341ad1bb556038785ebe05caee6098bd3fc16147c",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "8e41a0822c41393eae7147873834aa05844601248c7836adf8f2d909cdae0381",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.05_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.831925806999207,
                "independent_score_mean_max": 15.635621542930602,
                "interpretability_score_mean_max": 14.220564064979554,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:19:34",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.831925806999207,
                "independent_score_mean_max": 15.635621542930602,
                "interpretability_score_mean_max": 14.220564064979554
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.67938162326813,
                "independent_score_mean_max": -35.36364480495453,
                "interpretability_score_mean_max": -33.73104752063751
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.06519052502094969,
          "cebench_delta": -33.73104752063751,
          "cebench_interpretability_max": 14.220564064979554,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.15037888048949133,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.524238408156242,
              "alignment": 0.43486238532110094,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
        "candidate_tag": "seed456",
        "saebench": {
          "timestamp_utc": "2026-02-17T14:13:38+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "4773e30e98f44ee609650551de315061ab3dd52a6857f726e95869f81c866ac2",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6066061815256624,
                "test_auc": 0.6152878961043359,
                "test_f1": 0.5739939756288097
              },
              {
                "k": 2,
                "test_accuracy": 0.610098491375921,
                "test_auc": 0.6269119516763866,
                "test_f1": 0.5785955816164129
              },
              {
                "k": 5,
                "test_accuracy": 0.6171247429726339,
                "test_auc": 0.6429864501391557,
                "test_f1": 0.6009772361813108
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6171247429726339,
              "test_auc": 0.6429864501391557,
              "test_f1": 0.6009772361813108
            },
            "best_minus_llm_auc": -0.04983001625555883
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T14:16:06+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "c0524dd5e4a52b9bd42897cb0ce8e81d7981ea7a6898486b16f2c59f3de5012e",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "13b9297851db0cdc43c8b597151cd17d967a640d934c6df4b83a884c538dade9",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.05_seed456/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 14.763310737609864,
            "independent_score_mean_max": 16.00711371898651,
            "interpretability_score_mean_max": 14.432394185066222,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456",
            "sae_id": "custom_sae",
            "date": "2026-02-17 14:16:06",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 14.763310737609864,
            "independent_score_mean_max": 16.00711371898651,
            "interpretability_score_mean_max": 14.432394185066222
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -35.74799669265747,
            "independent_score_mean_max": -34.99215262889862,
            "interpretability_score_mean_max": -33.51921740055084
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8342554188705982,
        "ev_drop": 0.254526948928833,
        "ev_neg_drop": -0.254526948928833,
        "saebench_delta": -0.04983001625555883,
        "cebench_delta": -33.51921740055084,
        "cebench_interpretability_max": 14.432394185066222
      },
      "selection": {
        "joint_score": 0.8379462605298184,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    },
    {
      "lambda_consistency": 0.08,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9991053670644761,
        "std": 0.00028278028149498455,
        "min": 0.9988521337509155,
        "max": 0.999464213848114,
        "median": 0.9989157170057297,
        "ci95_low": 0.9989407195895911,
        "ci95_high": 0.9992727165669203,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.8350801445543766,
      "delta_pwmcc_ci_low_conservative": 0.8347434273548424,
      "ratio_pwmcc": 6.091169100550733,
      "explained_variance": {
        "mean": 0.5856225252151489,
        "std": 0.1495448288047038,
        "min": 0.5158818960189819,
        "max": 0.8531134128570557,
        "median": 0.5201324224472046,
        "ci95_low": 0.5173261165618896,
        "ci95_high": 0.7196650266647339,
        "n": 5
      },
      "mse": {
        "mean": 0.0003437556195422076,
        "std": 0.00012405818622291233,
        "min": 0.00012185269588371739,
        "max": 0.0004016106831841171,
        "median": 0.00039808396832086146,
        "ci95_low": 0.00023269078956218437,
        "ci95_high": 0.0004001999972388148,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9994327276945114,
        "std": 2.417835434014657e-05,
        "min": 0.9994068145751953,
        "max": 0.999464213848114,
        "median": 0.9994299411773682,
        "ci95_low": 0.9994141310453415,
        "ci95_high": 0.9994541108608246,
        "n": 4
      },
      "runtime_sec": 1429.881992816925,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.9994238018989563,
          "mse": 0.0003974188584834337,
          "explained_variance": 0.5209355354309082,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9126386000533346,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.99943608045578,
          "mse": 0.0004016106831841171,
          "explained_variance": 0.5158818960189819,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.912627692869002,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.999464213848114,
          "mse": 0.00039808396832086146,
          "explained_variance": 0.5201324224472046,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9126858430638634,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.9994068145751953,
          "mse": 0.0003998118918389082,
          "explained_variance": 0.5180493593215942,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9126540565414837,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9994238018989563,
        0.99943608045578,
        0.999464213848114,
        0.9994068145751953,
        0.9988862872123718,
        0.9989099502563477,
        0.9988521337509155,
        0.9989214837551117,
        0.9988633990287781,
        0.9988895058631897
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
      "selected_checkpoint_seed": 1011,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
          "alignment_to_ref": 0.9994068145751953,
          "explained_variance": 0.5180493593215942,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:32:32+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "e7ff8714bae14dfa1da307bb06be8de1ba76a6f4f2cb0ecf4edbd0c983a71502",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6008084902357144,
                    "test_auc": 0.6010654722672262,
                    "test_f1": 0.5673617775548091
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.596958570726893,
                    "test_auc": 0.630305052365858,
                    "test_f1": 0.571368838587414
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6139254093145695,
                    "test_auc": 0.6392954155264232,
                    "test_f1": 0.596392390315998
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6139254093145695,
                  "test_auc": 0.6392954155264232,
                  "test_f1": 0.596392390315998
                },
                "best_minus_llm_auc": -0.05352105086829129
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:35:03+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "491a3c15c13935c7122597ede518d1a0a857d01de1bd073b117d6a5fe5efd95c",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "96bad52266a644d9fecfecbf4396128e6d2015ab4aa8344d7a063af27af9f919",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.69216621875763,
                "independent_score_mean_max": 15.623788080215455,
                "interpretability_score_mean_max": 14.364149336814881,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:35:03",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.69216621875763,
                "independent_score_mean_max": 15.623788080215455,
                "interpretability_score_mean_max": 14.364149336814881
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.81914121150971,
                "independent_score_mean_max": -35.37547826766968,
                "interpretability_score_mean_max": -33.58746224880218
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05352105086829129,
          "cebench_delta": -33.58746224880218,
          "cebench_interpretability_max": 14.364149336814881,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.7989355576645798,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.1832731970017899,
              "alignment": 0.0,
              "explained_variance": 0.4288915622862265
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt",
          "alignment_to_ref": 0.99943608045578,
          "explained_variance": 0.5158818960189819,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:26:19+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "a83d6a9f19cab7c556fb2dc81e9b80518d944d9c233b29e7472eed82ec36d59c",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5878341661380411,
                    "test_auc": 0.6086008871854737,
                    "test_f1": 0.5507209076080434
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6047083991939219,
                    "test_auc": 0.6210274661691355,
                    "test_f1": 0.5830591919818804
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6129701735324887,
                    "test_auc": 0.6375346183576178,
                    "test_f1": 0.5939422638371942
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6129701735324887,
                  "test_auc": 0.6375346183576178,
                  "test_f1": 0.5939422638371942
                },
                "best_minus_llm_auc": -0.05528184803709668
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:28:48+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "24d7c1893249ce428135f1286ce96f0d32cc5beaadd05586980a0c4d2a58a362",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "0391c45e5ea18df7e66adcaea4ad5d610dfcaf9ccad6d97872dcd96d35e183d9",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.08_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.529748129844666,
                "independent_score_mean_max": 16.251275062561035,
                "interpretability_score_mean_max": 14.238390259742737,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:28:48",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.529748129844666,
                "independent_score_mean_max": 16.251275062561035,
                "interpretability_score_mean_max": 14.238390259742737
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.981559300422674,
                "independent_score_mean_max": -34.7479912853241,
                "interpretability_score_mean_max": -33.71322132587433
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05528184803709668,
          "cebench_delta": -33.71322132587433,
          "cebench_interpretability_max": 14.238390259742737,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.652310821636778,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.8232775217083224,
              "cebench": 0.06239620063953885,
              "alignment": 0.509865005192108,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt",
          "alignment_to_ref": 0.999464213848114,
          "explained_variance": 0.5201324224472046,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:23:16+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "ba0742030afafad5508cd8c966eabf7b569f8e2bab58e16964ed553cd63fe262",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6035507306715023,
                    "test_auc": 0.6143334976588454,
                    "test_f1": 0.5623110373518677
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6022696648496513,
                    "test_auc": 0.6215473079702509,
                    "test_f1": 0.5640224215271035
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6060716734325212,
                    "test_auc": 0.6298006261382599,
                    "test_f1": 0.5757701558039282
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6060716734325212,
                  "test_auc": 0.6298006261382599,
                  "test_f1": 0.5757701558039282
                },
                "best_minus_llm_auc": -0.06301584025645457
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:25:44+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "3b378d990d8f5d1940eb8909190089345ea62bd0f91678d20dba6af8d52ece52",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "0d23c28bc6142eb892c5442851cf955731ff98487abd98b3fcae573f4d3b45be",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.08_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 15.310425510406494,
                "independent_score_mean_max": 16.845168018341063,
                "interpretability_score_mean_max": 15.213862781524659,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:25:44",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 15.310425510406494,
                "independent_score_mean_max": 16.845168018341063,
                "interpretability_score_mean_max": 15.213862781524659
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.20088191986084,
                "independent_score_mean_max": -34.15409832954407,
                "interpretability_score_mean_max": -32.737748804092405
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.06301584025645457,
          "cebench_delta": -32.737748804092405,
          "cebench_interpretability_max": 15.213862781524659,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.27734542510524,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.047055083197271266,
              "cebench": 1.0,
              "alignment": 1.0,
              "explained_variance": 0.8410822541457316
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt",
          "alignment_to_ref": 0.9994238018989563,
          "explained_variance": 0.5209355354309082,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:29:23+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "5f36ad397dbf3d1baaca6d42c0922a62426cc3399b794ae9341fbb345911b953",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5951020187939368,
                    "test_auc": 0.6109618351040809,
                    "test_f1": 0.5658560813541762
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5916353466394714,
                    "test_auc": 0.6120628464006502,
                    "test_f1": 0.5651946659641527
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6069475810991407,
                    "test_auc": 0.629331786757596,
                    "test_f1": 0.5754561847893795
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6069475810991407,
                  "test_auc": 0.629331786757596,
                  "test_f1": 0.5754561847893795
                },
                "best_minus_llm_auc": -0.06348467963711846
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:31:58+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "187407e65ebab39f97dab18e2731e14351b04e78f26139636a37631d1e26781b",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "c6a523a45fca09b69cfbe8d96cc4a061bec5cde56a2d8bf8a19352e21aa2c304",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.08_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.591936388015746,
                "independent_score_mean_max": 15.730177035331726,
                "interpretability_score_mean_max": 14.173473949432372,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:31:57",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.591936388015746,
                "independent_score_mean_max": 15.730177035331726,
                "interpretability_score_mean_max": 14.173473949432372
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.91937104225159,
                "independent_score_mean_max": -35.269089312553405,
                "interpretability_score_mean_max": -33.778137636184695
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.06348467963711846,
          "cebench_delta": -33.778137636184695,
          "cebench_interpretability_max": 14.173473949432372,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.064797507788162,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.0,
              "alignment": 0.29595015576323985,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
        "candidate_tag": "seed1011",
        "saebench": {
          "timestamp_utc": "2026-02-17T14:32:32+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "e7ff8714bae14dfa1da307bb06be8de1ba76a6f4f2cb0ecf4edbd0c983a71502",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6008084902357144,
                "test_auc": 0.6010654722672262,
                "test_f1": 0.5673617775548091
              },
              {
                "k": 2,
                "test_accuracy": 0.596958570726893,
                "test_auc": 0.630305052365858,
                "test_f1": 0.571368838587414
              },
              {
                "k": 5,
                "test_accuracy": 0.6139254093145695,
                "test_auc": 0.6392954155264232,
                "test_f1": 0.596392390315998
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6139254093145695,
              "test_auc": 0.6392954155264232,
              "test_f1": 0.596392390315998
            },
            "best_minus_llm_auc": -0.05352105086829129
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T14:35:03+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "491a3c15c13935c7122597ede518d1a0a857d01de1bd073b117d6a5fe5efd95c",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "96bad52266a644d9fecfecbf4396128e6d2015ab4aa8344d7a063af27af9f919",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 14.69216621875763,
            "independent_score_mean_max": 15.623788080215455,
            "interpretability_score_mean_max": 14.364149336814881,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011",
            "sae_id": "custom_sae",
            "date": "2026-02-17 14:35:03",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 14.69216621875763,
            "independent_score_mean_max": 15.623788080215455,
            "interpretability_score_mean_max": 14.364149336814881
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -35.81914121150971,
            "independent_score_mean_max": -35.37547826766968,
            "interpretability_score_mean_max": -33.58746224880218
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8347434273548424,
        "ev_drop": 0.26709018945693974,
        "ev_neg_drop": -0.26709018945693974,
        "saebench_delta": -0.05352105086829129,
        "cebench_delta": -33.58746224880218,
        "cebench_interpretability_max": 14.364149336814881
      },
      "selection": {
        "joint_score": 0.7481107743721055,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    },
    {
      "lambda_consistency": 0.1,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9992468476295471,
        "std": 0.00023886581625513065,
        "min": 0.9990355670452118,
        "max": 0.9995493292808533,
        "median": 0.9990836828947067,
        "ci95_low": 0.9991079920530319,
        "ci95_high": 0.9993876112997532,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.8352216251194476,
      "delta_pwmcc_ci_low_conservative": 0.8349106998182834,
      "ratio_pwmcc": 6.092031654265984,
      "explained_variance": {
        "mean": 0.5791060209274292,
        "std": 0.15318464653674643,
        "min": 0.5077364444732666,
        "max": 0.8531134128570557,
        "median": 0.5118701457977295,
        "ci95_low": 0.5093899250030518,
        "ci95_high": 0.7164300680160522,
        "n": 5
      },
      "mse": {
        "mean": 0.0003491615687380545,
        "std": 0.0001270776986426151,
        "min": 0.00012185269588371739,
        "max": 0.0004083674284629524,
        "median": 0.00040493832784704864,
        "ci95_low": 0.0002352798022911884,
        "ci95_high": 0.0004069574817549437,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9995235204696655,
        "std": 1.916645410251353e-05,
        "min": 0.9995052814483643,
        "max": 0.9995493292808533,
        "median": 0.9995197355747223,
        "ci95_low": 0.9995094537734985,
        "ci95_high": 0.9995404034852982,
        "n": 4
      },
      "runtime_sec": 1430.774831533432,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9995258450508118,
          "mse": 0.0004047467955388129,
          "explained_variance": 0.5121017694473267,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9130210986326414,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9995136260986328,
          "mse": 0.0004083674284629524,
          "explained_variance": 0.5077364444732666,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9130018554731376,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9995493292808533,
          "mse": 0.00040493832784704864,
          "explained_variance": 0.5118701457977295,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9130613664165139,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9995052814483643,
          "mse": 0.00040590259595774114,
          "explained_variance": 0.5107083320617676,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9130352277964078,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9995259046554565,
        0.9995136260986328,
        0.9995493292808533,
        0.9995052814483643,
        0.9990586638450623,
        0.9990898370742798,
        0.9990452527999878,
        0.9990775287151337,
        0.9990355670452118,
        0.999067485332489
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
      "selected_checkpoint_seed": 1011,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
          "alignment_to_ref": 0.9995052814483643,
          "explained_variance": 0.5107083320617676,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:44:49+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "c690dface618319f2e5550c5ea683feb28167c6dcc1b4fd7c4d825a9fd96a257",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6005670166803218,
                    "test_auc": 0.610328512906832,
                    "test_f1": 0.560869596403959
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5994583508065682,
                    "test_auc": 0.6212511983198329,
                    "test_f1": 0.5613903360397708
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6167744931570085,
                    "test_auc": 0.6453791395072228,
                    "test_f1": 0.5994146554784834
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6167744931570085,
                  "test_auc": 0.6453791395072228,
                  "test_f1": 0.5994146554784834
                },
                "best_minus_llm_auc": -0.04743732688749169
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:47:18+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "3d52b0da409f2cf568e21830ca41dc989c118af2ac9f16d3da4e976d724f6bb5",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "67f87d4a084ff529329bec9a03f006a2840bc5d158a1ca9f4c728e00cc1f1c54",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.53305012702942,
                "independent_score_mean_max": 15.707403116226196,
                "interpretability_score_mean_max": 14.274428329467774,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:47:18",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.53305012702942,
                "independent_score_mean_max": 15.707403116226196,
                "interpretability_score_mean_max": 14.274428329467774
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.97825730323792,
                "independent_score_mean_max": -35.29186323165894,
                "interpretability_score_mean_max": -33.67718325614929
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04743732688749169,
          "cebench_delta": -33.67718325614929,
          "cebench_interpretability_max": 14.274428329467774,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.7962082570378375,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.08112367249580285,
              "alignment": 0.0,
              "explained_variance": 0.6807941232693411
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
          "alignment_to_ref": 0.9995258450508118,
          "explained_variance": 0.5121017694473267,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:38:42+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "a15678ef469de3ed87d0ecd8931606d35a1428a03815359a0f92290d3101ec62",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5857180551684256,
                    "test_auc": 0.5898490248552595,
                    "test_f1": 0.5497016292959489
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5976258767401619,
                    "test_auc": 0.6182818100662946,
                    "test_f1": 0.5617583060413073
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6108792386330605,
                    "test_auc": 0.6370931803979578,
                    "test_f1": 0.5721131684000194
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6108792386330605,
                  "test_auc": 0.6370931803979578,
                  "test_f1": 0.5721131684000194
                },
                "best_minus_llm_auc": -0.05572328599675669
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:41:11+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "0e56d4bf48f77762e8d7598e984c428072dffe4599f1ae90608edd24bdc080e4",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "3c673315941ba48695ade32d013f1fa20e99d927559aaefd558b43f4a21376a5",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.454545342922211,
                "independent_score_mean_max": 15.87158621788025,
                "interpretability_score_mean_max": 14.233841514587402,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:41:11",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.454545342922211,
                "independent_score_mean_max": 15.87158621788025,
                "interpretability_score_mean_max": 14.233841514587402
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.05676208734513,
                "independent_score_mean_max": -35.12768013000488,
                "interpretability_score_mean_max": -33.71777007102966
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05572328599675669,
          "cebench_delta": -33.71777007102966,
          "cebench_interpretability_max": 14.233841514587402,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.32226806614881404,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.3319009488208815,
              "cebench": 0.0,
              "alignment": 0.4668470906630582,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
          "alignment_to_ref": 0.9995493292808533,
          "explained_variance": 0.5118701457977295,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:35:37+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "45dba9bfe33e056e2d15b409257967058cd016b364f703977225dfba167932d1",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6013639660591745,
                    "test_auc": 0.6112161036980954,
                    "test_f1": 0.5556944197807919
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6057861750352806,
                    "test_auc": 0.6193888294894893,
                    "test_f1": 0.5697745452494726
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6090151503413785,
                    "test_auc": 0.6329768481184815,
                    "test_f1": 0.5811284768526122
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6090151503413785,
                  "test_auc": 0.6329768481184815,
                  "test_f1": 0.5811284768526122
                },
                "best_minus_llm_auc": -0.059839618276232964
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:38:08+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "7ccc8168801496d3189507ce2d5976ab9a84af74877a26146afaf8e3bcdc0d5e",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "e8ab6ad2f04b82568dce36ce788ee286f746ba6a9d1ac0861fb9f27de9284492",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.963360185623168,
                "independent_score_mean_max": 16.489828758239746,
                "interpretability_score_mean_max": 14.734149422645569,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:38:07",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.963360185623168,
                "independent_score_mean_max": 16.489828758239746,
                "interpretability_score_mean_max": 14.734149422645569
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.54794724464417,
                "independent_score_mean_max": -34.50943758964539,
                "interpretability_score_mean_max": -33.2174621629715
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.059839618276232964,
          "cebench_delta": -33.2174621629715,
          "cebench_interpretability_max": 14.734149422645569,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.2473470056528032,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 1.0,
              "alignment": 1.0,
              "explained_variance": 0.9469401130560637
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
          "alignment_to_ref": 0.9995136260986328,
          "explained_variance": 0.5077364444732666,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:41:45+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "b46916ae31f36fb7c4849231404eee90530a4e6886cbcec44eaefc1a650feb37",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5934354760787593,
                    "test_auc": 0.60302511348788,
                    "test_f1": 0.557938764186839
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6025555326857831,
                    "test_auc": 0.6164667363208649,
                    "test_f1": 0.5770236893266685
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6143169135212134,
                    "test_auc": 0.634824852518261,
                    "test_f1": 0.59718468201138
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6143169135212134,
                  "test_auc": 0.634824852518261,
                  "test_f1": 0.59718468201138
                },
                "best_minus_llm_auc": -0.05799161387645346
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:44:15+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "69b33b33626adc1552ef6aef823c6dea1e9b72aaae20da1d5e55aa3d97925d9b",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "72ae14220abccf9403ef15747038d3bc7ec4b3c28f2d6a8ff3a1e53d2b0395ea",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.621507120132446,
                "independent_score_mean_max": 16.828977513313294,
                "interpretability_score_mean_max": 14.498566346168518,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:44:15",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.621507120132446,
                "independent_score_mean_max": 16.828977513313294,
                "interpretability_score_mean_max": 14.498566346168518
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.88980031013489,
                "independent_score_mean_max": -34.170288834571835,
                "interpretability_score_mean_max": -33.45304523944855
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05799161387645346,
          "cebench_delta": -33.45304523944855,
          "cebench_interpretability_max": 14.498566346168518,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.20059464158167215,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.14900507832424492,
              "cebench": 0.5291238201862243,
              "alignment": 0.18944519621109607,
              "explained_variance": 0.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
        "candidate_tag": "seed1011",
        "saebench": {
          "timestamp_utc": "2026-02-17T14:44:49+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "c690dface618319f2e5550c5ea683feb28167c6dcc1b4fd7c4d825a9fd96a257",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6005670166803218,
                "test_auc": 0.610328512906832,
                "test_f1": 0.560869596403959
              },
              {
                "k": 2,
                "test_accuracy": 0.5994583508065682,
                "test_auc": 0.6212511983198329,
                "test_f1": 0.5613903360397708
              },
              {
                "k": 5,
                "test_accuracy": 0.6167744931570085,
                "test_auc": 0.6453791395072228,
                "test_f1": 0.5994146554784834
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6167744931570085,
              "test_auc": 0.6453791395072228,
              "test_f1": 0.5994146554784834
            },
            "best_minus_llm_auc": -0.04743732688749169
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T14:47:18+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "3d52b0da409f2cf568e21830ca41dc989c118af2ac9f16d3da4e976d724f6bb5",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "67f87d4a084ff529329bec9a03f006a2840bc5d158a1ca9f4c728e00cc1f1c54",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 14.53305012702942,
            "independent_score_mean_max": 15.707403116226196,
            "interpretability_score_mean_max": 14.274428329467774,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
            "sae_id": "custom_sae",
            "date": "2026-02-17 14:47:18",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 14.53305012702942,
            "independent_score_mean_max": 15.707403116226196,
            "interpretability_score_mean_max": 14.274428329467774
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -35.97825730323792,
            "independent_score_mean_max": -35.29186323165894,
            "interpretability_score_mean_max": -33.67718325614929
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8349106998182834,
        "ev_drop": 0.2736066937446594,
        "ev_neg_drop": -0.2736066937446594,
        "saebench_delta": -0.04743732688749169,
        "cebench_delta": -33.67718325614929,
        "cebench_interpretability_max": 14.274428329467774
      },
      "selection": {
        "joint_score": 0.884928575903846,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    },
    {
      "lambda_consistency": 0.15,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9994587928056717,
        "std": 0.00017226819902102904,
        "min": 0.9993079304695129,
        "max": 0.9996694922447205,
        "median": 0.9993388652801514,
        "ci95_low": 0.9993587650358677,
        "ci95_high": 0.9995604160428048,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.8354335702955723,
      "delta_pwmcc_ci_low_conservative": 0.8351614728011192,
      "ratio_pwmcc": 6.093323804173671,
      "explained_variance": {
        "mean": 0.565224289894104,
        "std": 0.16094904729961712,
        "min": 0.4896153211593628,
        "max": 0.8531134128570557,
        "median": 0.4942736029624939,
        "ci95_low": 0.4916369080543518,
        "ci95_high": 0.7095346933603287,
        "n": 5
      },
      "mse": {
        "mean": 0.00036067761684535073,
        "std": 0.00013351891089684233,
        "min": 0.00012185269588371739,
        "max": 0.00042340013897046447,
        "median": 0.00041953640175051987,
        "ci95_low": 0.00024096263368846848,
        "ci95_high": 0.00042172339744865893,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9996585100889206,
        "std": 1.0344268327548307e-05,
        "min": 0.9996452331542969,
        "max": 0.9996694922447205,
        "median": 0.9996596574783325,
        "ci95_low": 0.9996496587991714,
        "ci95_high": 0.9996662139892578,
        "n": 4
      },
      "runtime_sec": 1429.9556584358215,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9996563792228699,
          "mse": 0.0004197186790406704,
          "explained_variance": 0.4940541386604309,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9135211912259735,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9996694922447205,
          "mse": 0.00042340013897046447,
          "explained_variance": 0.4896153211593628,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.913505043886188,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9996629357337952,
          "mse": 0.00041888016858138144,
          "explained_variance": 0.49506497383117676,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9135338068870759,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9996452331542969,
          "mse": 0.00041953640175051987,
          "explained_variance": 0.4942736029624939,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9135304855148273,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9996564388275146,
        0.9996694922447205,
        0.9996629059314728,
        0.9996452331542969,
        0.9993362128734589,
        0.9993308782577515,
        0.9993079304695129,
        0.9993415176868439,
        0.9993225932121277,
        0.9993147253990173
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
      "selected_checkpoint_seed": 1011,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
          "alignment_to_ref": 0.9996452331542969,
          "explained_variance": 0.4942736029624939,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:56:57+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "7a86bd4992558cdc77d73b1cc6829b651f9855ec3c6e3044b199dac185cecc08",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6006991067498302,
                    "test_auc": 0.6054523472040786,
                    "test_f1": 0.5591604987435893
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6107239180883893,
                    "test_auc": 0.6315869251397795,
                    "test_f1": 0.5830891325183166
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6212830945545705,
                    "test_auc": 0.6434163861661613,
                    "test_f1": 0.601674809829184
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6212830945545705,
                  "test_auc": 0.6434163861661613,
                  "test_f1": 0.601674809829184
                },
                "best_minus_llm_auc": -0.049400080228553245
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:59:25+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "d53e20c400a347cd0b369cd878f8439b6ffd5623df64ee93efe36aa32f66ac24",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "8c8baf8291e6173362af86db0f7ee6a6589636731dc4b82dc7d009090a7e762a",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.078473398685455,
                "independent_score_mean_max": 15.712986750602722,
                "interpretability_score_mean_max": 13.888679838180542,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:59:24",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.078473398685455,
                "independent_score_mean_max": 15.712986750602722,
                "interpretability_score_mean_max": 13.888679838180542
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.43283403158188,
                "independent_score_mean_max": -35.28627959728241,
                "interpretability_score_mean_max": -34.06293174743652
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.049400080228553245,
          "cebench_delta": -34.06293174743652,
          "cebench_interpretability_max": 13.888679838180542,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.7927392540741551,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.0,
              "alignment": 0.0,
              "explained_variance": 0.8547850814831018
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt",
          "alignment_to_ref": 0.9996694922447205,
          "explained_variance": 0.4896153211593628,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:47:53+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "2c8e2e28f023133894534f66a93c8a8a2ba356ee999258ff727afb35acacca74",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.588827477867384,
                    "test_auc": 0.606022176007571,
                    "test_f1": 0.5496855766748145
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6010191944462877,
                    "test_auc": 0.6222711641225226,
                    "test_f1": 0.5730470827157904
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6048595574570451,
                    "test_auc": 0.6370757538876025,
                    "test_f1": 0.5859276944127422
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6048595574570451,
                  "test_auc": 0.6370757538876025,
                  "test_f1": 0.5859276944127422
                },
                "best_minus_llm_auc": -0.05574071250711199
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:50:21+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "b25c06375ccee55ff8c9aaff575f8204b39f1624bc9cdcafd0e646a1b06d562b",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "a5525f971b054a2867279c9b724f8f82908efca82d2a7765f09b5916ee3e6ecc",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.15_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.163305993080138,
                "independent_score_mean_max": 16.445481567382814,
                "interpretability_score_mean_max": 14.228761715888977,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:50:21",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.163305993080138,
                "independent_score_mean_max": 16.445481567382814,
                "interpretability_score_mean_max": 14.228761715888977
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.3480014371872,
                "independent_score_mean_max": -34.55378478050232,
                "interpretability_score_mean_max": -33.72284986972809
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05574071250711199,
          "cebench_delta": -33.72284986972809,
          "cebench_interpretability_max": 14.228761715888977,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.41654467355018515,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.3893669272954621,
              "cebench": 0.49679652052392387,
              "alignment": 1.0,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt",
          "alignment_to_ref": 0.9996563792228699,
          "explained_variance": 0.4940541386604309,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:53:54+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "7094bd294940f51cc03c17a1d9204c8c9d9c08977c6730f3b69531f00a47ea11",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5902357922436835,
                    "test_auc": 0.6066816778589407,
                    "test_f1": 0.5469513823369552
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5975346759193501,
                    "test_auc": 0.6162438966654439,
                    "test_f1": 0.5611947466102771
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6068551933871391,
                    "test_auc": 0.6349406548351108,
                    "test_f1": 0.5764170661341987
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6068551933871391,
                  "test_auc": 0.6349406548351108,
                  "test_f1": 0.5764170661341987
                },
                "best_minus_llm_auc": -0.05787581155960375
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:56:23+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "4b6841ef8016ed4ca86ea2d29721394c6130a02d6ba03ee7319d2d9c3f1d005c",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "3608a87c8ea7448767a89690787c5e69c2413dd13e7164d23634b4bae416037e",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.15_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.678274207115173,
                "independent_score_mean_max": 16.091999282836912,
                "interpretability_score_mean_max": 14.360926089286805,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:56:23",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.678274207115173,
                "independent_score_mean_max": 16.091999282836912,
                "interpretability_score_mean_max": 14.360926089286805
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.833033223152164,
                "independent_score_mean_max": -34.90726706504822,
                "interpretability_score_mean_max": -33.59068549633026
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05787581155960375,
          "cebench_delta": -33.59068549633026,
          "cebench_interpretability_max": 14.360926089286805,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.30498833014397153,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.18374672450269838,
              "cebench": 0.689864146719393,
              "alignment": 0.4594594594594595,
              "explained_variance": 0.8145138357213169
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt",
          "alignment_to_ref": 0.9996629357337952,
          "explained_variance": 0.49506497383117676,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:50:55+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "0f76348d14fb55d724938c8702d70be6e0737539187f1229c79346b5657f8e75",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5898871666588792,
                    "test_auc": 0.5899650946147676,
                    "test_f1": 0.5427584633811429
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5991539899512263,
                    "test_auc": 0.621235368158471,
                    "test_f1": 0.5570366375940453
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6108518891125181,
                    "test_auc": 0.6330326834779403,
                    "test_f1": 0.5908910024358591
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6108518891125181,
                  "test_auc": 0.6330326834779403,
                  "test_f1": 0.5908910024358591
                },
                "best_minus_llm_auc": -0.05978378291677422
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:53:19+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "2c71fefa1b76991daf57ae88915bc51504c885db6c4c372bbcd9c1c730d6fffb",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "fa4456d4a94f6857c5c2f7e9717fc1e7184211fdb187a5733667745fa50ffab7",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.15_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.65447340965271,
                "independent_score_mean_max": 16.609899797439574,
                "interpretability_score_mean_max": 14.573229475021362,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:53:19",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.65447340965271,
                "independent_score_mean_max": 16.609899797439574,
                "interpretability_score_mean_max": 14.573229475021362
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.85683402061463,
                "independent_score_mean_max": -34.38936655044556,
                "interpretability_score_mean_max": -33.3783821105957
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05978378291677422,
          "cebench_delta": -33.3783821105957,
          "cebench_interpretability_max": 14.573229475021362,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.23648648648648646,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 1.0,
              "alignment": 0.7297297297297297,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
        "candidate_tag": "seed1011",
        "saebench": {
          "timestamp_utc": "2026-02-17T14:56:57+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "7a86bd4992558cdc77d73b1cc6829b651f9855ec3c6e3044b199dac185cecc08",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6006991067498302,
                "test_auc": 0.6054523472040786,
                "test_f1": 0.5591604987435893
              },
              {
                "k": 2,
                "test_accuracy": 0.6107239180883893,
                "test_auc": 0.6315869251397795,
                "test_f1": 0.5830891325183166
              },
              {
                "k": 5,
                "test_accuracy": 0.6212830945545705,
                "test_auc": 0.6434163861661613,
                "test_f1": 0.601674809829184
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6212830945545705,
              "test_auc": 0.6434163861661613,
              "test_f1": 0.601674809829184
            },
            "best_minus_llm_auc": -0.049400080228553245
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T14:59:25+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "d53e20c400a347cd0b369cd878f8439b6ffd5623df64ee93efe36aa32f66ac24",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "8c8baf8291e6173362af86db0f7ee6a6589636731dc4b82dc7d009090a7e762a",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 14.078473398685455,
            "independent_score_mean_max": 15.712986750602722,
            "interpretability_score_mean_max": 13.888679838180542,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011",
            "sae_id": "custom_sae",
            "date": "2026-02-17 14:59:24",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 14.078473398685455,
            "independent_score_mean_max": 15.712986750602722,
            "interpretability_score_mean_max": 13.888679838180542
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -36.43283403158188,
            "independent_score_mean_max": -35.28627959728241,
            "interpretability_score_mean_max": -34.06293174743652
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8351614728011192,
        "ev_drop": 0.28748842477798464,
        "ev_neg_drop": -0.28748842477798464,
        "saebench_delta": -0.049400080228553245,
        "cebench_delta": -34.06293174743652,
        "cebench_interpretability_max": 13.888679838180542
      },
      "selection": {
        "joint_score": 0.8239971731909919,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    },
    {
      "lambda_consistency": 0.2,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9995654344558715,
        "std": 0.00013859488359840204,
        "min": 0.9994481205940247,
        "max": 0.9997372329235077,
        "median": 0.9994682967662811,
        "ci95_low": 0.9994847591221332,
        "ci95_high": 0.9996469320356846,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.8355402119457721,
      "delta_pwmcc_ci_low_conservative": 0.8352874668873846,
      "ratio_pwmcc": 6.093973958147358,
      "explained_variance": {
        "mean": 0.5555011987686157,
        "std": 0.16637817805189847,
        "min": 0.478765070438385,
        "max": 0.8531134128570557,
        "median": 0.482511043548584,
        "ci95_low": 0.4798823356628418,
        "ci95_high": 0.7044913411140442,
        "n": 5
      },
      "mse": {
        "mean": 0.000368743714352604,
        "std": 0.0001380228182910353,
        "min": 0.00012185269588371739,
        "max": 0.00043240131344646215,
        "median": 0.00042929573100991547,
        "ci95_low": 0.0002451783584547229,
        "ci95_high": 0.0004312348610255867,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9997261762619019,
        "std": 7.632653464226619e-06,
        "min": 0.9997198581695557,
        "max": 0.9997372031211853,
        "median": 0.9997238218784332,
        "ci95_low": 0.999721109867096,
        "ci95_high": 0.9997335970401764,
        "n": 4
      },
      "runtime_sec": 1428.0716757774353,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt",
          "lambda_consistency": 0.2,
          "alignment_to_ref": 0.9997372031211853,
          "mse": 0.00042929573100991547,
          "explained_variance": 0.482511043548584,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9137663184147742,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt",
          "lambda_consistency": 0.2,
          "alignment_to_ref": 0.9997227787971497,
          "mse": 0.00043240131344646215,
          "explained_variance": 0.478765070438385,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9137462373926408,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt",
          "lambda_consistency": 0.2,
          "alignment_to_ref": 0.9997248649597168,
          "mse": 0.0004291308578103781,
          "explained_variance": 0.4827076196670532,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9137652566725457,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
          "lambda_consistency": 0.2,
          "alignment_to_ref": 0.9997198581695557,
          "mse": 0.0004310379736125469,
          "explained_variance": 0.48040884733200073,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.913778047060111,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9997372329235077,
        0.9997227489948273,
        0.9997248649597168,
        0.999719887971878,
        0.9994661808013916,
        0.9994704127311707,
        0.9994618594646454,
        0.9994543194770813,
        0.9994481205940247,
        0.9994487166404724
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
      "selected_checkpoint_seed": 1011,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
          "alignment_to_ref": 0.9997198581695557,
          "explained_variance": 0.48040884733200073,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T15:08:58+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "1734d0c3732de1dbb273a65531dccd04fa71eb2e17b5623849f487ac2b9c8401",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.7881393432617188e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6035841638347159,
                    "test_auc": 0.6177526454058861,
                    "test_f1": 0.5561840981880544
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6125719937623532,
                    "test_auc": 0.6300517613759598,
                    "test_f1": 0.5760787124875978
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6127867447088708,
                    "test_auc": 0.6421026345680163,
                    "test_f1": 0.5941668238141362
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6127867447088708,
                  "test_auc": 0.6421026345680163,
                  "test_f1": 0.5941668238141362
                },
                "best_minus_llm_auc": -0.0507138318266982
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T15:11:07+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "e0e9fea6ceb18a20bd9e95ca67ef08bd558f98519f06a777b0845a0987e41557",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "efa1ea9f898742938f87b77f78b24bfdd0a714a184cd3bc29257a6615d5e9294",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.7881393432617188e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 16.051321711540222,
                "independent_score_mean_max": 16.977635536193848,
                "interpretability_score_mean_max": 16.291307973861695,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 15:11:07",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 16.051321711540222,
                "independent_score_mean_max": 16.977635536193848,
                "interpretability_score_mean_max": 16.291307973861695
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -34.45998571872711,
                "independent_score_mean_max": -34.02163081169128,
                "interpretability_score_mean_max": -31.66030361175537
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.0507138318266982,
          "cebench_delta": -31.66030361175537,
          "cebench_interpretability_max": 16.291307973861695,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8975217129334486,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.968900117458774,
              "cebench": 1.0,
              "alignment": 0.0,
              "explained_variance": 0.4169324967873611
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt",
          "alignment_to_ref": 0.9997372031211853,
          "explained_variance": 0.482511043548584,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:59:59+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "1a23b825eb49ee1fe174a626ee099fe94324d378c9094bf206107b652f402d1e",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5784967500433654,
                    "test_auc": 0.5940343071376452,
                    "test_f1": 0.5377764235437756
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6011172766107579,
                    "test_auc": 0.6142925448732075,
                    "test_f1": 0.57443744003793
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6138099050236868,
                    "test_auc": 0.6425124161194115,
                    "test_f1": 0.5955063789764061
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6138099050236868,
                  "test_auc": 0.6425124161194115,
                  "test_f1": 0.5955063789764061
                },
                "best_minus_llm_auc": -0.05030405027530305
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T15:02:24+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "a88c8dab0b381044b75071b732522e81801e4c1bab60c8d04ceb33a1fd0ce0a0",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "2c6d0f7f1461e56c52554faf9d500a12face76cfda31c0fa5411a91abfad51b9",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.2_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.344642190933227,
                "independent_score_mean_max": 16.04955201625824,
                "interpretability_score_mean_max": 14.150790357589722,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 15:02:24",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.344642190933227,
                "independent_score_mean_max": 16.04955201625824,
                "interpretability_score_mean_max": 14.150790357589722
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.16666523933411,
                "independent_score_mean_max": -34.94971433162689,
                "interpretability_score_mean_max": -33.800821228027345
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05030405027530305,
          "cebench_delta": -33.800821228027345,
          "cebench_interpretability_max": 14.150790357589722,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8518972910221856,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.02926865872073572,
              "alignment": 1.0,
              "explained_variance": 0.9501398442815028
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt",
          "alignment_to_ref": 0.9997227787971497,
          "explained_variance": 0.478765070438385,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T15:05:56+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "2e9191197bd7f8cc8f59f3fd40882592ada6c4c7dccced87ad7e61b63d9784e5",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5997531635726936,
                    "test_auc": 0.6086304849830424,
                    "test_f1": 0.5598049238870679
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6012001959739481,
                    "test_auc": 0.6162582953210269,
                    "test_f1": 0.5742629779832751
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6102373929218674,
                    "test_auc": 0.6348628371091691,
                    "test_f1": 0.5913518831792549
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6102373929218674,
                  "test_auc": 0.6348628371091691,
                  "test_f1": 0.5913518831792549
                },
                "best_minus_llm_auc": -0.05795362928554537
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T15:08:23+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "9eb770334bd4d82833f39466f91299a27773efc7f55591d74d3bd5a376aa2ecf",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "d3674a8a5e965c8d7fd8422a97fcf15881264ae34cf22b03b80e6f1690b24f9d",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.2_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.27119710445404,
                "independent_score_mean_max": 16.285932083129882,
                "interpretability_score_mean_max": 14.086251306533814,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 15:08:23",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.27119710445404,
                "independent_score_mean_max": 16.285932083129882,
                "interpretability_score_mean_max": 14.086251306533814
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.2401103258133,
                "independent_score_mean_max": -34.71333426475525,
                "interpretability_score_mean_max": -33.86536027908325
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05795362928554537,
          "cebench_delta": -33.86536027908325,
          "cebench_interpretability_max": 14.086251306533814,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.32300248126523473,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.4194443163719739,
              "cebench": 0.0,
              "alignment": 0.16838487972508592,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt",
          "alignment_to_ref": 0.9997248649597168,
          "explained_variance": 0.4827076196670532,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T15:02:59+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "a4ab6b847894b2256a01378e11ba6775c6660ca9ffbb93ff62519fcd5d2188c7",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5988745985849107,
                    "test_auc": 0.60919939809392,
                    "test_f1": 0.5470218802722566
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5961715665469506,
                    "test_auc": 0.6170797443169445,
                    "test_f1": 0.5547850088894999
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.5981226481197492,
                    "test_auc": 0.6293361106831468,
                    "test_f1": 0.5762340054425952
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.5981226481197492,
                  "test_auc": 0.6293361106831468,
                  "test_f1": 0.5762340054425952
                },
                "best_minus_llm_auc": -0.06348035571156774
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T15:05:22+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "4b4b99b113b199e530d6651ee166c5120c7a72e569e18e7ca90b0a48bb1f145b",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "23c7c5e69a44e6bdc67d0668abb02ef54c08bb0f14c0b292029b6e5b14a8bd3a",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.2_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.962849588394166,
                "independent_score_mean_max": 16.97179027557373,
                "interpretability_score_mean_max": 14.961721000671387,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 15:05:22",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.962849588394166,
                "independent_score_mean_max": 16.97179027557373,
                "interpretability_score_mean_max": 14.961721000671387
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.54845784187317,
                "independent_score_mean_max": -34.0274760723114,
                "interpretability_score_mean_max": -32.98989058494568
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.06348035571156774,
          "cebench_delta": -32.98989058494568,
          "cebench_interpretability_max": 14.961721000671387,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.12398722068459987,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.3970282066258548,
              "alignment": 0.28865979381443296,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
        "candidate_tag": "seed1011",
        "saebench": {
          "timestamp_utc": "2026-02-17T15:08:58+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "1734d0c3732de1dbb273a65531dccd04fa71eb2e17b5623849f487ac2b9c8401",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.7881393432617188e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6035841638347159,
                "test_auc": 0.6177526454058861,
                "test_f1": 0.5561840981880544
              },
              {
                "k": 2,
                "test_accuracy": 0.6125719937623532,
                "test_auc": 0.6300517613759598,
                "test_f1": 0.5760787124875978
              },
              {
                "k": 5,
                "test_accuracy": 0.6127867447088708,
                "test_auc": 0.6421026345680163,
                "test_f1": 0.5941668238141362
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6127867447088708,
              "test_auc": 0.6421026345680163,
              "test_f1": 0.5941668238141362
            },
            "best_minus_llm_auc": -0.0507138318266982
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T15:11:07+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "e0e9fea6ceb18a20bd9e95ca67ef08bd558f98519f06a777b0845a0987e41557",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "efa1ea9f898742938f87b77f78b24bfdd0a714a184cd3bc29257a6615d5e9294",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.7881393432617188e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 16.051321711540222,
            "independent_score_mean_max": 16.977635536193848,
            "interpretability_score_mean_max": 16.291307973861695,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011",
            "sae_id": "custom_sae",
            "date": "2026-02-17 15:11:07",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 16.051321711540222,
            "independent_score_mean_max": 16.977635536193848,
            "interpretability_score_mean_max": 16.291307973861695
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -34.45998571872711,
            "independent_score_mean_max": -34.02163081169128,
            "interpretability_score_mean_max": -31.66030361175537
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8352874668873846,
        "ev_drop": 0.29721151590347294,
        "ev_neg_drop": -0.29721151590347294,
        "saebench_delta": -0.0507138318266982,
        "cebench_delta": -31.66030361175537,
        "cebench_interpretability_max": 16.291307973861695
      },
      "selection": {
        "joint_score": 0.8740940564177333,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    }
  ],
  "pareto_front": [
    {
      "lambda_consistency": 0.0,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.18844734728336335,
        "std": 0.0003059837005938743,
        "min": 0.18794596940279007,
        "max": 0.18887364864349365,
        "median": 0.1885439231991768,
        "ci95_low": 0.18826177448034287,
        "ci95_high": 0.18862040981650355,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.024422124773263942,
      "delta_pwmcc_ci_low_conservative": 0.024064482245594265,
      "ratio_pwmcc": 1.1488924959194018,
      "explained_variance": {
        "mean": 0.8527127146720886,
        "std": 0.00029619645172861494,
        "min": 0.8522933721542358,
        "max": 0.8531134128570557,
        "median": 0.8526833057403564,
        "ci95_low": 0.8524707198143006,
        "ci95_high": 0.8529362440109253,
        "n": 5
      },
      "mse": {
        "mean": 0.00012218514020787553,
        "std": 2.457315501250927e-07,
        "min": 0.00012185269588371739,
        "max": 0.00012253301974851638,
        "median": 0.00012220953067298979,
        "ci95_low": 0.00012199542979942634,
        "ci95_high": 0.00012238164199516178,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.17893202230334282,
        "std": 0.00025345869798676964,
        "min": 0.17862744629383087,
        "max": 0.17914609611034393,
        "median": 0.17897727340459824,
        "ci95_low": 0.1787232756614685,
        "ci95_high": 0.17914076894521713,
        "n": 4
      },
      "runtime_sec": 130.26984858512878,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.17862744629383087,
          "mse": 0.00012209962005726993,
          "explained_variance": 0.8528158068656921,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.17913544178009033,
          "mse": 0.00012220953067298979,
          "explained_variance": 0.8526833057403564,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.17881910502910614,
          "mse": 0.00012253301974851638,
          "explained_variance": 0.8522933721542358,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.17914609611034393,
          "mse": 0.00012223083467688411,
          "explained_variance": 0.852657675743103,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.18794596940279007,
        0.18825341761112213,
        0.18811380118131638,
        0.1886357069015503,
        0.18847618252038956,
        0.18817367404699326,
        0.18861166387796402,
        0.1887010708451271,
        0.18868833780288696,
        0.18887364864349365
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
      "selected_checkpoint_seed": 456,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
          "alignment_to_ref": 0.17913544178009033,
          "explained_variance": 0.8526833057403564,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T13:49:43+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "cf080d6390d2ad3f2e25945fb5827bb778fa0ad5d2cf8c3f26b44bc7e39d6083",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5922339463042303,
                    "test_auc": 0.5977728124763309,
                    "test_f1": 0.513670665689709
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5939358844384306,
                    "test_auc": 0.6044448816311556,
                    "test_f1": 0.5224244083386272
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.5990433882190835,
                    "test_auc": 0.6216382091990383,
                    "test_f1": 0.5512589180003198
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.5990433882190835,
                  "test_auc": 0.6216382091990383,
                  "test_f1": 0.5512589180003198
                },
                "best_minus_llm_auc": -0.07117825719567616
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T13:51:53+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "06b88d0f2f18c557770a146ecb8e2d83967709b413840f8445e09e42f34ce1b4",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "11a07de24fcf49207b4de552f9a2ef897603f80e1ef3d2b58099257f877e0a85",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.0_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 10.196092100143433,
                "independent_score_mean_max": 10.429015238285064,
                "interpretability_score_mean_max": 10.441005325317382,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 13:51:53",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 10.196092100143433,
                "independent_score_mean_max": 10.429015238285064,
                "interpretability_score_mean_max": 10.441005325317382
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -40.315215330123905,
                "independent_score_mean_max": -40.570251109600065,
                "interpretability_score_mean_max": -37.51060626029968
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.07117825719567616,
          "cebench_delta": -37.51060626029968,
          "cebench_interpretability_max": 10.441005325317382,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9172841854463769,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.5399495019351912,
              "alignment": 0.9794575647876803,
              "explained_variance": 0.746377638334284
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt",
          "alignment_to_ref": 0.17881910502910614,
          "explained_variance": 0.8522933721542358,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T13:52:30+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "dabf1952126fd34801d502577b7f5b2aedd0752e3ecf2ae26b6a7f124daf4ff1",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5813078403928299,
                    "test_auc": 0.5910117571295512,
                    "test_f1": 0.49264823545271164
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5804280390427752,
                    "test_auc": 0.6059040932864593,
                    "test_f1": 0.5129210078643981
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.5902378746011774,
                    "test_auc": 0.6180760062642267,
                    "test_f1": 0.5388127078496961
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.5902378746011774,
                  "test_auc": 0.6180760062642267,
                  "test_f1": 0.5388127078496961
                },
                "best_minus_llm_auc": -0.07474046013048785
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T13:54:55+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "889c7e6e11e80271a57fe5a0a579fc83d19f9ee3d2bc7351e314f3273daf94e3",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "f10967e9f0e131861579845b90183a4cd6658ebb5f950c479d914e580b7fd64a",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.0_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 10.361549708843231,
                "independent_score_mean_max": 10.78331934928894,
                "interpretability_score_mean_max": 10.674233231544495,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 13:54:55",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 10.361549708843231,
                "independent_score_mean_max": 10.78331934928894,
                "interpretability_score_mean_max": 10.674233231544495
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -40.14975772142411,
                "independent_score_mean_max": -40.215946998596195,
                "interpretability_score_mean_max": -37.27737835407257
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.07474046013048785,
          "cebench_delta": -37.27737835407257,
          "cebench_interpretability_max": 10.674233231544495,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.5896514948808999,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.5615663939483461,
              "cebench": 1.0,
              "alignment": 0.3695339883928058,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt",
          "alignment_to_ref": 0.17914609611034393,
          "explained_variance": 0.852657675743103,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T13:46:42+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "acd3f245f48d0a140e64700576a688bdcbf8e10e8769973c24c9332b8234bcb5",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5704222937912591,
                    "test_auc": 0.5759697473068347,
                    "test_f1": 0.4755615746549608
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5869041249394854,
                    "test_auc": 0.6080147834373766,
                    "test_f1": 0.5204035619485314
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.598790133810647,
                    "test_auc": 0.6182154097797055,
                    "test_f1": 0.5422254688402578
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.598790133810647,
                  "test_auc": 0.6182154097797055,
                  "test_f1": 0.5422254688402578
                },
                "best_minus_llm_auc": -0.07460105661500904
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T13:49:06+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "7c9ca32c42ff6e3b266995da4b58a7199686291e5fe60ed966fe13fd887d17cd",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "8639d97807bff9b8fcbe6a3e6ae2159fc1f33cafc1c31f46d6b5eb8969b451b4",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.877204098701476,
                "independent_score_mean_max": 11.0145872092247,
                "interpretability_score_mean_max": 10.16727169752121,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 13:49:06",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.877204098701476,
                "independent_score_mean_max": 11.0145872092247,
                "interpretability_score_mean_max": 10.16727169752121
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -40.63410333156586,
                "independent_score_mean_max": -39.98467913866043,
                "interpretability_score_mean_max": -37.78433988809586
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.07460105661500904,
          "cebench_delta": -37.78433988809586,
          "cebench_interpretability_max": 10.16727169752121,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.5189090096499562,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.5787240874054941,
              "cebench": 0.0,
              "alignment": 1.0,
              "explained_variance": 0.6973188819167142
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt",
          "alignment_to_ref": 0.17862744629383087,
          "explained_variance": 0.8528158068656921,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T13:55:33+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "333a0757af9a572d88217bf513073c02c9499907e9b0bbef4f16bad0c405d0ae",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5844798733918964,
                    "test_auc": 0.5879168889685746,
                    "test_f1": 0.5085568718667245
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5917775648840801,
                    "test_auc": 0.5961223460293172,
                    "test_f1": 0.5254993035676552
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.5978387803822386,
                    "test_auc": 0.6135133691191654,
                    "test_f1": 0.5527361780240143
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.5978387803822386,
                  "test_auc": 0.6135133691191654,
                  "test_f1": 0.5527361780240143
                },
                "best_minus_llm_auc": -0.07930309727554907
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T13:57:59+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "2b1c9f207a8583f6bc3aa028ece6cde940459abb7e10e89b6b8b92de51f593cd",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "d7f2012fdda5cd84a5f892f20c9d7af72d9c4604c0341614dc8e09dfa4e95aae",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.0_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 10.35431608915329,
                "independent_score_mean_max": 10.762057542800903,
                "interpretability_score_mean_max": 10.65065663099289,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 13:57:59",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 10.35431608915329,
                "independent_score_mean_max": 10.762057542800903,
                "interpretability_score_mean_max": 10.65065663099289
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -40.15699134111405,
                "independent_score_mean_max": -40.23720880508423,
                "interpretability_score_mean_max": -37.300954954624174
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.07930309727554907,
          "cebench_delta": -37.300954954624174,
          "cebench_interpretability_max": 10.65065663099289,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.19302414513646599,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.9534943009097732,
              "alignment": 0.0,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
        "candidate_tag": "seed456",
        "saebench": {
          "timestamp_utc": "2026-02-17T13:49:43+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "cf080d6390d2ad3f2e25945fb5827bb778fa0ad5d2cf8c3f26b44bc7e39d6083",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.5922339463042303,
                "test_auc": 0.5977728124763309,
                "test_f1": 0.513670665689709
              },
              {
                "k": 2,
                "test_accuracy": 0.5939358844384306,
                "test_auc": 0.6044448816311556,
                "test_f1": 0.5224244083386272
              },
              {
                "k": 5,
                "test_accuracy": 0.5990433882190835,
                "test_auc": 0.6216382091990383,
                "test_f1": 0.5512589180003198
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.5990433882190835,
              "test_auc": 0.6216382091990383,
              "test_f1": 0.5512589180003198
            },
            "best_minus_llm_auc": -0.07117825719567616
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T13:51:53+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "06b88d0f2f18c557770a146ecb8e2d83967709b413840f8445e09e42f34ce1b4",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "11a07de24fcf49207b4de552f9a2ef897603f80e1ef3d2b58099257f877e0a85",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.0_seed456/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 10.196092100143433,
            "independent_score_mean_max": 10.429015238285064,
            "interpretability_score_mean_max": 10.441005325317382,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456",
            "sae_id": "custom_sae",
            "date": "2026-02-17 13:51:53",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 10.196092100143433,
            "independent_score_mean_max": 10.429015238285064,
            "interpretability_score_mean_max": 10.441005325317382
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -40.315215330123905,
            "independent_score_mean_max": -40.570251109600065,
            "interpretability_score_mean_max": -37.51060626029968
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.024064482245594265,
        "ev_drop": 0.0,
        "ev_neg_drop": -0.0,
        "saebench_delta": -0.07117825719567616,
        "cebench_delta": -37.51060626029968,
        "cebench_interpretability_max": 10.441005325317382
      },
      "selection": {
        "joint_score": 0.05,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    },
    {
      "lambda_consistency": 0.03,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9978271931409836,
        "std": 0.0006739460976970869,
        "min": 0.9972622096538544,
        "max": 0.998632937669754,
        "median": 0.9973331391811371,
        "ci95_low": 0.9974357336759567,
        "ci95_high": 0.9982214707136153,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.8338019706308841,
      "delta_pwmcc_ci_low_conservative": 0.8332384414412082,
      "ratio_pwmcc": 6.083376555575439,
      "explained_variance": {
        "mean": 0.6137382864952088,
        "std": 0.13381697521634336,
        "min": 0.5529702305793762,
        "max": 0.8531134128570557,
        "median": 0.553804874420166,
        "ci95_low": 0.553428053855896,
        "ci95_high": 0.7334831833839417,
        "n": 5
      },
      "mse": {
        "mean": 0.0003204313092282973,
        "std": 0.00011101065404439031,
        "min": 0.00012185269588371739,
        "max": 0.00037084275390952826,
        "median": 0.0003701501991599798,
        "ci95_low": 0.00022109446726972237,
        "ci95_high": 0.00037046290235593916,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9986097514629364,
        "std": 1.8901878731606503e-05,
        "min": 0.9985896944999695,
        "max": 0.9986329078674316,
        "median": 0.9986082017421722,
        "ci95_low": 0.9985949397087097,
        "ci95_high": 0.9986247271299362,
        "n": 4
      },
      "runtime_sec": 1431.7777667045593,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt",
          "lambda_consistency": 0.03,
          "alignment_to_ref": 0.9985896944999695,
          "mse": 0.00036907149478793144,
          "explained_variance": 0.555105447769165,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9091940732431356,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
          "lambda_consistency": 0.03,
          "alignment_to_ref": 0.9986162185668945,
          "mse": 0.00037084275390952826,
          "explained_variance": 0.5529702305793762,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9091687868866656,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt",
          "lambda_consistency": 0.03,
          "alignment_to_ref": 0.9986329078674316,
          "mse": 0.0003702394024003297,
          "explained_variance": 0.5536974668502808,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9092401030852839,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt",
          "lambda_consistency": 0.03,
          "alignment_to_ref": 0.99860018491745,
          "mse": 0.0003701501991599798,
          "explained_variance": 0.553804874420166,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9092095805745986,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9985897541046143,
        0.9986162185668945,
        0.998632937669754,
        0.99860018491745,
        0.9973362684249878,
        0.9973001182079315,
        0.9972622096538544,
        0.9973300099372864,
        0.997287929058075,
        0.997316300868988
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
      "selected_checkpoint_seed": 456,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
          "alignment_to_ref": 0.9986162185668945,
          "explained_variance": 0.5529702305793762,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:01:38+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "f6f5f2d8d0cd0d8f9e058c249e76fb8e968a3f73ac94aa7f3172758cd8fe1986",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5894021379898293,
                    "test_auc": 0.6041184861654619,
                    "test_f1": 0.5498710508381413
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5984883739823331,
                    "test_auc": 0.6151961788330417,
                    "test_f1": 0.5603444631865563
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.622710819433242,
                    "test_auc": 0.6434387555393835,
                    "test_f1": 0.6054708336806258
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.622710819433242,
                  "test_auc": 0.6434387555393835,
                  "test_f1": 0.6054708336806258
                },
                "best_minus_llm_auc": -0.04937771085533105
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:04:31+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "bc30efca5430344f341c2bdc9b02cd2924e67ea0f35f959b383239dcdac6b808",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "8b2f1900460b956886cb4a8bf160b1c347bd2e10d4bb90c4e995664d2ca82904",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.03_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.624090700149535,
                "independent_score_mean_max": 15.732642364501952,
                "interpretability_score_mean_max": 14.12977129459381,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:04:31",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.624090700149535,
                "independent_score_mean_max": 15.732642364501952,
                "interpretability_score_mean_max": 14.12977129459381
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.8872167301178,
                "independent_score_mean_max": -35.266623983383184,
                "interpretability_score_mean_max": -33.82184029102326
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04937771085533105,
          "cebench_delta": -33.82184029102326,
          "cebench_interpretability_max": 14.12977129459381,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8639712255756447,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.5552104693548718,
              "alignment": 0.6137931034482759,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt",
          "alignment_to_ref": 0.99860018491745,
          "explained_variance": 0.553804874420166,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:05:06+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "49f2139ee60ada7f85a4780374f6f9fbf423a90714e36f1d4c6fc2119edcceda",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.599030064376878,
                    "test_auc": 0.6085647594940361,
                    "test_f1": 0.5528062786696007
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6128467688667418,
                    "test_auc": 0.6302196507820805,
                    "test_f1": 0.5894119791327191
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6190131699376694,
                    "test_auc": 0.6410805881005667,
                    "test_f1": 0.6036582437167475
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6190131699376694,
                  "test_auc": 0.6410805881005667,
                  "test_f1": 0.6036582437167475
                },
                "best_minus_llm_auc": -0.05173587829414783
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:07:26+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "30d1f69c0fb022872713ac4f3b33282c52748b8a37ecab72ae78c74da2f7a044",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "d435a6c9b9a88f1b84153de0462330aa0333f22e078df378336f3f4dc7a65bbd",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.02915442466736,
                "independent_score_mean_max": 15.24943531036377,
                "interpretability_score_mean_max": 13.719969158172608,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:07:26",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.02915442466736,
                "independent_score_mean_max": 15.24943531036377,
                "interpretability_score_mean_max": 13.719969158172608
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.482153005599976,
                "independent_score_mean_max": -35.74983103752136,
                "interpretability_score_mean_max": -34.231642427444456
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05173587829414783,
          "cebench_delta": -34.231642427444456,
          "cebench_interpretability_max": 13.719969158172608,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6104065996361289,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.7716319502486025,
              "cebench": 0.0,
              "alignment": 0.24275862068965517,
              "explained_variance": 0.390894118303883
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt",
          "alignment_to_ref": 0.9985896944999695,
          "explained_variance": 0.555105447769165,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:08:00+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "67ce7fb4a5cdd8c31f95895ba0837437b3b21033a771280eab45ad04df4a367d",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5755048683417479,
                    "test_auc": 0.5798039493835621,
                    "test_f1": 0.5359674936844536
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5923725598616915,
                    "test_auc": 0.6194176905019874,
                    "test_f1": 0.5675971476136623
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6152991094073653,
                    "test_auc": 0.6357177802286724,
                    "test_f1": 0.5843968326969083
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6152991094073653,
                  "test_auc": 0.6357177802286724,
                  "test_f1": 0.5843968326969083
                },
                "best_minus_llm_auc": -0.05709868616604208
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:10:01+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "7641e68540aad135706ee63f07bb2269836aa0e3d2ab7989d0a3454ec0d374d7",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "469ec2dd0489f3481a662a1823a1004349b663472d10857ea7bc4d98fdca4cc6",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.03_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 15.085028817653656,
                "independent_score_mean_max": 16.178657956123352,
                "interpretability_score_mean_max": 14.458071479797363,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:10:01",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 15.085028817653656,
                "independent_score_mean_max": 16.178657956123352,
                "interpretability_score_mean_max": 14.458071479797363
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.42627861261368,
                "independent_score_mean_max": -34.82060839176178,
                "interpretability_score_mean_max": -33.493540105819704
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05709868616604208,
          "cebench_delta": -33.493540105819704,
          "cebench_interpretability_max": 14.458071479797363,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.3892179140265573,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.2522905520354098,
              "cebench": 1.0,
              "alignment": 0.0,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt",
          "alignment_to_ref": 0.9986329078674316,
          "explained_variance": 0.5536974668502808,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T13:58:33+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "316aee73acf2010d68edefd109a6cb7406f514c978079559808417a38f5f71c0",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5892651752726169,
                    "test_auc": 0.6071717086300038,
                    "test_f1": 0.5472773606127306
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6075098526371968,
                    "test_auc": 0.6278448729043701,
                    "test_f1": 0.5750274170193598
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6082202142364151,
                    "test_auc": 0.6331125849503545,
                    "test_f1": 0.5870829717832178
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6082202142364151,
                  "test_auc": 0.6331125849503545,
                  "test_f1": 0.5870829717832178
                },
                "best_minus_llm_auc": -0.05970388144436001
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:01:02+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "42cb60f6e7dfbfa0ac8afa91db4c93b7acd505fd423582c64b0c45eacf65fd61",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "ce4452af4b791ec9db9845e612cf755aad04bd6ed729ed0fefb3b33e958a0b55",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.03_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.651202373504638,
                "independent_score_mean_max": 15.845165600776673,
                "interpretability_score_mean_max": 13.908076062202454,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:01:02",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.651202373504638,
                "independent_score_mean_max": 15.845165600776673,
                "interpretability_score_mean_max": 13.908076062202454
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.8601050567627,
                "independent_score_mean_max": -35.15410074710846,
                "interpretability_score_mean_max": -34.04353552341461
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05970388144436001,
          "cebench_delta": -34.04353552341461,
          "cebench_interpretability_max": 13.908076062202454,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.10525737240998803,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.2548520693117087,
              "alignment": 1.0,
              "explained_variance": 0.34059124026463444
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
        "candidate_tag": "seed456",
        "saebench": {
          "timestamp_utc": "2026-02-17T14:01:38+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "f6f5f2d8d0cd0d8f9e058c249e76fb8e968a3f73ac94aa7f3172758cd8fe1986",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.5894021379898293,
                "test_auc": 0.6041184861654619,
                "test_f1": 0.5498710508381413
              },
              {
                "k": 2,
                "test_accuracy": 0.5984883739823331,
                "test_auc": 0.6151961788330417,
                "test_f1": 0.5603444631865563
              },
              {
                "k": 5,
                "test_accuracy": 0.622710819433242,
                "test_auc": 0.6434387555393835,
                "test_f1": 0.6054708336806258
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.622710819433242,
              "test_auc": 0.6434387555393835,
              "test_f1": 0.6054708336806258
            },
            "best_minus_llm_auc": -0.04937771085533105
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T14:04:31+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "bc30efca5430344f341c2bdc9b02cd2924e67ea0f35f959b383239dcdac6b808",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "8b2f1900460b956886cb4a8bf160b1c347bd2e10d4bb90c4e995664d2ca82904",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.03_seed456/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 14.624090700149535,
            "independent_score_mean_max": 15.732642364501952,
            "interpretability_score_mean_max": 14.12977129459381,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456",
            "sae_id": "custom_sae",
            "date": "2026-02-17 14:04:31",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 14.624090700149535,
            "independent_score_mean_max": 15.732642364501952,
            "interpretability_score_mean_max": 14.12977129459381
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -35.8872167301178,
            "independent_score_mean_max": -35.266623983383184,
            "interpretability_score_mean_max": -33.82184029102326
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8332384414412082,
        "ev_drop": 0.23897442817687986,
        "ev_neg_drop": -0.23897442817687986,
        "saebench_delta": -0.04937771085533105,
        "cebench_delta": -33.82184029102326,
        "cebench_interpretability_max": 14.12977129459381
      },
      "selection": {
        "joint_score": 0.8404448355747316,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    },
    {
      "lambda_consistency": 0.05,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9986905753612518,
        "std": 0.0004090263797073315,
        "min": 0.9983469843864441,
        "max": 0.9991788864135742,
        "median": 0.998396247625351,
        "ci95_low": 0.9984527111053467,
        "ci95_high": 0.9989304366707802,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.8346653528511524,
      "delta_pwmcc_ci_low_conservative": 0.8342554188705982,
      "ratio_pwmcc": 6.088640271771375,
      "explained_variance": {
        "mean": 0.5981857657432557,
        "std": 0.14251887039387154,
        "min": 0.5322084426879883,
        "max": 0.8531134128570557,
        "median": 0.5345327854156494,
        "ci95_low": 0.5334399938583374,
        "ci95_high": 0.7256995439529419,
        "n": 5
      },
      "mse": {
        "mean": 0.0003333334097987972,
        "std": 0.00011822959124170233,
        "min": 0.00012185269588371739,
        "max": 0.000388066255254671,
        "median": 0.000386137719033286,
        "ci95_low": 0.00022755175159545616,
        "ci95_high": 0.00038704443140886725,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.999165415763855,
        "std": 1.5007513714984594e-05,
        "min": 0.9991464018821716,
        "max": 0.9991788864135742,
        "median": 0.999168187379837,
        "ci95_low": 0.9991534650325775,
        "ci95_high": 0.9991773664951324,
        "n": 4
      },
      "runtime_sec": 1447.2789540290833,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt",
          "lambda_consistency": 0.05,
          "alignment_to_ref": 0.9991605281829834,
          "mse": 0.0003841344150714576,
          "explained_variance": 0.5369490385055542,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9114554998188935,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
          "lambda_consistency": 0.05,
          "alignment_to_ref": 0.9991758465766907,
          "mse": 0.000388066255254671,
          "explained_variance": 0.5322084426879883,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9114441092264045,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt",
          "lambda_consistency": 0.05,
          "alignment_to_ref": 0.9991788864135742,
          "mse": 0.00038647596375085413,
          "explained_variance": 0.5341251492500305,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9114961447366686,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt",
          "lambda_consistency": 0.05,
          "alignment_to_ref": 0.9991464018821716,
          "mse": 0.000386137719033286,
          "explained_variance": 0.5345327854156494,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.911461247217462,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9991605281829834,
        0.9991758465766907,
        0.9991788864135742,
        0.9991463422775269,
        0.998396098613739,
        0.9983784556388855,
        0.9983469843864441,
        0.9983963966369629,
        0.9983612895011902,
        0.9983649253845215
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
      "selected_checkpoint_seed": 456,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
          "alignment_to_ref": 0.9991758465766907,
          "explained_variance": 0.5322084426879883,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:13:38+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "4773e30e98f44ee609650551de315061ab3dd52a6857f726e95869f81c866ac2",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6066061815256624,
                    "test_auc": 0.6152878961043359,
                    "test_f1": 0.5739939756288097
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.610098491375921,
                    "test_auc": 0.6269119516763866,
                    "test_f1": 0.5785955816164129
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6171247429726339,
                    "test_auc": 0.6429864501391557,
                    "test_f1": 0.6009772361813108
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6171247429726339,
                  "test_auc": 0.6429864501391557,
                  "test_f1": 0.6009772361813108
                },
                "best_minus_llm_auc": -0.04983001625555883
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:16:06+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "c0524dd5e4a52b9bd42897cb0ce8e81d7981ea7a6898486b16f2c59f3de5012e",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "13b9297851db0cdc43c8b597151cd17d967a640d934c6df4b83a884c538dade9",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.05_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.763310737609864,
                "independent_score_mean_max": 16.00711371898651,
                "interpretability_score_mean_max": 14.432394185066222,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:16:06",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.763310737609864,
                "independent_score_mean_max": 16.00711371898651,
                "interpretability_score_mean_max": 14.432394185066222
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.74799669265747,
                "independent_score_mean_max": -34.99215262889862,
                "interpretability_score_mean_max": -33.51921740055084
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04983001625555883,
          "cebench_delta": -33.51921740055084,
          "cebench_interpretability_max": 14.432394185066222,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9453211009174313,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 1.0,
              "alignment": 0.9064220183486239,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt",
          "alignment_to_ref": 0.9991788864135742,
          "explained_variance": 0.5341251492500305,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:10:36+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "1a3e16a786a2860ac515cc16e2bf0b3c20c5b93b98dad076cd21bb8ff6e0926b",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5968626797281039,
                    "test_auc": 0.6113969524408849,
                    "test_f1": 0.5655017971229078
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.597283077860725,
                    "test_auc": 0.6225565634691657,
                    "test_f1": 0.5657513530281966
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6161741448508103,
                    "test_auc": 0.6381718088654948,
                    "test_f1": 0.5944126233949023
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6161741448508103,
                  "test_auc": 0.6381718088654948,
                  "test_f1": 0.5944126233949023
                },
                "best_minus_llm_auc": -0.05464465752921965
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:13:04+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "f6cf87d2df6e1ee5103f5c952433c85ebb5d67e543b76617b4aca89f9e3e4418",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "b25f1aca2f19e6664a8f6d44324bb1bf515b46d237051d450f1616a4d9e1a279",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.05_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.56902340888977,
                "independent_score_mean_max": 16.1038503074646,
                "interpretability_score_mean_max": 14.256655421257019,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:13:04",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.56902340888977,
                "independent_score_mean_max": 16.1038503074646,
                "interpretability_score_mean_max": 14.256655421257019
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.94228402137757,
                "independent_score_mean_max": -34.89541604042053,
                "interpretability_score_mean_max": -33.69495616436005
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05464465752921965,
          "cebench_delta": -33.69495616436005,
          "cebench_interpretability_max": 14.256655421257019,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6759284759150354,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.6865571741667299,
              "cebench": 0.6052980851622284,
              "alignment": 1.0,
              "explained_variance": 0.40431765031307365
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt",
          "alignment_to_ref": 0.9991464018821716,
          "explained_variance": 0.5345327854156494,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:20:09+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "59549040ce3b997726ecd1f1b7961b34aba0951c69c830fd911c0d0e95639638",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.607632068525092,
                    "test_auc": 0.6233378465884156,
                    "test_f1": 0.5778571732655139
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6100462681076082,
                    "test_auc": 0.6291616940012972,
                    "test_f1": 0.5829058628387733
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6128017932111576,
                    "test_auc": 0.6396893866434897,
                    "test_f1": 0.5935148767411194
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6128017932111576,
                  "test_auc": 0.6396893866434897,
                  "test_f1": 0.5935148767411194
                },
                "best_minus_llm_auc": -0.05312707975122477
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:22:42+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "a152204971b4bf53d7222f04c0e6d6c50e1abbb0d1490b9bad4a07b523f0f1c7",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "2a0205d34d8b860390bc897ed75730d4a2362bdb139032fbea03b705d65e8f21",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.194043025970458,
                "independent_score_mean_max": 15.576153869628905,
                "interpretability_score_mean_max": 13.987149920463562,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:22:42",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.194043025970458,
                "independent_score_mean_max": 15.576153869628905,
                "interpretability_score_mean_max": 13.987149920463562
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.31726440429688,
                "independent_score_mean_max": -35.42311247825623,
                "interpretability_score_mean_max": -33.96446166515351
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05312707975122477,
          "cebench_delta": -33.96446166515351,
          "cebench_interpretability_max": 13.987149920463562,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6135312053681524,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.7853545383148612,
              "cebench": 0.0,
              "alignment": 0.0,
              "explained_variance": 0.49030603264012873
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt",
          "alignment_to_ref": 0.9991605281829834,
          "explained_variance": 0.5369490385055542,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:16:41+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "d6a755bf9b293b33a8e45fc1e60c8ac91a6f65b2145bafa468aacaa013099a6e",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5862263257211054,
                    "test_auc": 0.5905524079472635,
                    "test_f1": 0.5497188208926932
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5957760266028238,
                    "test_auc": 0.6138050266229562,
                    "test_f1": 0.5606819447105547
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6010810986155259,
                    "test_auc": 0.6276259413737648,
                    "test_f1": 0.567838180692527
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6010810986155259,
                  "test_auc": 0.6276259413737648,
                  "test_f1": 0.567838180692527
                },
                "best_minus_llm_auc": -0.06519052502094969
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:19:34+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "85beef7db8f01bef5448c12341ad1bb556038785ebe05caee6098bd3fc16147c",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "8e41a0822c41393eae7147873834aa05844601248c7836adf8f2d909cdae0381",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.05_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.831925806999207,
                "independent_score_mean_max": 15.635621542930602,
                "interpretability_score_mean_max": 14.220564064979554,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:19:34",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.831925806999207,
                "independent_score_mean_max": 15.635621542930602,
                "interpretability_score_mean_max": 14.220564064979554
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.67938162326813,
                "independent_score_mean_max": -35.36364480495453,
                "interpretability_score_mean_max": -33.73104752063751
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.06519052502094969,
          "cebench_delta": -33.73104752063751,
          "cebench_interpretability_max": 14.220564064979554,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.15037888048949133,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.524238408156242,
              "alignment": 0.43486238532110094,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
        "candidate_tag": "seed456",
        "saebench": {
          "timestamp_utc": "2026-02-17T14:13:38+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "4773e30e98f44ee609650551de315061ab3dd52a6857f726e95869f81c866ac2",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6066061815256624,
                "test_auc": 0.6152878961043359,
                "test_f1": 0.5739939756288097
              },
              {
                "k": 2,
                "test_accuracy": 0.610098491375921,
                "test_auc": 0.6269119516763866,
                "test_f1": 0.5785955816164129
              },
              {
                "k": 5,
                "test_accuracy": 0.6171247429726339,
                "test_auc": 0.6429864501391557,
                "test_f1": 0.6009772361813108
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6171247429726339,
              "test_auc": 0.6429864501391557,
              "test_f1": 0.6009772361813108
            },
            "best_minus_llm_auc": -0.04983001625555883
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T14:16:06+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "c0524dd5e4a52b9bd42897cb0ce8e81d7981ea7a6898486b16f2c59f3de5012e",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "13b9297851db0cdc43c8b597151cd17d967a640d934c6df4b83a884c538dade9",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.05_seed456/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 14.763310737609864,
            "independent_score_mean_max": 16.00711371898651,
            "interpretability_score_mean_max": 14.432394185066222,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456",
            "sae_id": "custom_sae",
            "date": "2026-02-17 14:16:06",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 14.763310737609864,
            "independent_score_mean_max": 16.00711371898651,
            "interpretability_score_mean_max": 14.432394185066222
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -35.74799669265747,
            "independent_score_mean_max": -34.99215262889862,
            "interpretability_score_mean_max": -33.51921740055084
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8342554188705982,
        "ev_drop": 0.254526948928833,
        "ev_neg_drop": -0.254526948928833,
        "saebench_delta": -0.04983001625555883,
        "cebench_delta": -33.51921740055084,
        "cebench_interpretability_max": 14.432394185066222
      },
      "selection": {
        "joint_score": 0.8379462605298184,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    },
    {
      "lambda_consistency": 0.08,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9991053670644761,
        "std": 0.00028278028149498455,
        "min": 0.9988521337509155,
        "max": 0.999464213848114,
        "median": 0.9989157170057297,
        "ci95_low": 0.9989407195895911,
        "ci95_high": 0.9992727165669203,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.8350801445543766,
      "delta_pwmcc_ci_low_conservative": 0.8347434273548424,
      "ratio_pwmcc": 6.091169100550733,
      "explained_variance": {
        "mean": 0.5856225252151489,
        "std": 0.1495448288047038,
        "min": 0.5158818960189819,
        "max": 0.8531134128570557,
        "median": 0.5201324224472046,
        "ci95_low": 0.5173261165618896,
        "ci95_high": 0.7196650266647339,
        "n": 5
      },
      "mse": {
        "mean": 0.0003437556195422076,
        "std": 0.00012405818622291233,
        "min": 0.00012185269588371739,
        "max": 0.0004016106831841171,
        "median": 0.00039808396832086146,
        "ci95_low": 0.00023269078956218437,
        "ci95_high": 0.0004001999972388148,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9994327276945114,
        "std": 2.417835434014657e-05,
        "min": 0.9994068145751953,
        "max": 0.999464213848114,
        "median": 0.9994299411773682,
        "ci95_low": 0.9994141310453415,
        "ci95_high": 0.9994541108608246,
        "n": 4
      },
      "runtime_sec": 1429.881992816925,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.9994238018989563,
          "mse": 0.0003974188584834337,
          "explained_variance": 0.5209355354309082,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9126386000533346,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.99943608045578,
          "mse": 0.0004016106831841171,
          "explained_variance": 0.5158818960189819,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.912627692869002,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.999464213848114,
          "mse": 0.00039808396832086146,
          "explained_variance": 0.5201324224472046,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9126858430638634,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.9994068145751953,
          "mse": 0.0003998118918389082,
          "explained_variance": 0.5180493593215942,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9126540565414837,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9994238018989563,
        0.99943608045578,
        0.999464213848114,
        0.9994068145751953,
        0.9988862872123718,
        0.9989099502563477,
        0.9988521337509155,
        0.9989214837551117,
        0.9988633990287781,
        0.9988895058631897
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
      "selected_checkpoint_seed": 1011,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
          "alignment_to_ref": 0.9994068145751953,
          "explained_variance": 0.5180493593215942,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:32:32+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "e7ff8714bae14dfa1da307bb06be8de1ba76a6f4f2cb0ecf4edbd0c983a71502",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6008084902357144,
                    "test_auc": 0.6010654722672262,
                    "test_f1": 0.5673617775548091
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.596958570726893,
                    "test_auc": 0.630305052365858,
                    "test_f1": 0.571368838587414
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6139254093145695,
                    "test_auc": 0.6392954155264232,
                    "test_f1": 0.596392390315998
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6139254093145695,
                  "test_auc": 0.6392954155264232,
                  "test_f1": 0.596392390315998
                },
                "best_minus_llm_auc": -0.05352105086829129
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:35:03+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "491a3c15c13935c7122597ede518d1a0a857d01de1bd073b117d6a5fe5efd95c",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "96bad52266a644d9fecfecbf4396128e6d2015ab4aa8344d7a063af27af9f919",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.69216621875763,
                "independent_score_mean_max": 15.623788080215455,
                "interpretability_score_mean_max": 14.364149336814881,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:35:03",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.69216621875763,
                "independent_score_mean_max": 15.623788080215455,
                "interpretability_score_mean_max": 14.364149336814881
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.81914121150971,
                "independent_score_mean_max": -35.37547826766968,
                "interpretability_score_mean_max": -33.58746224880218
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05352105086829129,
          "cebench_delta": -33.58746224880218,
          "cebench_interpretability_max": 14.364149336814881,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.7989355576645798,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.1832731970017899,
              "alignment": 0.0,
              "explained_variance": 0.4288915622862265
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt",
          "alignment_to_ref": 0.99943608045578,
          "explained_variance": 0.5158818960189819,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:26:19+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "a83d6a9f19cab7c556fb2dc81e9b80518d944d9c233b29e7472eed82ec36d59c",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5878341661380411,
                    "test_auc": 0.6086008871854737,
                    "test_f1": 0.5507209076080434
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6047083991939219,
                    "test_auc": 0.6210274661691355,
                    "test_f1": 0.5830591919818804
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6129701735324887,
                    "test_auc": 0.6375346183576178,
                    "test_f1": 0.5939422638371942
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6129701735324887,
                  "test_auc": 0.6375346183576178,
                  "test_f1": 0.5939422638371942
                },
                "best_minus_llm_auc": -0.05528184803709668
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:28:48+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "24d7c1893249ce428135f1286ce96f0d32cc5beaadd05586980a0c4d2a58a362",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "0391c45e5ea18df7e66adcaea4ad5d610dfcaf9ccad6d97872dcd96d35e183d9",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.08_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.529748129844666,
                "independent_score_mean_max": 16.251275062561035,
                "interpretability_score_mean_max": 14.238390259742737,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:28:48",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.529748129844666,
                "independent_score_mean_max": 16.251275062561035,
                "interpretability_score_mean_max": 14.238390259742737
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.981559300422674,
                "independent_score_mean_max": -34.7479912853241,
                "interpretability_score_mean_max": -33.71322132587433
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05528184803709668,
          "cebench_delta": -33.71322132587433,
          "cebench_interpretability_max": 14.238390259742737,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.652310821636778,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.8232775217083224,
              "cebench": 0.06239620063953885,
              "alignment": 0.509865005192108,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt",
          "alignment_to_ref": 0.999464213848114,
          "explained_variance": 0.5201324224472046,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:23:16+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "ba0742030afafad5508cd8c966eabf7b569f8e2bab58e16964ed553cd63fe262",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6035507306715023,
                    "test_auc": 0.6143334976588454,
                    "test_f1": 0.5623110373518677
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6022696648496513,
                    "test_auc": 0.6215473079702509,
                    "test_f1": 0.5640224215271035
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6060716734325212,
                    "test_auc": 0.6298006261382599,
                    "test_f1": 0.5757701558039282
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6060716734325212,
                  "test_auc": 0.6298006261382599,
                  "test_f1": 0.5757701558039282
                },
                "best_minus_llm_auc": -0.06301584025645457
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:25:44+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "3b378d990d8f5d1940eb8909190089345ea62bd0f91678d20dba6af8d52ece52",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "0d23c28bc6142eb892c5442851cf955731ff98487abd98b3fcae573f4d3b45be",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.08_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 15.310425510406494,
                "independent_score_mean_max": 16.845168018341063,
                "interpretability_score_mean_max": 15.213862781524659,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:25:44",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 15.310425510406494,
                "independent_score_mean_max": 16.845168018341063,
                "interpretability_score_mean_max": 15.213862781524659
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.20088191986084,
                "independent_score_mean_max": -34.15409832954407,
                "interpretability_score_mean_max": -32.737748804092405
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.06301584025645457,
          "cebench_delta": -32.737748804092405,
          "cebench_interpretability_max": 15.213862781524659,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.27734542510524,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.047055083197271266,
              "cebench": 1.0,
              "alignment": 1.0,
              "explained_variance": 0.8410822541457316
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt",
          "alignment_to_ref": 0.9994238018989563,
          "explained_variance": 0.5209355354309082,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:29:23+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "5f36ad397dbf3d1baaca6d42c0922a62426cc3399b794ae9341fbb345911b953",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5951020187939368,
                    "test_auc": 0.6109618351040809,
                    "test_f1": 0.5658560813541762
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5916353466394714,
                    "test_auc": 0.6120628464006502,
                    "test_f1": 0.5651946659641527
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6069475810991407,
                    "test_auc": 0.629331786757596,
                    "test_f1": 0.5754561847893795
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6069475810991407,
                  "test_auc": 0.629331786757596,
                  "test_f1": 0.5754561847893795
                },
                "best_minus_llm_auc": -0.06348467963711846
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:31:58+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "187407e65ebab39f97dab18e2731e14351b04e78f26139636a37631d1e26781b",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "c6a523a45fca09b69cfbe8d96cc4a061bec5cde56a2d8bf8a19352e21aa2c304",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.08_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.591936388015746,
                "independent_score_mean_max": 15.730177035331726,
                "interpretability_score_mean_max": 14.173473949432372,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:31:57",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.591936388015746,
                "independent_score_mean_max": 15.730177035331726,
                "interpretability_score_mean_max": 14.173473949432372
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.91937104225159,
                "independent_score_mean_max": -35.269089312553405,
                "interpretability_score_mean_max": -33.778137636184695
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.06348467963711846,
          "cebench_delta": -33.778137636184695,
          "cebench_interpretability_max": 14.173473949432372,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.064797507788162,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.0,
              "alignment": 0.29595015576323985,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
        "candidate_tag": "seed1011",
        "saebench": {
          "timestamp_utc": "2026-02-17T14:32:32+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "e7ff8714bae14dfa1da307bb06be8de1ba76a6f4f2cb0ecf4edbd0c983a71502",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6008084902357144,
                "test_auc": 0.6010654722672262,
                "test_f1": 0.5673617775548091
              },
              {
                "k": 2,
                "test_accuracy": 0.596958570726893,
                "test_auc": 0.630305052365858,
                "test_f1": 0.571368838587414
              },
              {
                "k": 5,
                "test_accuracy": 0.6139254093145695,
                "test_auc": 0.6392954155264232,
                "test_f1": 0.596392390315998
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6139254093145695,
              "test_auc": 0.6392954155264232,
              "test_f1": 0.596392390315998
            },
            "best_minus_llm_auc": -0.05352105086829129
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T14:35:03+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "491a3c15c13935c7122597ede518d1a0a857d01de1bd073b117d6a5fe5efd95c",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "96bad52266a644d9fecfecbf4396128e6d2015ab4aa8344d7a063af27af9f919",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 14.69216621875763,
            "independent_score_mean_max": 15.623788080215455,
            "interpretability_score_mean_max": 14.364149336814881,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011",
            "sae_id": "custom_sae",
            "date": "2026-02-17 14:35:03",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 14.69216621875763,
            "independent_score_mean_max": 15.623788080215455,
            "interpretability_score_mean_max": 14.364149336814881
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -35.81914121150971,
            "independent_score_mean_max": -35.37547826766968,
            "interpretability_score_mean_max": -33.58746224880218
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8347434273548424,
        "ev_drop": 0.26709018945693974,
        "ev_neg_drop": -0.26709018945693974,
        "saebench_delta": -0.05352105086829129,
        "cebench_delta": -33.58746224880218,
        "cebench_interpretability_max": 14.364149336814881
      },
      "selection": {
        "joint_score": 0.7481107743721055,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    },
    {
      "lambda_consistency": 0.1,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9992468476295471,
        "std": 0.00023886581625513065,
        "min": 0.9990355670452118,
        "max": 0.9995493292808533,
        "median": 0.9990836828947067,
        "ci95_low": 0.9991079920530319,
        "ci95_high": 0.9993876112997532,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.8352216251194476,
      "delta_pwmcc_ci_low_conservative": 0.8349106998182834,
      "ratio_pwmcc": 6.092031654265984,
      "explained_variance": {
        "mean": 0.5791060209274292,
        "std": 0.15318464653674643,
        "min": 0.5077364444732666,
        "max": 0.8531134128570557,
        "median": 0.5118701457977295,
        "ci95_low": 0.5093899250030518,
        "ci95_high": 0.7164300680160522,
        "n": 5
      },
      "mse": {
        "mean": 0.0003491615687380545,
        "std": 0.0001270776986426151,
        "min": 0.00012185269588371739,
        "max": 0.0004083674284629524,
        "median": 0.00040493832784704864,
        "ci95_low": 0.0002352798022911884,
        "ci95_high": 0.0004069574817549437,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9995235204696655,
        "std": 1.916645410251353e-05,
        "min": 0.9995052814483643,
        "max": 0.9995493292808533,
        "median": 0.9995197355747223,
        "ci95_low": 0.9995094537734985,
        "ci95_high": 0.9995404034852982,
        "n": 4
      },
      "runtime_sec": 1430.774831533432,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9995258450508118,
          "mse": 0.0004047467955388129,
          "explained_variance": 0.5121017694473267,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9130210986326414,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9995136260986328,
          "mse": 0.0004083674284629524,
          "explained_variance": 0.5077364444732666,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9130018554731376,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9995493292808533,
          "mse": 0.00040493832784704864,
          "explained_variance": 0.5118701457977295,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9130613664165139,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9995052814483643,
          "mse": 0.00040590259595774114,
          "explained_variance": 0.5107083320617676,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9130352277964078,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9995259046554565,
        0.9995136260986328,
        0.9995493292808533,
        0.9995052814483643,
        0.9990586638450623,
        0.9990898370742798,
        0.9990452527999878,
        0.9990775287151337,
        0.9990355670452118,
        0.999067485332489
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
      "selected_checkpoint_seed": 1011,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
          "alignment_to_ref": 0.9995052814483643,
          "explained_variance": 0.5107083320617676,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:44:49+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "c690dface618319f2e5550c5ea683feb28167c6dcc1b4fd7c4d825a9fd96a257",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6005670166803218,
                    "test_auc": 0.610328512906832,
                    "test_f1": 0.560869596403959
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5994583508065682,
                    "test_auc": 0.6212511983198329,
                    "test_f1": 0.5613903360397708
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6167744931570085,
                    "test_auc": 0.6453791395072228,
                    "test_f1": 0.5994146554784834
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6167744931570085,
                  "test_auc": 0.6453791395072228,
                  "test_f1": 0.5994146554784834
                },
                "best_minus_llm_auc": -0.04743732688749169
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:47:18+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "3d52b0da409f2cf568e21830ca41dc989c118af2ac9f16d3da4e976d724f6bb5",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "67f87d4a084ff529329bec9a03f006a2840bc5d158a1ca9f4c728e00cc1f1c54",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.53305012702942,
                "independent_score_mean_max": 15.707403116226196,
                "interpretability_score_mean_max": 14.274428329467774,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:47:18",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.53305012702942,
                "independent_score_mean_max": 15.707403116226196,
                "interpretability_score_mean_max": 14.274428329467774
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.97825730323792,
                "independent_score_mean_max": -35.29186323165894,
                "interpretability_score_mean_max": -33.67718325614929
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04743732688749169,
          "cebench_delta": -33.67718325614929,
          "cebench_interpretability_max": 14.274428329467774,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.7962082570378375,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.08112367249580285,
              "alignment": 0.0,
              "explained_variance": 0.6807941232693411
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
          "alignment_to_ref": 0.9995258450508118,
          "explained_variance": 0.5121017694473267,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:38:42+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "a15678ef469de3ed87d0ecd8931606d35a1428a03815359a0f92290d3101ec62",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5857180551684256,
                    "test_auc": 0.5898490248552595,
                    "test_f1": 0.5497016292959489
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5976258767401619,
                    "test_auc": 0.6182818100662946,
                    "test_f1": 0.5617583060413073
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6108792386330605,
                    "test_auc": 0.6370931803979578,
                    "test_f1": 0.5721131684000194
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6108792386330605,
                  "test_auc": 0.6370931803979578,
                  "test_f1": 0.5721131684000194
                },
                "best_minus_llm_auc": -0.05572328599675669
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:41:11+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "0e56d4bf48f77762e8d7598e984c428072dffe4599f1ae90608edd24bdc080e4",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "3c673315941ba48695ade32d013f1fa20e99d927559aaefd558b43f4a21376a5",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.454545342922211,
                "independent_score_mean_max": 15.87158621788025,
                "interpretability_score_mean_max": 14.233841514587402,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:41:11",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.454545342922211,
                "independent_score_mean_max": 15.87158621788025,
                "interpretability_score_mean_max": 14.233841514587402
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.05676208734513,
                "independent_score_mean_max": -35.12768013000488,
                "interpretability_score_mean_max": -33.71777007102966
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05572328599675669,
          "cebench_delta": -33.71777007102966,
          "cebench_interpretability_max": 14.233841514587402,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.32226806614881404,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.3319009488208815,
              "cebench": 0.0,
              "alignment": 0.4668470906630582,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
          "alignment_to_ref": 0.9995493292808533,
          "explained_variance": 0.5118701457977295,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:35:37+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "45dba9bfe33e056e2d15b409257967058cd016b364f703977225dfba167932d1",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6013639660591745,
                    "test_auc": 0.6112161036980954,
                    "test_f1": 0.5556944197807919
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6057861750352806,
                    "test_auc": 0.6193888294894893,
                    "test_f1": 0.5697745452494726
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6090151503413785,
                    "test_auc": 0.6329768481184815,
                    "test_f1": 0.5811284768526122
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6090151503413785,
                  "test_auc": 0.6329768481184815,
                  "test_f1": 0.5811284768526122
                },
                "best_minus_llm_auc": -0.059839618276232964
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:38:08+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "7ccc8168801496d3189507ce2d5976ab9a84af74877a26146afaf8e3bcdc0d5e",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "e8ab6ad2f04b82568dce36ce788ee286f746ba6a9d1ac0861fb9f27de9284492",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.963360185623168,
                "independent_score_mean_max": 16.489828758239746,
                "interpretability_score_mean_max": 14.734149422645569,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:38:07",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.963360185623168,
                "independent_score_mean_max": 16.489828758239746,
                "interpretability_score_mean_max": 14.734149422645569
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.54794724464417,
                "independent_score_mean_max": -34.50943758964539,
                "interpretability_score_mean_max": -33.2174621629715
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.059839618276232964,
          "cebench_delta": -33.2174621629715,
          "cebench_interpretability_max": 14.734149422645569,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.2473470056528032,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 1.0,
              "alignment": 1.0,
              "explained_variance": 0.9469401130560637
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
          "alignment_to_ref": 0.9995136260986328,
          "explained_variance": 0.5077364444732666,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:41:45+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "b46916ae31f36fb7c4849231404eee90530a4e6886cbcec44eaefc1a650feb37",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5934354760787593,
                    "test_auc": 0.60302511348788,
                    "test_f1": 0.557938764186839
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6025555326857831,
                    "test_auc": 0.6164667363208649,
                    "test_f1": 0.5770236893266685
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6143169135212134,
                    "test_auc": 0.634824852518261,
                    "test_f1": 0.59718468201138
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6143169135212134,
                  "test_auc": 0.634824852518261,
                  "test_f1": 0.59718468201138
                },
                "best_minus_llm_auc": -0.05799161387645346
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:44:15+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "69b33b33626adc1552ef6aef823c6dea1e9b72aaae20da1d5e55aa3d97925d9b",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "72ae14220abccf9403ef15747038d3bc7ec4b3c28f2d6a8ff3a1e53d2b0395ea",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.621507120132446,
                "independent_score_mean_max": 16.828977513313294,
                "interpretability_score_mean_max": 14.498566346168518,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:44:15",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.621507120132446,
                "independent_score_mean_max": 16.828977513313294,
                "interpretability_score_mean_max": 14.498566346168518
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.88980031013489,
                "independent_score_mean_max": -34.170288834571835,
                "interpretability_score_mean_max": -33.45304523944855
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05799161387645346,
          "cebench_delta": -33.45304523944855,
          "cebench_interpretability_max": 14.498566346168518,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.20059464158167215,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.14900507832424492,
              "cebench": 0.5291238201862243,
              "alignment": 0.18944519621109607,
              "explained_variance": 0.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
        "candidate_tag": "seed1011",
        "saebench": {
          "timestamp_utc": "2026-02-17T14:44:49+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "c690dface618319f2e5550c5ea683feb28167c6dcc1b4fd7c4d825a9fd96a257",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6005670166803218,
                "test_auc": 0.610328512906832,
                "test_f1": 0.560869596403959
              },
              {
                "k": 2,
                "test_accuracy": 0.5994583508065682,
                "test_auc": 0.6212511983198329,
                "test_f1": 0.5613903360397708
              },
              {
                "k": 5,
                "test_accuracy": 0.6167744931570085,
                "test_auc": 0.6453791395072228,
                "test_f1": 0.5994146554784834
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6167744931570085,
              "test_auc": 0.6453791395072228,
              "test_f1": 0.5994146554784834
            },
            "best_minus_llm_auc": -0.04743732688749169
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T14:47:18+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "3d52b0da409f2cf568e21830ca41dc989c118af2ac9f16d3da4e976d724f6bb5",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "67f87d4a084ff529329bec9a03f006a2840bc5d158a1ca9f4c728e00cc1f1c54",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 14.53305012702942,
            "independent_score_mean_max": 15.707403116226196,
            "interpretability_score_mean_max": 14.274428329467774,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
            "sae_id": "custom_sae",
            "date": "2026-02-17 14:47:18",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 14.53305012702942,
            "independent_score_mean_max": 15.707403116226196,
            "interpretability_score_mean_max": 14.274428329467774
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -35.97825730323792,
            "independent_score_mean_max": -35.29186323165894,
            "interpretability_score_mean_max": -33.67718325614929
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8349106998182834,
        "ev_drop": 0.2736066937446594,
        "ev_neg_drop": -0.2736066937446594,
        "saebench_delta": -0.04743732688749169,
        "cebench_delta": -33.67718325614929,
        "cebench_interpretability_max": 14.274428329467774
      },
      "selection": {
        "joint_score": 0.884928575903846,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    },
    {
      "lambda_consistency": 0.15,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9994587928056717,
        "std": 0.00017226819902102904,
        "min": 0.9993079304695129,
        "max": 0.9996694922447205,
        "median": 0.9993388652801514,
        "ci95_low": 0.9993587650358677,
        "ci95_high": 0.9995604160428048,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.8354335702955723,
      "delta_pwmcc_ci_low_conservative": 0.8351614728011192,
      "ratio_pwmcc": 6.093323804173671,
      "explained_variance": {
        "mean": 0.565224289894104,
        "std": 0.16094904729961712,
        "min": 0.4896153211593628,
        "max": 0.8531134128570557,
        "median": 0.4942736029624939,
        "ci95_low": 0.4916369080543518,
        "ci95_high": 0.7095346933603287,
        "n": 5
      },
      "mse": {
        "mean": 0.00036067761684535073,
        "std": 0.00013351891089684233,
        "min": 0.00012185269588371739,
        "max": 0.00042340013897046447,
        "median": 0.00041953640175051987,
        "ci95_low": 0.00024096263368846848,
        "ci95_high": 0.00042172339744865893,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9996585100889206,
        "std": 1.0344268327548307e-05,
        "min": 0.9996452331542969,
        "max": 0.9996694922447205,
        "median": 0.9996596574783325,
        "ci95_low": 0.9996496587991714,
        "ci95_high": 0.9996662139892578,
        "n": 4
      },
      "runtime_sec": 1429.9556584358215,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9996563792228699,
          "mse": 0.0004197186790406704,
          "explained_variance": 0.4940541386604309,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9135211912259735,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9996694922447205,
          "mse": 0.00042340013897046447,
          "explained_variance": 0.4896153211593628,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.913505043886188,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9996629357337952,
          "mse": 0.00041888016858138144,
          "explained_variance": 0.49506497383117676,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9135338068870759,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9996452331542969,
          "mse": 0.00041953640175051987,
          "explained_variance": 0.4942736029624939,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9135304855148273,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9996564388275146,
        0.9996694922447205,
        0.9996629059314728,
        0.9996452331542969,
        0.9993362128734589,
        0.9993308782577515,
        0.9993079304695129,
        0.9993415176868439,
        0.9993225932121277,
        0.9993147253990173
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
      "selected_checkpoint_seed": 1011,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
          "alignment_to_ref": 0.9996452331542969,
          "explained_variance": 0.4942736029624939,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:56:57+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "7a86bd4992558cdc77d73b1cc6829b651f9855ec3c6e3044b199dac185cecc08",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6006991067498302,
                    "test_auc": 0.6054523472040786,
                    "test_f1": 0.5591604987435893
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6107239180883893,
                    "test_auc": 0.6315869251397795,
                    "test_f1": 0.5830891325183166
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6212830945545705,
                    "test_auc": 0.6434163861661613,
                    "test_f1": 0.601674809829184
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6212830945545705,
                  "test_auc": 0.6434163861661613,
                  "test_f1": 0.601674809829184
                },
                "best_minus_llm_auc": -0.049400080228553245
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:59:25+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "d53e20c400a347cd0b369cd878f8439b6ffd5623df64ee93efe36aa32f66ac24",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "8c8baf8291e6173362af86db0f7ee6a6589636731dc4b82dc7d009090a7e762a",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.078473398685455,
                "independent_score_mean_max": 15.712986750602722,
                "interpretability_score_mean_max": 13.888679838180542,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:59:24",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.078473398685455,
                "independent_score_mean_max": 15.712986750602722,
                "interpretability_score_mean_max": 13.888679838180542
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.43283403158188,
                "independent_score_mean_max": -35.28627959728241,
                "interpretability_score_mean_max": -34.06293174743652
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.049400080228553245,
          "cebench_delta": -34.06293174743652,
          "cebench_interpretability_max": 13.888679838180542,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.7927392540741551,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.0,
              "alignment": 0.0,
              "explained_variance": 0.8547850814831018
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt",
          "alignment_to_ref": 0.9996694922447205,
          "explained_variance": 0.4896153211593628,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:47:53+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "2c8e2e28f023133894534f66a93c8a8a2ba356ee999258ff727afb35acacca74",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.588827477867384,
                    "test_auc": 0.606022176007571,
                    "test_f1": 0.5496855766748145
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6010191944462877,
                    "test_auc": 0.6222711641225226,
                    "test_f1": 0.5730470827157904
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6048595574570451,
                    "test_auc": 0.6370757538876025,
                    "test_f1": 0.5859276944127422
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6048595574570451,
                  "test_auc": 0.6370757538876025,
                  "test_f1": 0.5859276944127422
                },
                "best_minus_llm_auc": -0.05574071250711199
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:50:21+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "b25c06375ccee55ff8c9aaff575f8204b39f1624bc9cdcafd0e646a1b06d562b",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "a5525f971b054a2867279c9b724f8f82908efca82d2a7765f09b5916ee3e6ecc",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.15_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.163305993080138,
                "independent_score_mean_max": 16.445481567382814,
                "interpretability_score_mean_max": 14.228761715888977,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:50:21",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.163305993080138,
                "independent_score_mean_max": 16.445481567382814,
                "interpretability_score_mean_max": 14.228761715888977
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.3480014371872,
                "independent_score_mean_max": -34.55378478050232,
                "interpretability_score_mean_max": -33.72284986972809
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05574071250711199,
          "cebench_delta": -33.72284986972809,
          "cebench_interpretability_max": 14.228761715888977,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.41654467355018515,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.3893669272954621,
              "cebench": 0.49679652052392387,
              "alignment": 1.0,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt",
          "alignment_to_ref": 0.9996563792228699,
          "explained_variance": 0.4940541386604309,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:53:54+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "7094bd294940f51cc03c17a1d9204c8c9d9c08977c6730f3b69531f00a47ea11",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5902357922436835,
                    "test_auc": 0.6066816778589407,
                    "test_f1": 0.5469513823369552
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5975346759193501,
                    "test_auc": 0.6162438966654439,
                    "test_f1": 0.5611947466102771
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6068551933871391,
                    "test_auc": 0.6349406548351108,
                    "test_f1": 0.5764170661341987
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6068551933871391,
                  "test_auc": 0.6349406548351108,
                  "test_f1": 0.5764170661341987
                },
                "best_minus_llm_auc": -0.05787581155960375
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:56:23+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "4b6841ef8016ed4ca86ea2d29721394c6130a02d6ba03ee7319d2d9c3f1d005c",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "3608a87c8ea7448767a89690787c5e69c2413dd13e7164d23634b4bae416037e",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.15_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.678274207115173,
                "independent_score_mean_max": 16.091999282836912,
                "interpretability_score_mean_max": 14.360926089286805,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:56:23",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.678274207115173,
                "independent_score_mean_max": 16.091999282836912,
                "interpretability_score_mean_max": 14.360926089286805
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.833033223152164,
                "independent_score_mean_max": -34.90726706504822,
                "interpretability_score_mean_max": -33.59068549633026
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05787581155960375,
          "cebench_delta": -33.59068549633026,
          "cebench_interpretability_max": 14.360926089286805,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.30498833014397153,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.18374672450269838,
              "cebench": 0.689864146719393,
              "alignment": 0.4594594594594595,
              "explained_variance": 0.8145138357213169
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt",
          "alignment_to_ref": 0.9996629357337952,
          "explained_variance": 0.49506497383117676,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:50:55+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "0f76348d14fb55d724938c8702d70be6e0737539187f1229c79346b5657f8e75",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5898871666588792,
                    "test_auc": 0.5899650946147676,
                    "test_f1": 0.5427584633811429
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5991539899512263,
                    "test_auc": 0.621235368158471,
                    "test_f1": 0.5570366375940453
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6108518891125181,
                    "test_auc": 0.6330326834779403,
                    "test_f1": 0.5908910024358591
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6108518891125181,
                  "test_auc": 0.6330326834779403,
                  "test_f1": 0.5908910024358591
                },
                "best_minus_llm_auc": -0.05978378291677422
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:53:19+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "2c71fefa1b76991daf57ae88915bc51504c885db6c4c372bbcd9c1c730d6fffb",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "fa4456d4a94f6857c5c2f7e9717fc1e7184211fdb187a5733667745fa50ffab7",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.15_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.65447340965271,
                "independent_score_mean_max": 16.609899797439574,
                "interpretability_score_mean_max": 14.573229475021362,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:53:19",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.65447340965271,
                "independent_score_mean_max": 16.609899797439574,
                "interpretability_score_mean_max": 14.573229475021362
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.85683402061463,
                "independent_score_mean_max": -34.38936655044556,
                "interpretability_score_mean_max": -33.3783821105957
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05978378291677422,
          "cebench_delta": -33.3783821105957,
          "cebench_interpretability_max": 14.573229475021362,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.23648648648648646,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 1.0,
              "alignment": 0.7297297297297297,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
        "candidate_tag": "seed1011",
        "saebench": {
          "timestamp_utc": "2026-02-17T14:56:57+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "7a86bd4992558cdc77d73b1cc6829b651f9855ec3c6e3044b199dac185cecc08",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6006991067498302,
                "test_auc": 0.6054523472040786,
                "test_f1": 0.5591604987435893
              },
              {
                "k": 2,
                "test_accuracy": 0.6107239180883893,
                "test_auc": 0.6315869251397795,
                "test_f1": 0.5830891325183166
              },
              {
                "k": 5,
                "test_accuracy": 0.6212830945545705,
                "test_auc": 0.6434163861661613,
                "test_f1": 0.601674809829184
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6212830945545705,
              "test_auc": 0.6434163861661613,
              "test_f1": 0.601674809829184
            },
            "best_minus_llm_auc": -0.049400080228553245
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T14:59:25+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "d53e20c400a347cd0b369cd878f8439b6ffd5623df64ee93efe36aa32f66ac24",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "8c8baf8291e6173362af86db0f7ee6a6589636731dc4b82dc7d009090a7e762a",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 14.078473398685455,
            "independent_score_mean_max": 15.712986750602722,
            "interpretability_score_mean_max": 13.888679838180542,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011",
            "sae_id": "custom_sae",
            "date": "2026-02-17 14:59:24",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 14.078473398685455,
            "independent_score_mean_max": 15.712986750602722,
            "interpretability_score_mean_max": 13.888679838180542
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -36.43283403158188,
            "independent_score_mean_max": -35.28627959728241,
            "interpretability_score_mean_max": -34.06293174743652
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8351614728011192,
        "ev_drop": 0.28748842477798464,
        "ev_neg_drop": -0.28748842477798464,
        "saebench_delta": -0.049400080228553245,
        "cebench_delta": -34.06293174743652,
        "cebench_interpretability_max": 13.888679838180542
      },
      "selection": {
        "joint_score": 0.8239971731909919,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    },
    {
      "lambda_consistency": 0.2,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9995654344558715,
        "std": 0.00013859488359840204,
        "min": 0.9994481205940247,
        "max": 0.9997372329235077,
        "median": 0.9994682967662811,
        "ci95_low": 0.9994847591221332,
        "ci95_high": 0.9996469320356846,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.8355402119457721,
      "delta_pwmcc_ci_low_conservative": 0.8352874668873846,
      "ratio_pwmcc": 6.093973958147358,
      "explained_variance": {
        "mean": 0.5555011987686157,
        "std": 0.16637817805189847,
        "min": 0.478765070438385,
        "max": 0.8531134128570557,
        "median": 0.482511043548584,
        "ci95_low": 0.4798823356628418,
        "ci95_high": 0.7044913411140442,
        "n": 5
      },
      "mse": {
        "mean": 0.000368743714352604,
        "std": 0.0001380228182910353,
        "min": 0.00012185269588371739,
        "max": 0.00043240131344646215,
        "median": 0.00042929573100991547,
        "ci95_low": 0.0002451783584547229,
        "ci95_high": 0.0004312348610255867,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9997261762619019,
        "std": 7.632653464226619e-06,
        "min": 0.9997198581695557,
        "max": 0.9997372031211853,
        "median": 0.9997238218784332,
        "ci95_low": 0.999721109867096,
        "ci95_high": 0.9997335970401764,
        "n": 4
      },
      "runtime_sec": 1428.0716757774353,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt",
          "lambda_consistency": 0.2,
          "alignment_to_ref": 0.9997372031211853,
          "mse": 0.00042929573100991547,
          "explained_variance": 0.482511043548584,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9137663184147742,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt",
          "lambda_consistency": 0.2,
          "alignment_to_ref": 0.9997227787971497,
          "mse": 0.00043240131344646215,
          "explained_variance": 0.478765070438385,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9137462373926408,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt",
          "lambda_consistency": 0.2,
          "alignment_to_ref": 0.9997248649597168,
          "mse": 0.0004291308578103781,
          "explained_variance": 0.4827076196670532,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9137652566725457,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
          "lambda_consistency": 0.2,
          "alignment_to_ref": 0.9997198581695557,
          "mse": 0.0004310379736125469,
          "explained_variance": 0.48040884733200073,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.913778047060111,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9997372329235077,
        0.9997227489948273,
        0.9997248649597168,
        0.999719887971878,
        0.9994661808013916,
        0.9994704127311707,
        0.9994618594646454,
        0.9994543194770813,
        0.9994481205940247,
        0.9994487166404724
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
      "selected_checkpoint_seed": 1011,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
          "alignment_to_ref": 0.9997198581695557,
          "explained_variance": 0.48040884733200073,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T15:08:58+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "1734d0c3732de1dbb273a65531dccd04fa71eb2e17b5623849f487ac2b9c8401",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.7881393432617188e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6035841638347159,
                    "test_auc": 0.6177526454058861,
                    "test_f1": 0.5561840981880544
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6125719937623532,
                    "test_auc": 0.6300517613759598,
                    "test_f1": 0.5760787124875978
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6127867447088708,
                    "test_auc": 0.6421026345680163,
                    "test_f1": 0.5941668238141362
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6127867447088708,
                  "test_auc": 0.6421026345680163,
                  "test_f1": 0.5941668238141362
                },
                "best_minus_llm_auc": -0.0507138318266982
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T15:11:07+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "e0e9fea6ceb18a20bd9e95ca67ef08bd558f98519f06a777b0845a0987e41557",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "efa1ea9f898742938f87b77f78b24bfdd0a714a184cd3bc29257a6615d5e9294",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.7881393432617188e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 16.051321711540222,
                "independent_score_mean_max": 16.977635536193848,
                "interpretability_score_mean_max": 16.291307973861695,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 15:11:07",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 16.051321711540222,
                "independent_score_mean_max": 16.977635536193848,
                "interpretability_score_mean_max": 16.291307973861695
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -34.45998571872711,
                "independent_score_mean_max": -34.02163081169128,
                "interpretability_score_mean_max": -31.66030361175537
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.0507138318266982,
          "cebench_delta": -31.66030361175537,
          "cebench_interpretability_max": 16.291307973861695,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8975217129334486,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.968900117458774,
              "cebench": 1.0,
              "alignment": 0.0,
              "explained_variance": 0.4169324967873611
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt",
          "alignment_to_ref": 0.9997372031211853,
          "explained_variance": 0.482511043548584,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:59:59+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "1a23b825eb49ee1fe174a626ee099fe94324d378c9094bf206107b652f402d1e",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5784967500433654,
                    "test_auc": 0.5940343071376452,
                    "test_f1": 0.5377764235437756
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6011172766107579,
                    "test_auc": 0.6142925448732075,
                    "test_f1": 0.57443744003793
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6138099050236868,
                    "test_auc": 0.6425124161194115,
                    "test_f1": 0.5955063789764061
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6138099050236868,
                  "test_auc": 0.6425124161194115,
                  "test_f1": 0.5955063789764061
                },
                "best_minus_llm_auc": -0.05030405027530305
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T15:02:24+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "a88c8dab0b381044b75071b732522e81801e4c1bab60c8d04ceb33a1fd0ce0a0",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "2c6d0f7f1461e56c52554faf9d500a12face76cfda31c0fa5411a91abfad51b9",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.2_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.344642190933227,
                "independent_score_mean_max": 16.04955201625824,
                "interpretability_score_mean_max": 14.150790357589722,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 15:02:24",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.344642190933227,
                "independent_score_mean_max": 16.04955201625824,
                "interpretability_score_mean_max": 14.150790357589722
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.16666523933411,
                "independent_score_mean_max": -34.94971433162689,
                "interpretability_score_mean_max": -33.800821228027345
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05030405027530305,
          "cebench_delta": -33.800821228027345,
          "cebench_interpretability_max": 14.150790357589722,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8518972910221856,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.02926865872073572,
              "alignment": 1.0,
              "explained_variance": 0.9501398442815028
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt",
          "alignment_to_ref": 0.9997227787971497,
          "explained_variance": 0.478765070438385,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T15:05:56+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "2e9191197bd7f8cc8f59f3fd40882592ada6c4c7dccced87ad7e61b63d9784e5",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5997531635726936,
                    "test_auc": 0.6086304849830424,
                    "test_f1": 0.5598049238870679
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6012001959739481,
                    "test_auc": 0.6162582953210269,
                    "test_f1": 0.5742629779832751
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6102373929218674,
                    "test_auc": 0.6348628371091691,
                    "test_f1": 0.5913518831792549
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6102373929218674,
                  "test_auc": 0.6348628371091691,
                  "test_f1": 0.5913518831792549
                },
                "best_minus_llm_auc": -0.05795362928554537
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T15:08:23+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "9eb770334bd4d82833f39466f91299a27773efc7f55591d74d3bd5a376aa2ecf",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "d3674a8a5e965c8d7fd8422a97fcf15881264ae34cf22b03b80e6f1690b24f9d",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.2_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.27119710445404,
                "independent_score_mean_max": 16.285932083129882,
                "interpretability_score_mean_max": 14.086251306533814,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 15:08:23",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.27119710445404,
                "independent_score_mean_max": 16.285932083129882,
                "interpretability_score_mean_max": 14.086251306533814
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.2401103258133,
                "independent_score_mean_max": -34.71333426475525,
                "interpretability_score_mean_max": -33.86536027908325
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05795362928554537,
          "cebench_delta": -33.86536027908325,
          "cebench_interpretability_max": 14.086251306533814,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.32300248126523473,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.4194443163719739,
              "cebench": 0.0,
              "alignment": 0.16838487972508592,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt",
          "alignment_to_ref": 0.9997248649597168,
          "explained_variance": 0.4827076196670532,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T15:02:59+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "a4ab6b847894b2256a01378e11ba6775c6660ca9ffbb93ff62519fcd5d2188c7",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5988745985849107,
                    "test_auc": 0.60919939809392,
                    "test_f1": 0.5470218802722566
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5961715665469506,
                    "test_auc": 0.6170797443169445,
                    "test_f1": 0.5547850088894999
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.5981226481197492,
                    "test_auc": 0.6293361106831468,
                    "test_f1": 0.5762340054425952
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.5981226481197492,
                  "test_auc": 0.6293361106831468,
                  "test_f1": 0.5762340054425952
                },
                "best_minus_llm_auc": -0.06348035571156774
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T15:05:22+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "4b4b99b113b199e530d6651ee166c5120c7a72e569e18e7ca90b0a48bb1f145b",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "23c7c5e69a44e6bdc67d0668abb02ef54c08bb0f14c0b292029b6e5b14a8bd3a",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.2_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.962849588394166,
                "independent_score_mean_max": 16.97179027557373,
                "interpretability_score_mean_max": 14.961721000671387,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 15:05:22",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.962849588394166,
                "independent_score_mean_max": 16.97179027557373,
                "interpretability_score_mean_max": 14.961721000671387
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.54845784187317,
                "independent_score_mean_max": -34.0274760723114,
                "interpretability_score_mean_max": -32.98989058494568
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.06348035571156774,
          "cebench_delta": -32.98989058494568,
          "cebench_interpretability_max": 14.961721000671387,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.12398722068459987,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.3970282066258548,
              "alignment": 0.28865979381443296,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
        "candidate_tag": "seed1011",
        "saebench": {
          "timestamp_utc": "2026-02-17T15:08:58+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "1734d0c3732de1dbb273a65531dccd04fa71eb2e17b5623849f487ac2b9c8401",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.7881393432617188e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6035841638347159,
                "test_auc": 0.6177526454058861,
                "test_f1": 0.5561840981880544
              },
              {
                "k": 2,
                "test_accuracy": 0.6125719937623532,
                "test_auc": 0.6300517613759598,
                "test_f1": 0.5760787124875978
              },
              {
                "k": 5,
                "test_accuracy": 0.6127867447088708,
                "test_auc": 0.6421026345680163,
                "test_f1": 0.5941668238141362
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6127867447088708,
              "test_auc": 0.6421026345680163,
              "test_f1": 0.5941668238141362
            },
            "best_minus_llm_auc": -0.0507138318266982
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T15:11:07+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "e0e9fea6ceb18a20bd9e95ca67ef08bd558f98519f06a777b0845a0987e41557",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "efa1ea9f898742938f87b77f78b24bfdd0a714a184cd3bc29257a6615d5e9294",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.7881393432617188e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 16.051321711540222,
            "independent_score_mean_max": 16.977635536193848,
            "interpretability_score_mean_max": 16.291307973861695,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011",
            "sae_id": "custom_sae",
            "date": "2026-02-17 15:11:07",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 16.051321711540222,
            "independent_score_mean_max": 16.977635536193848,
            "interpretability_score_mean_max": 16.291307973861695
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -34.45998571872711,
            "independent_score_mean_max": -34.02163081169128,
            "interpretability_score_mean_max": -31.66030361175537
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8352874668873846,
        "ev_drop": 0.29721151590347294,
        "ev_neg_drop": -0.29721151590347294,
        "saebench_delta": -0.0507138318266982,
        "cebench_delta": -31.66030361175537,
        "cebench_interpretability_max": 16.291307973861695
      },
      "selection": {
        "joint_score": 0.8740940564177333,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    }
  ],
  "ranked": [
    {
      "lambda_consistency": 0.1,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9992468476295471,
        "std": 0.00023886581625513065,
        "min": 0.9990355670452118,
        "max": 0.9995493292808533,
        "median": 0.9990836828947067,
        "ci95_low": 0.9991079920530319,
        "ci95_high": 0.9993876112997532,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.8352216251194476,
      "delta_pwmcc_ci_low_conservative": 0.8349106998182834,
      "ratio_pwmcc": 6.092031654265984,
      "explained_variance": {
        "mean": 0.5791060209274292,
        "std": 0.15318464653674643,
        "min": 0.5077364444732666,
        "max": 0.8531134128570557,
        "median": 0.5118701457977295,
        "ci95_low": 0.5093899250030518,
        "ci95_high": 0.7164300680160522,
        "n": 5
      },
      "mse": {
        "mean": 0.0003491615687380545,
        "std": 0.0001270776986426151,
        "min": 0.00012185269588371739,
        "max": 0.0004083674284629524,
        "median": 0.00040493832784704864,
        "ci95_low": 0.0002352798022911884,
        "ci95_high": 0.0004069574817549437,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9995235204696655,
        "std": 1.916645410251353e-05,
        "min": 0.9995052814483643,
        "max": 0.9995493292808533,
        "median": 0.9995197355747223,
        "ci95_low": 0.9995094537734985,
        "ci95_high": 0.9995404034852982,
        "n": 4
      },
      "runtime_sec": 1430.774831533432,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9995258450508118,
          "mse": 0.0004047467955388129,
          "explained_variance": 0.5121017694473267,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9130210986326414,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9995136260986328,
          "mse": 0.0004083674284629524,
          "explained_variance": 0.5077364444732666,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9130018554731376,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9995493292808533,
          "mse": 0.00040493832784704864,
          "explained_variance": 0.5118701457977295,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9130613664165139,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9995052814483643,
          "mse": 0.00040590259595774114,
          "explained_variance": 0.5107083320617676,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9130352277964078,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9995259046554565,
        0.9995136260986328,
        0.9995493292808533,
        0.9995052814483643,
        0.9990586638450623,
        0.9990898370742798,
        0.9990452527999878,
        0.9990775287151337,
        0.9990355670452118,
        0.999067485332489
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
      "selected_checkpoint_seed": 1011,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
          "alignment_to_ref": 0.9995052814483643,
          "explained_variance": 0.5107083320617676,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:44:49+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "c690dface618319f2e5550c5ea683feb28167c6dcc1b4fd7c4d825a9fd96a257",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6005670166803218,
                    "test_auc": 0.610328512906832,
                    "test_f1": 0.560869596403959
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5994583508065682,
                    "test_auc": 0.6212511983198329,
                    "test_f1": 0.5613903360397708
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6167744931570085,
                    "test_auc": 0.6453791395072228,
                    "test_f1": 0.5994146554784834
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6167744931570085,
                  "test_auc": 0.6453791395072228,
                  "test_f1": 0.5994146554784834
                },
                "best_minus_llm_auc": -0.04743732688749169
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:47:18+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "3d52b0da409f2cf568e21830ca41dc989c118af2ac9f16d3da4e976d724f6bb5",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "67f87d4a084ff529329bec9a03f006a2840bc5d158a1ca9f4c728e00cc1f1c54",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.53305012702942,
                "independent_score_mean_max": 15.707403116226196,
                "interpretability_score_mean_max": 14.274428329467774,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:47:18",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.53305012702942,
                "independent_score_mean_max": 15.707403116226196,
                "interpretability_score_mean_max": 14.274428329467774
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.97825730323792,
                "independent_score_mean_max": -35.29186323165894,
                "interpretability_score_mean_max": -33.67718325614929
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04743732688749169,
          "cebench_delta": -33.67718325614929,
          "cebench_interpretability_max": 14.274428329467774,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.7962082570378375,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.08112367249580285,
              "alignment": 0.0,
              "explained_variance": 0.6807941232693411
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
          "alignment_to_ref": 0.9995258450508118,
          "explained_variance": 0.5121017694473267,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:38:42+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "a15678ef469de3ed87d0ecd8931606d35a1428a03815359a0f92290d3101ec62",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5857180551684256,
                    "test_auc": 0.5898490248552595,
                    "test_f1": 0.5497016292959489
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5976258767401619,
                    "test_auc": 0.6182818100662946,
                    "test_f1": 0.5617583060413073
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6108792386330605,
                    "test_auc": 0.6370931803979578,
                    "test_f1": 0.5721131684000194
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6108792386330605,
                  "test_auc": 0.6370931803979578,
                  "test_f1": 0.5721131684000194
                },
                "best_minus_llm_auc": -0.05572328599675669
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:41:11+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "0e56d4bf48f77762e8d7598e984c428072dffe4599f1ae90608edd24bdc080e4",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "3c673315941ba48695ade32d013f1fa20e99d927559aaefd558b43f4a21376a5",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.454545342922211,
                "independent_score_mean_max": 15.87158621788025,
                "interpretability_score_mean_max": 14.233841514587402,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:41:11",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.454545342922211,
                "independent_score_mean_max": 15.87158621788025,
                "interpretability_score_mean_max": 14.233841514587402
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.05676208734513,
                "independent_score_mean_max": -35.12768013000488,
                "interpretability_score_mean_max": -33.71777007102966
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05572328599675669,
          "cebench_delta": -33.71777007102966,
          "cebench_interpretability_max": 14.233841514587402,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.32226806614881404,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.3319009488208815,
              "cebench": 0.0,
              "alignment": 0.4668470906630582,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
          "alignment_to_ref": 0.9995493292808533,
          "explained_variance": 0.5118701457977295,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:35:37+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "45dba9bfe33e056e2d15b409257967058cd016b364f703977225dfba167932d1",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6013639660591745,
                    "test_auc": 0.6112161036980954,
                    "test_f1": 0.5556944197807919
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6057861750352806,
                    "test_auc": 0.6193888294894893,
                    "test_f1": 0.5697745452494726
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6090151503413785,
                    "test_auc": 0.6329768481184815,
                    "test_f1": 0.5811284768526122
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6090151503413785,
                  "test_auc": 0.6329768481184815,
                  "test_f1": 0.5811284768526122
                },
                "best_minus_llm_auc": -0.059839618276232964
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:38:08+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "7ccc8168801496d3189507ce2d5976ab9a84af74877a26146afaf8e3bcdc0d5e",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "e8ab6ad2f04b82568dce36ce788ee286f746ba6a9d1ac0861fb9f27de9284492",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.963360185623168,
                "independent_score_mean_max": 16.489828758239746,
                "interpretability_score_mean_max": 14.734149422645569,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:38:07",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.963360185623168,
                "independent_score_mean_max": 16.489828758239746,
                "interpretability_score_mean_max": 14.734149422645569
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.54794724464417,
                "independent_score_mean_max": -34.50943758964539,
                "interpretability_score_mean_max": -33.2174621629715
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.059839618276232964,
          "cebench_delta": -33.2174621629715,
          "cebench_interpretability_max": 14.734149422645569,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.2473470056528032,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 1.0,
              "alignment": 1.0,
              "explained_variance": 0.9469401130560637
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
          "alignment_to_ref": 0.9995136260986328,
          "explained_variance": 0.5077364444732666,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:41:45+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "b46916ae31f36fb7c4849231404eee90530a4e6886cbcec44eaefc1a650feb37",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5934354760787593,
                    "test_auc": 0.60302511348788,
                    "test_f1": 0.557938764186839
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6025555326857831,
                    "test_auc": 0.6164667363208649,
                    "test_f1": 0.5770236893266685
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6143169135212134,
                    "test_auc": 0.634824852518261,
                    "test_f1": 0.59718468201138
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6143169135212134,
                  "test_auc": 0.634824852518261,
                  "test_f1": 0.59718468201138
                },
                "best_minus_llm_auc": -0.05799161387645346
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:44:15+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "69b33b33626adc1552ef6aef823c6dea1e9b72aaae20da1d5e55aa3d97925d9b",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "72ae14220abccf9403ef15747038d3bc7ec4b3c28f2d6a8ff3a1e53d2b0395ea",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.621507120132446,
                "independent_score_mean_max": 16.828977513313294,
                "interpretability_score_mean_max": 14.498566346168518,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:44:15",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.621507120132446,
                "independent_score_mean_max": 16.828977513313294,
                "interpretability_score_mean_max": 14.498566346168518
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.88980031013489,
                "independent_score_mean_max": -34.170288834571835,
                "interpretability_score_mean_max": -33.45304523944855
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05799161387645346,
          "cebench_delta": -33.45304523944855,
          "cebench_interpretability_max": 14.498566346168518,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.20059464158167215,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.14900507832424492,
              "cebench": 0.5291238201862243,
              "alignment": 0.18944519621109607,
              "explained_variance": 0.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
        "candidate_tag": "seed1011",
        "saebench": {
          "timestamp_utc": "2026-02-17T14:44:49+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "c690dface618319f2e5550c5ea683feb28167c6dcc1b4fd7c4d825a9fd96a257",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6005670166803218,
                "test_auc": 0.610328512906832,
                "test_f1": 0.560869596403959
              },
              {
                "k": 2,
                "test_accuracy": 0.5994583508065682,
                "test_auc": 0.6212511983198329,
                "test_f1": 0.5613903360397708
              },
              {
                "k": 5,
                "test_accuracy": 0.6167744931570085,
                "test_auc": 0.6453791395072228,
                "test_f1": 0.5994146554784834
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6167744931570085,
              "test_auc": 0.6453791395072228,
              "test_f1": 0.5994146554784834
            },
            "best_minus_llm_auc": -0.04743732688749169
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T14:47:18+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "3d52b0da409f2cf568e21830ca41dc989c118af2ac9f16d3da4e976d724f6bb5",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "67f87d4a084ff529329bec9a03f006a2840bc5d158a1ca9f4c728e00cc1f1c54",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 14.53305012702942,
            "independent_score_mean_max": 15.707403116226196,
            "interpretability_score_mean_max": 14.274428329467774,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
            "sae_id": "custom_sae",
            "date": "2026-02-17 14:47:18",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 14.53305012702942,
            "independent_score_mean_max": 15.707403116226196,
            "interpretability_score_mean_max": 14.274428329467774
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -35.97825730323792,
            "independent_score_mean_max": -35.29186323165894,
            "interpretability_score_mean_max": -33.67718325614929
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8349106998182834,
        "ev_drop": 0.2736066937446594,
        "ev_neg_drop": -0.2736066937446594,
        "saebench_delta": -0.04743732688749169,
        "cebench_delta": -33.67718325614929,
        "cebench_interpretability_max": 14.274428329467774
      },
      "selection": {
        "joint_score": 0.884928575903846,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    },
    {
      "lambda_consistency": 0.2,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9995654344558715,
        "std": 0.00013859488359840204,
        "min": 0.9994481205940247,
        "max": 0.9997372329235077,
        "median": 0.9994682967662811,
        "ci95_low": 0.9994847591221332,
        "ci95_high": 0.9996469320356846,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.8355402119457721,
      "delta_pwmcc_ci_low_conservative": 0.8352874668873846,
      "ratio_pwmcc": 6.093973958147358,
      "explained_variance": {
        "mean": 0.5555011987686157,
        "std": 0.16637817805189847,
        "min": 0.478765070438385,
        "max": 0.8531134128570557,
        "median": 0.482511043548584,
        "ci95_low": 0.4798823356628418,
        "ci95_high": 0.7044913411140442,
        "n": 5
      },
      "mse": {
        "mean": 0.000368743714352604,
        "std": 0.0001380228182910353,
        "min": 0.00012185269588371739,
        "max": 0.00043240131344646215,
        "median": 0.00042929573100991547,
        "ci95_low": 0.0002451783584547229,
        "ci95_high": 0.0004312348610255867,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9997261762619019,
        "std": 7.632653464226619e-06,
        "min": 0.9997198581695557,
        "max": 0.9997372031211853,
        "median": 0.9997238218784332,
        "ci95_low": 0.999721109867096,
        "ci95_high": 0.9997335970401764,
        "n": 4
      },
      "runtime_sec": 1428.0716757774353,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt",
          "lambda_consistency": 0.2,
          "alignment_to_ref": 0.9997372031211853,
          "mse": 0.00042929573100991547,
          "explained_variance": 0.482511043548584,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9137663184147742,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt",
          "lambda_consistency": 0.2,
          "alignment_to_ref": 0.9997227787971497,
          "mse": 0.00043240131344646215,
          "explained_variance": 0.478765070438385,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9137462373926408,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt",
          "lambda_consistency": 0.2,
          "alignment_to_ref": 0.9997248649597168,
          "mse": 0.0004291308578103781,
          "explained_variance": 0.4827076196670532,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9137652566725457,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
          "lambda_consistency": 0.2,
          "alignment_to_ref": 0.9997198581695557,
          "mse": 0.0004310379736125469,
          "explained_variance": 0.48040884733200073,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.913778047060111,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9997372329235077,
        0.9997227489948273,
        0.9997248649597168,
        0.999719887971878,
        0.9994661808013916,
        0.9994704127311707,
        0.9994618594646454,
        0.9994543194770813,
        0.9994481205940247,
        0.9994487166404724
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
      "selected_checkpoint_seed": 1011,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
          "alignment_to_ref": 0.9997198581695557,
          "explained_variance": 0.48040884733200073,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T15:08:58+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "1734d0c3732de1dbb273a65531dccd04fa71eb2e17b5623849f487ac2b9c8401",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.7881393432617188e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6035841638347159,
                    "test_auc": 0.6177526454058861,
                    "test_f1": 0.5561840981880544
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6125719937623532,
                    "test_auc": 0.6300517613759598,
                    "test_f1": 0.5760787124875978
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6127867447088708,
                    "test_auc": 0.6421026345680163,
                    "test_f1": 0.5941668238141362
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6127867447088708,
                  "test_auc": 0.6421026345680163,
                  "test_f1": 0.5941668238141362
                },
                "best_minus_llm_auc": -0.0507138318266982
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T15:11:07+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "e0e9fea6ceb18a20bd9e95ca67ef08bd558f98519f06a777b0845a0987e41557",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "efa1ea9f898742938f87b77f78b24bfdd0a714a184cd3bc29257a6615d5e9294",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.7881393432617188e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 16.051321711540222,
                "independent_score_mean_max": 16.977635536193848,
                "interpretability_score_mean_max": 16.291307973861695,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 15:11:07",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 16.051321711540222,
                "independent_score_mean_max": 16.977635536193848,
                "interpretability_score_mean_max": 16.291307973861695
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -34.45998571872711,
                "independent_score_mean_max": -34.02163081169128,
                "interpretability_score_mean_max": -31.66030361175537
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.0507138318266982,
          "cebench_delta": -31.66030361175537,
          "cebench_interpretability_max": 16.291307973861695,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8975217129334486,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.968900117458774,
              "cebench": 1.0,
              "alignment": 0.0,
              "explained_variance": 0.4169324967873611
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt",
          "alignment_to_ref": 0.9997372031211853,
          "explained_variance": 0.482511043548584,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:59:59+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "1a23b825eb49ee1fe174a626ee099fe94324d378c9094bf206107b652f402d1e",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5784967500433654,
                    "test_auc": 0.5940343071376452,
                    "test_f1": 0.5377764235437756
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6011172766107579,
                    "test_auc": 0.6142925448732075,
                    "test_f1": 0.57443744003793
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6138099050236868,
                    "test_auc": 0.6425124161194115,
                    "test_f1": 0.5955063789764061
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6138099050236868,
                  "test_auc": 0.6425124161194115,
                  "test_f1": 0.5955063789764061
                },
                "best_minus_llm_auc": -0.05030405027530305
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T15:02:24+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "a88c8dab0b381044b75071b732522e81801e4c1bab60c8d04ceb33a1fd0ce0a0",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "2c6d0f7f1461e56c52554faf9d500a12face76cfda31c0fa5411a91abfad51b9",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.2_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.344642190933227,
                "independent_score_mean_max": 16.04955201625824,
                "interpretability_score_mean_max": 14.150790357589722,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 15:02:24",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.344642190933227,
                "independent_score_mean_max": 16.04955201625824,
                "interpretability_score_mean_max": 14.150790357589722
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.16666523933411,
                "independent_score_mean_max": -34.94971433162689,
                "interpretability_score_mean_max": -33.800821228027345
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05030405027530305,
          "cebench_delta": -33.800821228027345,
          "cebench_interpretability_max": 14.150790357589722,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8518972910221856,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.02926865872073572,
              "alignment": 1.0,
              "explained_variance": 0.9501398442815028
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt",
          "alignment_to_ref": 0.9997227787971497,
          "explained_variance": 0.478765070438385,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T15:05:56+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "2e9191197bd7f8cc8f59f3fd40882592ada6c4c7dccced87ad7e61b63d9784e5",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5997531635726936,
                    "test_auc": 0.6086304849830424,
                    "test_f1": 0.5598049238870679
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6012001959739481,
                    "test_auc": 0.6162582953210269,
                    "test_f1": 0.5742629779832751
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6102373929218674,
                    "test_auc": 0.6348628371091691,
                    "test_f1": 0.5913518831792549
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6102373929218674,
                  "test_auc": 0.6348628371091691,
                  "test_f1": 0.5913518831792549
                },
                "best_minus_llm_auc": -0.05795362928554537
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T15:08:23+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "9eb770334bd4d82833f39466f91299a27773efc7f55591d74d3bd5a376aa2ecf",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "d3674a8a5e965c8d7fd8422a97fcf15881264ae34cf22b03b80e6f1690b24f9d",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.2_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.27119710445404,
                "independent_score_mean_max": 16.285932083129882,
                "interpretability_score_mean_max": 14.086251306533814,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 15:08:23",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.27119710445404,
                "independent_score_mean_max": 16.285932083129882,
                "interpretability_score_mean_max": 14.086251306533814
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.2401103258133,
                "independent_score_mean_max": -34.71333426475525,
                "interpretability_score_mean_max": -33.86536027908325
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05795362928554537,
          "cebench_delta": -33.86536027908325,
          "cebench_interpretability_max": 14.086251306533814,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.32300248126523473,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.4194443163719739,
              "cebench": 0.0,
              "alignment": 0.16838487972508592,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt",
          "alignment_to_ref": 0.9997248649597168,
          "explained_variance": 0.4827076196670532,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T15:02:59+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "a4ab6b847894b2256a01378e11ba6775c6660ca9ffbb93ff62519fcd5d2188c7",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5988745985849107,
                    "test_auc": 0.60919939809392,
                    "test_f1": 0.5470218802722566
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5961715665469506,
                    "test_auc": 0.6170797443169445,
                    "test_f1": 0.5547850088894999
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.5981226481197492,
                    "test_auc": 0.6293361106831468,
                    "test_f1": 0.5762340054425952
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.5981226481197492,
                  "test_auc": 0.6293361106831468,
                  "test_f1": 0.5762340054425952
                },
                "best_minus_llm_auc": -0.06348035571156774
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T15:05:22+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "4b4b99b113b199e530d6651ee166c5120c7a72e569e18e7ca90b0a48bb1f145b",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "23c7c5e69a44e6bdc67d0668abb02ef54c08bb0f14c0b292029b6e5b14a8bd3a",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.2_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.962849588394166,
                "independent_score_mean_max": 16.97179027557373,
                "interpretability_score_mean_max": 14.961721000671387,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 15:05:22",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.962849588394166,
                "independent_score_mean_max": 16.97179027557373,
                "interpretability_score_mean_max": 14.961721000671387
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.54845784187317,
                "independent_score_mean_max": -34.0274760723114,
                "interpretability_score_mean_max": -32.98989058494568
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.06348035571156774,
          "cebench_delta": -32.98989058494568,
          "cebench_interpretability_max": 14.961721000671387,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.12398722068459987,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.3970282066258548,
              "alignment": 0.28865979381443296,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
        "candidate_tag": "seed1011",
        "saebench": {
          "timestamp_utc": "2026-02-17T15:08:58+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "1734d0c3732de1dbb273a65531dccd04fa71eb2e17b5623849f487ac2b9c8401",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.7881393432617188e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6035841638347159,
                "test_auc": 0.6177526454058861,
                "test_f1": 0.5561840981880544
              },
              {
                "k": 2,
                "test_accuracy": 0.6125719937623532,
                "test_auc": 0.6300517613759598,
                "test_f1": 0.5760787124875978
              },
              {
                "k": 5,
                "test_accuracy": 0.6127867447088708,
                "test_auc": 0.6421026345680163,
                "test_f1": 0.5941668238141362
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6127867447088708,
              "test_auc": 0.6421026345680163,
              "test_f1": 0.5941668238141362
            },
            "best_minus_llm_auc": -0.0507138318266982
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T15:11:07+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "e0e9fea6ceb18a20bd9e95ca67ef08bd558f98519f06a777b0845a0987e41557",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.2/sae_seed1011.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "efa1ea9f898742938f87b77f78b24bfdd0a714a184cd3bc29257a6615d5e9294",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.7881393432617188e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 16.051321711540222,
            "independent_score_mean_max": 16.977635536193848,
            "interpretability_score_mean_max": 16.291307973861695,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.2_seed1011",
            "sae_id": "custom_sae",
            "date": "2026-02-17 15:11:07",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 16.051321711540222,
            "independent_score_mean_max": 16.977635536193848,
            "interpretability_score_mean_max": 16.291307973861695
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -34.45998571872711,
            "independent_score_mean_max": -34.02163081169128,
            "interpretability_score_mean_max": -31.66030361175537
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.2/seed1011/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8352874668873846,
        "ev_drop": 0.29721151590347294,
        "ev_neg_drop": -0.29721151590347294,
        "saebench_delta": -0.0507138318266982,
        "cebench_delta": -31.66030361175537,
        "cebench_interpretability_max": 16.291307973861695
      },
      "selection": {
        "joint_score": 0.8740940564177333,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    },
    {
      "lambda_consistency": 0.03,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9978271931409836,
        "std": 0.0006739460976970869,
        "min": 0.9972622096538544,
        "max": 0.998632937669754,
        "median": 0.9973331391811371,
        "ci95_low": 0.9974357336759567,
        "ci95_high": 0.9982214707136153,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.8338019706308841,
      "delta_pwmcc_ci_low_conservative": 0.8332384414412082,
      "ratio_pwmcc": 6.083376555575439,
      "explained_variance": {
        "mean": 0.6137382864952088,
        "std": 0.13381697521634336,
        "min": 0.5529702305793762,
        "max": 0.8531134128570557,
        "median": 0.553804874420166,
        "ci95_low": 0.553428053855896,
        "ci95_high": 0.7334831833839417,
        "n": 5
      },
      "mse": {
        "mean": 0.0003204313092282973,
        "std": 0.00011101065404439031,
        "min": 0.00012185269588371739,
        "max": 0.00037084275390952826,
        "median": 0.0003701501991599798,
        "ci95_low": 0.00022109446726972237,
        "ci95_high": 0.00037046290235593916,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9986097514629364,
        "std": 1.8901878731606503e-05,
        "min": 0.9985896944999695,
        "max": 0.9986329078674316,
        "median": 0.9986082017421722,
        "ci95_low": 0.9985949397087097,
        "ci95_high": 0.9986247271299362,
        "n": 4
      },
      "runtime_sec": 1431.7777667045593,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt",
          "lambda_consistency": 0.03,
          "alignment_to_ref": 0.9985896944999695,
          "mse": 0.00036907149478793144,
          "explained_variance": 0.555105447769165,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9091940732431356,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
          "lambda_consistency": 0.03,
          "alignment_to_ref": 0.9986162185668945,
          "mse": 0.00037084275390952826,
          "explained_variance": 0.5529702305793762,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9091687868866656,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt",
          "lambda_consistency": 0.03,
          "alignment_to_ref": 0.9986329078674316,
          "mse": 0.0003702394024003297,
          "explained_variance": 0.5536974668502808,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9092401030852839,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt",
          "lambda_consistency": 0.03,
          "alignment_to_ref": 0.99860018491745,
          "mse": 0.0003701501991599798,
          "explained_variance": 0.553804874420166,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9092095805745986,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9985897541046143,
        0.9986162185668945,
        0.998632937669754,
        0.99860018491745,
        0.9973362684249878,
        0.9973001182079315,
        0.9972622096538544,
        0.9973300099372864,
        0.997287929058075,
        0.997316300868988
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
      "selected_checkpoint_seed": 456,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
          "alignment_to_ref": 0.9986162185668945,
          "explained_variance": 0.5529702305793762,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:01:38+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "f6f5f2d8d0cd0d8f9e058c249e76fb8e968a3f73ac94aa7f3172758cd8fe1986",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5894021379898293,
                    "test_auc": 0.6041184861654619,
                    "test_f1": 0.5498710508381413
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5984883739823331,
                    "test_auc": 0.6151961788330417,
                    "test_f1": 0.5603444631865563
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.622710819433242,
                    "test_auc": 0.6434387555393835,
                    "test_f1": 0.6054708336806258
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.622710819433242,
                  "test_auc": 0.6434387555393835,
                  "test_f1": 0.6054708336806258
                },
                "best_minus_llm_auc": -0.04937771085533105
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:04:31+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "bc30efca5430344f341c2bdc9b02cd2924e67ea0f35f959b383239dcdac6b808",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "8b2f1900460b956886cb4a8bf160b1c347bd2e10d4bb90c4e995664d2ca82904",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.03_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.624090700149535,
                "independent_score_mean_max": 15.732642364501952,
                "interpretability_score_mean_max": 14.12977129459381,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:04:31",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.624090700149535,
                "independent_score_mean_max": 15.732642364501952,
                "interpretability_score_mean_max": 14.12977129459381
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.8872167301178,
                "independent_score_mean_max": -35.266623983383184,
                "interpretability_score_mean_max": -33.82184029102326
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04937771085533105,
          "cebench_delta": -33.82184029102326,
          "cebench_interpretability_max": 14.12977129459381,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8639712255756447,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.5552104693548718,
              "alignment": 0.6137931034482759,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt",
          "alignment_to_ref": 0.99860018491745,
          "explained_variance": 0.553804874420166,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:05:06+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "49f2139ee60ada7f85a4780374f6f9fbf423a90714e36f1d4c6fc2119edcceda",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.599030064376878,
                    "test_auc": 0.6085647594940361,
                    "test_f1": 0.5528062786696007
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6128467688667418,
                    "test_auc": 0.6302196507820805,
                    "test_f1": 0.5894119791327191
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6190131699376694,
                    "test_auc": 0.6410805881005667,
                    "test_f1": 0.6036582437167475
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6190131699376694,
                  "test_auc": 0.6410805881005667,
                  "test_f1": 0.6036582437167475
                },
                "best_minus_llm_auc": -0.05173587829414783
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:07:26+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "30d1f69c0fb022872713ac4f3b33282c52748b8a37ecab72ae78c74da2f7a044",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "d435a6c9b9a88f1b84153de0462330aa0333f22e078df378336f3f4dc7a65bbd",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.02915442466736,
                "independent_score_mean_max": 15.24943531036377,
                "interpretability_score_mean_max": 13.719969158172608,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:07:26",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.02915442466736,
                "independent_score_mean_max": 15.24943531036377,
                "interpretability_score_mean_max": 13.719969158172608
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.482153005599976,
                "independent_score_mean_max": -35.74983103752136,
                "interpretability_score_mean_max": -34.231642427444456
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05173587829414783,
          "cebench_delta": -34.231642427444456,
          "cebench_interpretability_max": 13.719969158172608,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6104065996361289,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.7716319502486025,
              "cebench": 0.0,
              "alignment": 0.24275862068965517,
              "explained_variance": 0.390894118303883
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt",
          "alignment_to_ref": 0.9985896944999695,
          "explained_variance": 0.555105447769165,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:08:00+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "67ce7fb4a5cdd8c31f95895ba0837437b3b21033a771280eab45ad04df4a367d",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5755048683417479,
                    "test_auc": 0.5798039493835621,
                    "test_f1": 0.5359674936844536
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5923725598616915,
                    "test_auc": 0.6194176905019874,
                    "test_f1": 0.5675971476136623
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6152991094073653,
                    "test_auc": 0.6357177802286724,
                    "test_f1": 0.5843968326969083
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6152991094073653,
                  "test_auc": 0.6357177802286724,
                  "test_f1": 0.5843968326969083
                },
                "best_minus_llm_auc": -0.05709868616604208
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:10:01+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "7641e68540aad135706ee63f07bb2269836aa0e3d2ab7989d0a3454ec0d374d7",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "469ec2dd0489f3481a662a1823a1004349b663472d10857ea7bc4d98fdca4cc6",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.03_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 15.085028817653656,
                "independent_score_mean_max": 16.178657956123352,
                "interpretability_score_mean_max": 14.458071479797363,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:10:01",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 15.085028817653656,
                "independent_score_mean_max": 16.178657956123352,
                "interpretability_score_mean_max": 14.458071479797363
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.42627861261368,
                "independent_score_mean_max": -34.82060839176178,
                "interpretability_score_mean_max": -33.493540105819704
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05709868616604208,
          "cebench_delta": -33.493540105819704,
          "cebench_interpretability_max": 14.458071479797363,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.3892179140265573,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.2522905520354098,
              "cebench": 1.0,
              "alignment": 0.0,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt",
          "alignment_to_ref": 0.9986329078674316,
          "explained_variance": 0.5536974668502808,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T13:58:33+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "316aee73acf2010d68edefd109a6cb7406f514c978079559808417a38f5f71c0",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5892651752726169,
                    "test_auc": 0.6071717086300038,
                    "test_f1": 0.5472773606127306
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6075098526371968,
                    "test_auc": 0.6278448729043701,
                    "test_f1": 0.5750274170193598
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6082202142364151,
                    "test_auc": 0.6331125849503545,
                    "test_f1": 0.5870829717832178
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6082202142364151,
                  "test_auc": 0.6331125849503545,
                  "test_f1": 0.5870829717832178
                },
                "best_minus_llm_auc": -0.05970388144436001
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:01:02+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "42cb60f6e7dfbfa0ac8afa91db4c93b7acd505fd423582c64b0c45eacf65fd61",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "ce4452af4b791ec9db9845e612cf755aad04bd6ed729ed0fefb3b33e958a0b55",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.03_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.651202373504638,
                "independent_score_mean_max": 15.845165600776673,
                "interpretability_score_mean_max": 13.908076062202454,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:01:02",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.651202373504638,
                "independent_score_mean_max": 15.845165600776673,
                "interpretability_score_mean_max": 13.908076062202454
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.8601050567627,
                "independent_score_mean_max": -35.15410074710846,
                "interpretability_score_mean_max": -34.04353552341461
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05970388144436001,
          "cebench_delta": -34.04353552341461,
          "cebench_interpretability_max": 13.908076062202454,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.10525737240998803,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.2548520693117087,
              "alignment": 1.0,
              "explained_variance": 0.34059124026463444
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
        "candidate_tag": "seed456",
        "saebench": {
          "timestamp_utc": "2026-02-17T14:01:38+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "f6f5f2d8d0cd0d8f9e058c249e76fb8e968a3f73ac94aa7f3172758cd8fe1986",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.5894021379898293,
                "test_auc": 0.6041184861654619,
                "test_f1": 0.5498710508381413
              },
              {
                "k": 2,
                "test_accuracy": 0.5984883739823331,
                "test_auc": 0.6151961788330417,
                "test_f1": 0.5603444631865563
              },
              {
                "k": 5,
                "test_accuracy": 0.622710819433242,
                "test_auc": 0.6434387555393835,
                "test_f1": 0.6054708336806258
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.622710819433242,
              "test_auc": 0.6434387555393835,
              "test_f1": 0.6054708336806258
            },
            "best_minus_llm_auc": -0.04937771085533105
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T14:04:31+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.03_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "bc30efca5430344f341c2bdc9b02cd2924e67ea0f35f959b383239dcdac6b808",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.03/sae_seed456.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "8b2f1900460b956886cb4a8bf160b1c347bd2e10d4bb90c4e995664d2ca82904",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.03_seed456/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 14.624090700149535,
            "independent_score_mean_max": 15.732642364501952,
            "interpretability_score_mean_max": 14.12977129459381,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.03_seed456",
            "sae_id": "custom_sae",
            "date": "2026-02-17 14:04:31",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 14.624090700149535,
            "independent_score_mean_max": 15.732642364501952,
            "interpretability_score_mean_max": 14.12977129459381
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -35.8872167301178,
            "independent_score_mean_max": -35.266623983383184,
            "interpretability_score_mean_max": -33.82184029102326
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.03/seed456/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8332384414412082,
        "ev_drop": 0.23897442817687986,
        "ev_neg_drop": -0.23897442817687986,
        "saebench_delta": -0.04937771085533105,
        "cebench_delta": -33.82184029102326,
        "cebench_interpretability_max": 14.12977129459381
      },
      "selection": {
        "joint_score": 0.8404448355747316,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    },
    {
      "lambda_consistency": 0.05,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9986905753612518,
        "std": 0.0004090263797073315,
        "min": 0.9983469843864441,
        "max": 0.9991788864135742,
        "median": 0.998396247625351,
        "ci95_low": 0.9984527111053467,
        "ci95_high": 0.9989304366707802,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.8346653528511524,
      "delta_pwmcc_ci_low_conservative": 0.8342554188705982,
      "ratio_pwmcc": 6.088640271771375,
      "explained_variance": {
        "mean": 0.5981857657432557,
        "std": 0.14251887039387154,
        "min": 0.5322084426879883,
        "max": 0.8531134128570557,
        "median": 0.5345327854156494,
        "ci95_low": 0.5334399938583374,
        "ci95_high": 0.7256995439529419,
        "n": 5
      },
      "mse": {
        "mean": 0.0003333334097987972,
        "std": 0.00011822959124170233,
        "min": 0.00012185269588371739,
        "max": 0.000388066255254671,
        "median": 0.000386137719033286,
        "ci95_low": 0.00022755175159545616,
        "ci95_high": 0.00038704443140886725,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.999165415763855,
        "std": 1.5007513714984594e-05,
        "min": 0.9991464018821716,
        "max": 0.9991788864135742,
        "median": 0.999168187379837,
        "ci95_low": 0.9991534650325775,
        "ci95_high": 0.9991773664951324,
        "n": 4
      },
      "runtime_sec": 1447.2789540290833,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt",
          "lambda_consistency": 0.05,
          "alignment_to_ref": 0.9991605281829834,
          "mse": 0.0003841344150714576,
          "explained_variance": 0.5369490385055542,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9114554998188935,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
          "lambda_consistency": 0.05,
          "alignment_to_ref": 0.9991758465766907,
          "mse": 0.000388066255254671,
          "explained_variance": 0.5322084426879883,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9114441092264045,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt",
          "lambda_consistency": 0.05,
          "alignment_to_ref": 0.9991788864135742,
          "mse": 0.00038647596375085413,
          "explained_variance": 0.5341251492500305,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9114961447366686,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt",
          "lambda_consistency": 0.05,
          "alignment_to_ref": 0.9991464018821716,
          "mse": 0.000386137719033286,
          "explained_variance": 0.5345327854156494,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.911461247217462,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9991605281829834,
        0.9991758465766907,
        0.9991788864135742,
        0.9991463422775269,
        0.998396098613739,
        0.9983784556388855,
        0.9983469843864441,
        0.9983963966369629,
        0.9983612895011902,
        0.9983649253845215
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
      "selected_checkpoint_seed": 456,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
          "alignment_to_ref": 0.9991758465766907,
          "explained_variance": 0.5322084426879883,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:13:38+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "4773e30e98f44ee609650551de315061ab3dd52a6857f726e95869f81c866ac2",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6066061815256624,
                    "test_auc": 0.6152878961043359,
                    "test_f1": 0.5739939756288097
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.610098491375921,
                    "test_auc": 0.6269119516763866,
                    "test_f1": 0.5785955816164129
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6171247429726339,
                    "test_auc": 0.6429864501391557,
                    "test_f1": 0.6009772361813108
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6171247429726339,
                  "test_auc": 0.6429864501391557,
                  "test_f1": 0.6009772361813108
                },
                "best_minus_llm_auc": -0.04983001625555883
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:16:06+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "c0524dd5e4a52b9bd42897cb0ce8e81d7981ea7a6898486b16f2c59f3de5012e",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "13b9297851db0cdc43c8b597151cd17d967a640d934c6df4b83a884c538dade9",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.05_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.763310737609864,
                "independent_score_mean_max": 16.00711371898651,
                "interpretability_score_mean_max": 14.432394185066222,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:16:06",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.763310737609864,
                "independent_score_mean_max": 16.00711371898651,
                "interpretability_score_mean_max": 14.432394185066222
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.74799669265747,
                "independent_score_mean_max": -34.99215262889862,
                "interpretability_score_mean_max": -33.51921740055084
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04983001625555883,
          "cebench_delta": -33.51921740055084,
          "cebench_interpretability_max": 14.432394185066222,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9453211009174313,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 1.0,
              "alignment": 0.9064220183486239,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt",
          "alignment_to_ref": 0.9991788864135742,
          "explained_variance": 0.5341251492500305,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:10:36+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "1a3e16a786a2860ac515cc16e2bf0b3c20c5b93b98dad076cd21bb8ff6e0926b",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5968626797281039,
                    "test_auc": 0.6113969524408849,
                    "test_f1": 0.5655017971229078
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.597283077860725,
                    "test_auc": 0.6225565634691657,
                    "test_f1": 0.5657513530281966
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6161741448508103,
                    "test_auc": 0.6381718088654948,
                    "test_f1": 0.5944126233949023
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6161741448508103,
                  "test_auc": 0.6381718088654948,
                  "test_f1": 0.5944126233949023
                },
                "best_minus_llm_auc": -0.05464465752921965
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:13:04+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "f6cf87d2df6e1ee5103f5c952433c85ebb5d67e543b76617b4aca89f9e3e4418",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "b25f1aca2f19e6664a8f6d44324bb1bf515b46d237051d450f1616a4d9e1a279",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.05_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.56902340888977,
                "independent_score_mean_max": 16.1038503074646,
                "interpretability_score_mean_max": 14.256655421257019,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:13:04",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.56902340888977,
                "independent_score_mean_max": 16.1038503074646,
                "interpretability_score_mean_max": 14.256655421257019
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.94228402137757,
                "independent_score_mean_max": -34.89541604042053,
                "interpretability_score_mean_max": -33.69495616436005
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05464465752921965,
          "cebench_delta": -33.69495616436005,
          "cebench_interpretability_max": 14.256655421257019,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6759284759150354,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.6865571741667299,
              "cebench": 0.6052980851622284,
              "alignment": 1.0,
              "explained_variance": 0.40431765031307365
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt",
          "alignment_to_ref": 0.9991464018821716,
          "explained_variance": 0.5345327854156494,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:20:09+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "59549040ce3b997726ecd1f1b7961b34aba0951c69c830fd911c0d0e95639638",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.607632068525092,
                    "test_auc": 0.6233378465884156,
                    "test_f1": 0.5778571732655139
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6100462681076082,
                    "test_auc": 0.6291616940012972,
                    "test_f1": 0.5829058628387733
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6128017932111576,
                    "test_auc": 0.6396893866434897,
                    "test_f1": 0.5935148767411194
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6128017932111576,
                  "test_auc": 0.6396893866434897,
                  "test_f1": 0.5935148767411194
                },
                "best_minus_llm_auc": -0.05312707975122477
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:22:42+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "a152204971b4bf53d7222f04c0e6d6c50e1abbb0d1490b9bad4a07b523f0f1c7",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "2a0205d34d8b860390bc897ed75730d4a2362bdb139032fbea03b705d65e8f21",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.194043025970458,
                "independent_score_mean_max": 15.576153869628905,
                "interpretability_score_mean_max": 13.987149920463562,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:22:42",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.194043025970458,
                "independent_score_mean_max": 15.576153869628905,
                "interpretability_score_mean_max": 13.987149920463562
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.31726440429688,
                "independent_score_mean_max": -35.42311247825623,
                "interpretability_score_mean_max": -33.96446166515351
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05312707975122477,
          "cebench_delta": -33.96446166515351,
          "cebench_interpretability_max": 13.987149920463562,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6135312053681524,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.7853545383148612,
              "cebench": 0.0,
              "alignment": 0.0,
              "explained_variance": 0.49030603264012873
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt",
          "alignment_to_ref": 0.9991605281829834,
          "explained_variance": 0.5369490385055542,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:16:41+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "d6a755bf9b293b33a8e45fc1e60c8ac91a6f65b2145bafa468aacaa013099a6e",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5862263257211054,
                    "test_auc": 0.5905524079472635,
                    "test_f1": 0.5497188208926932
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5957760266028238,
                    "test_auc": 0.6138050266229562,
                    "test_f1": 0.5606819447105547
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6010810986155259,
                    "test_auc": 0.6276259413737648,
                    "test_f1": 0.567838180692527
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6010810986155259,
                  "test_auc": 0.6276259413737648,
                  "test_f1": 0.567838180692527
                },
                "best_minus_llm_auc": -0.06519052502094969
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:19:34+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "85beef7db8f01bef5448c12341ad1bb556038785ebe05caee6098bd3fc16147c",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "8e41a0822c41393eae7147873834aa05844601248c7836adf8f2d909cdae0381",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.05_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.831925806999207,
                "independent_score_mean_max": 15.635621542930602,
                "interpretability_score_mean_max": 14.220564064979554,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:19:34",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.831925806999207,
                "independent_score_mean_max": 15.635621542930602,
                "interpretability_score_mean_max": 14.220564064979554
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.67938162326813,
                "independent_score_mean_max": -35.36364480495453,
                "interpretability_score_mean_max": -33.73104752063751
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.06519052502094969,
          "cebench_delta": -33.73104752063751,
          "cebench_interpretability_max": 14.220564064979554,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.15037888048949133,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.524238408156242,
              "alignment": 0.43486238532110094,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
        "candidate_tag": "seed456",
        "saebench": {
          "timestamp_utc": "2026-02-17T14:13:38+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "4773e30e98f44ee609650551de315061ab3dd52a6857f726e95869f81c866ac2",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6066061815256624,
                "test_auc": 0.6152878961043359,
                "test_f1": 0.5739939756288097
              },
              {
                "k": 2,
                "test_accuracy": 0.610098491375921,
                "test_auc": 0.6269119516763866,
                "test_f1": 0.5785955816164129
              },
              {
                "k": 5,
                "test_accuracy": 0.6171247429726339,
                "test_auc": 0.6429864501391557,
                "test_f1": 0.6009772361813108
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6171247429726339,
              "test_auc": 0.6429864501391557,
              "test_f1": 0.6009772361813108
            },
            "best_minus_llm_auc": -0.04983001625555883
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T14:16:06+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.05_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "c0524dd5e4a52b9bd42897cb0ce8e81d7981ea7a6898486b16f2c59f3de5012e",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.05/sae_seed456.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "13b9297851db0cdc43c8b597151cd17d967a640d934c6df4b83a884c538dade9",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.05_seed456/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 14.763310737609864,
            "independent_score_mean_max": 16.00711371898651,
            "interpretability_score_mean_max": 14.432394185066222,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.05_seed456",
            "sae_id": "custom_sae",
            "date": "2026-02-17 14:16:06",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 14.763310737609864,
            "independent_score_mean_max": 16.00711371898651,
            "interpretability_score_mean_max": 14.432394185066222
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -35.74799669265747,
            "independent_score_mean_max": -34.99215262889862,
            "interpretability_score_mean_max": -33.51921740055084
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.05/seed456/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8342554188705982,
        "ev_drop": 0.254526948928833,
        "ev_neg_drop": -0.254526948928833,
        "saebench_delta": -0.04983001625555883,
        "cebench_delta": -33.51921740055084,
        "cebench_interpretability_max": 14.432394185066222
      },
      "selection": {
        "joint_score": 0.8379462605298184,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    },
    {
      "lambda_consistency": 0.15,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9994587928056717,
        "std": 0.00017226819902102904,
        "min": 0.9993079304695129,
        "max": 0.9996694922447205,
        "median": 0.9993388652801514,
        "ci95_low": 0.9993587650358677,
        "ci95_high": 0.9995604160428048,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.8354335702955723,
      "delta_pwmcc_ci_low_conservative": 0.8351614728011192,
      "ratio_pwmcc": 6.093323804173671,
      "explained_variance": {
        "mean": 0.565224289894104,
        "std": 0.16094904729961712,
        "min": 0.4896153211593628,
        "max": 0.8531134128570557,
        "median": 0.4942736029624939,
        "ci95_low": 0.4916369080543518,
        "ci95_high": 0.7095346933603287,
        "n": 5
      },
      "mse": {
        "mean": 0.00036067761684535073,
        "std": 0.00013351891089684233,
        "min": 0.00012185269588371739,
        "max": 0.00042340013897046447,
        "median": 0.00041953640175051987,
        "ci95_low": 0.00024096263368846848,
        "ci95_high": 0.00042172339744865893,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9996585100889206,
        "std": 1.0344268327548307e-05,
        "min": 0.9996452331542969,
        "max": 0.9996694922447205,
        "median": 0.9996596574783325,
        "ci95_low": 0.9996496587991714,
        "ci95_high": 0.9996662139892578,
        "n": 4
      },
      "runtime_sec": 1429.9556584358215,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9996563792228699,
          "mse": 0.0004197186790406704,
          "explained_variance": 0.4940541386604309,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9135211912259735,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9996694922447205,
          "mse": 0.00042340013897046447,
          "explained_variance": 0.4896153211593628,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.913505043886188,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9996629357337952,
          "mse": 0.00041888016858138144,
          "explained_variance": 0.49506497383117676,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9135338068870759,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9996452331542969,
          "mse": 0.00041953640175051987,
          "explained_variance": 0.4942736029624939,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9135304855148273,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9996564388275146,
        0.9996694922447205,
        0.9996629059314728,
        0.9996452331542969,
        0.9993362128734589,
        0.9993308782577515,
        0.9993079304695129,
        0.9993415176868439,
        0.9993225932121277,
        0.9993147253990173
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
      "selected_checkpoint_seed": 1011,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
          "alignment_to_ref": 0.9996452331542969,
          "explained_variance": 0.4942736029624939,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:56:57+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "7a86bd4992558cdc77d73b1cc6829b651f9855ec3c6e3044b199dac185cecc08",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6006991067498302,
                    "test_auc": 0.6054523472040786,
                    "test_f1": 0.5591604987435893
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6107239180883893,
                    "test_auc": 0.6315869251397795,
                    "test_f1": 0.5830891325183166
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6212830945545705,
                    "test_auc": 0.6434163861661613,
                    "test_f1": 0.601674809829184
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6212830945545705,
                  "test_auc": 0.6434163861661613,
                  "test_f1": 0.601674809829184
                },
                "best_minus_llm_auc": -0.049400080228553245
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:59:25+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "d53e20c400a347cd0b369cd878f8439b6ffd5623df64ee93efe36aa32f66ac24",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "8c8baf8291e6173362af86db0f7ee6a6589636731dc4b82dc7d009090a7e762a",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.078473398685455,
                "independent_score_mean_max": 15.712986750602722,
                "interpretability_score_mean_max": 13.888679838180542,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:59:24",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.078473398685455,
                "independent_score_mean_max": 15.712986750602722,
                "interpretability_score_mean_max": 13.888679838180542
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.43283403158188,
                "independent_score_mean_max": -35.28627959728241,
                "interpretability_score_mean_max": -34.06293174743652
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.049400080228553245,
          "cebench_delta": -34.06293174743652,
          "cebench_interpretability_max": 13.888679838180542,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.7927392540741551,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.0,
              "alignment": 0.0,
              "explained_variance": 0.8547850814831018
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt",
          "alignment_to_ref": 0.9996694922447205,
          "explained_variance": 0.4896153211593628,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:47:53+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "2c8e2e28f023133894534f66a93c8a8a2ba356ee999258ff727afb35acacca74",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.588827477867384,
                    "test_auc": 0.606022176007571,
                    "test_f1": 0.5496855766748145
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6010191944462877,
                    "test_auc": 0.6222711641225226,
                    "test_f1": 0.5730470827157904
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6048595574570451,
                    "test_auc": 0.6370757538876025,
                    "test_f1": 0.5859276944127422
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6048595574570451,
                  "test_auc": 0.6370757538876025,
                  "test_f1": 0.5859276944127422
                },
                "best_minus_llm_auc": -0.05574071250711199
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:50:21+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "b25c06375ccee55ff8c9aaff575f8204b39f1624bc9cdcafd0e646a1b06d562b",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "a5525f971b054a2867279c9b724f8f82908efca82d2a7765f09b5916ee3e6ecc",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.15_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.163305993080138,
                "independent_score_mean_max": 16.445481567382814,
                "interpretability_score_mean_max": 14.228761715888977,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:50:21",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.163305993080138,
                "independent_score_mean_max": 16.445481567382814,
                "interpretability_score_mean_max": 14.228761715888977
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -36.3480014371872,
                "independent_score_mean_max": -34.55378478050232,
                "interpretability_score_mean_max": -33.72284986972809
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05574071250711199,
          "cebench_delta": -33.72284986972809,
          "cebench_interpretability_max": 14.228761715888977,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.41654467355018515,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.3893669272954621,
              "cebench": 0.49679652052392387,
              "alignment": 1.0,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt",
          "alignment_to_ref": 0.9996563792228699,
          "explained_variance": 0.4940541386604309,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:53:54+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "7094bd294940f51cc03c17a1d9204c8c9d9c08977c6730f3b69531f00a47ea11",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5902357922436835,
                    "test_auc": 0.6066816778589407,
                    "test_f1": 0.5469513823369552
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5975346759193501,
                    "test_auc": 0.6162438966654439,
                    "test_f1": 0.5611947466102771
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6068551933871391,
                    "test_auc": 0.6349406548351108,
                    "test_f1": 0.5764170661341987
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6068551933871391,
                  "test_auc": 0.6349406548351108,
                  "test_f1": 0.5764170661341987
                },
                "best_minus_llm_auc": -0.05787581155960375
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:56:23+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "4b6841ef8016ed4ca86ea2d29721394c6130a02d6ba03ee7319d2d9c3f1d005c",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "3608a87c8ea7448767a89690787c5e69c2413dd13e7164d23634b4bae416037e",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.15_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.678274207115173,
                "independent_score_mean_max": 16.091999282836912,
                "interpretability_score_mean_max": 14.360926089286805,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:56:23",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.678274207115173,
                "independent_score_mean_max": 16.091999282836912,
                "interpretability_score_mean_max": 14.360926089286805
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.833033223152164,
                "independent_score_mean_max": -34.90726706504822,
                "interpretability_score_mean_max": -33.59068549633026
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05787581155960375,
          "cebench_delta": -33.59068549633026,
          "cebench_interpretability_max": 14.360926089286805,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.30498833014397153,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.18374672450269838,
              "cebench": 0.689864146719393,
              "alignment": 0.4594594594594595,
              "explained_variance": 0.8145138357213169
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt",
          "alignment_to_ref": 0.9996629357337952,
          "explained_variance": 0.49506497383117676,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:50:55+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "0f76348d14fb55d724938c8702d70be6e0737539187f1229c79346b5657f8e75",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5898871666588792,
                    "test_auc": 0.5899650946147676,
                    "test_f1": 0.5427584633811429
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5991539899512263,
                    "test_auc": 0.621235368158471,
                    "test_f1": 0.5570366375940453
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6108518891125181,
                    "test_auc": 0.6330326834779403,
                    "test_f1": 0.5908910024358591
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6108518891125181,
                  "test_auc": 0.6330326834779403,
                  "test_f1": 0.5908910024358591
                },
                "best_minus_llm_auc": -0.05978378291677422
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:53:19+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "2c71fefa1b76991daf57ae88915bc51504c885db6c4c372bbcd9c1c730d6fffb",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "fa4456d4a94f6857c5c2f7e9717fc1e7184211fdb187a5733667745fa50ffab7",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.15_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.65447340965271,
                "independent_score_mean_max": 16.609899797439574,
                "interpretability_score_mean_max": 14.573229475021362,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:53:19",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.65447340965271,
                "independent_score_mean_max": 16.609899797439574,
                "interpretability_score_mean_max": 14.573229475021362
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.85683402061463,
                "independent_score_mean_max": -34.38936655044556,
                "interpretability_score_mean_max": -33.3783821105957
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05978378291677422,
          "cebench_delta": -33.3783821105957,
          "cebench_interpretability_max": 14.573229475021362,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.23648648648648646,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 1.0,
              "alignment": 0.7297297297297297,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
        "candidate_tag": "seed1011",
        "saebench": {
          "timestamp_utc": "2026-02-17T14:56:57+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "7a86bd4992558cdc77d73b1cc6829b651f9855ec3c6e3044b199dac185cecc08",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6006991067498302,
                "test_auc": 0.6054523472040786,
                "test_f1": 0.5591604987435893
              },
              {
                "k": 2,
                "test_accuracy": 0.6107239180883893,
                "test_auc": 0.6315869251397795,
                "test_f1": 0.5830891325183166
              },
              {
                "k": 5,
                "test_accuracy": 0.6212830945545705,
                "test_auc": 0.6434163861661613,
                "test_f1": 0.601674809829184
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6212830945545705,
              "test_auc": 0.6434163861661613,
              "test_f1": 0.601674809829184
            },
            "best_minus_llm_auc": -0.049400080228553245
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T14:59:25+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "d53e20c400a347cd0b369cd878f8439b6ffd5623df64ee93efe36aa32f66ac24",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.15/sae_seed1011.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "8c8baf8291e6173362af86db0f7ee6a6589636731dc4b82dc7d009090a7e762a",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 14.078473398685455,
            "independent_score_mean_max": 15.712986750602722,
            "interpretability_score_mean_max": 13.888679838180542,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.15_seed1011",
            "sae_id": "custom_sae",
            "date": "2026-02-17 14:59:24",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 14.078473398685455,
            "independent_score_mean_max": 15.712986750602722,
            "interpretability_score_mean_max": 13.888679838180542
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -36.43283403158188,
            "independent_score_mean_max": -35.28627959728241,
            "interpretability_score_mean_max": -34.06293174743652
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.15/seed1011/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8351614728011192,
        "ev_drop": 0.28748842477798464,
        "ev_neg_drop": -0.28748842477798464,
        "saebench_delta": -0.049400080228553245,
        "cebench_delta": -34.06293174743652,
        "cebench_interpretability_max": 13.888679838180542
      },
      "selection": {
        "joint_score": 0.8239971731909919,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    },
    {
      "lambda_consistency": 0.08,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9991053670644761,
        "std": 0.00028278028149498455,
        "min": 0.9988521337509155,
        "max": 0.999464213848114,
        "median": 0.9989157170057297,
        "ci95_low": 0.9989407195895911,
        "ci95_high": 0.9992727165669203,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.8350801445543766,
      "delta_pwmcc_ci_low_conservative": 0.8347434273548424,
      "ratio_pwmcc": 6.091169100550733,
      "explained_variance": {
        "mean": 0.5856225252151489,
        "std": 0.1495448288047038,
        "min": 0.5158818960189819,
        "max": 0.8531134128570557,
        "median": 0.5201324224472046,
        "ci95_low": 0.5173261165618896,
        "ci95_high": 0.7196650266647339,
        "n": 5
      },
      "mse": {
        "mean": 0.0003437556195422076,
        "std": 0.00012405818622291233,
        "min": 0.00012185269588371739,
        "max": 0.0004016106831841171,
        "median": 0.00039808396832086146,
        "ci95_low": 0.00023269078956218437,
        "ci95_high": 0.0004001999972388148,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9994327276945114,
        "std": 2.417835434014657e-05,
        "min": 0.9994068145751953,
        "max": 0.999464213848114,
        "median": 0.9994299411773682,
        "ci95_low": 0.9994141310453415,
        "ci95_high": 0.9994541108608246,
        "n": 4
      },
      "runtime_sec": 1429.881992816925,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.9994238018989563,
          "mse": 0.0003974188584834337,
          "explained_variance": 0.5209355354309082,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9126386000533346,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.99943608045578,
          "mse": 0.0004016106831841171,
          "explained_variance": 0.5158818960189819,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.912627692869002,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.999464213848114,
          "mse": 0.00039808396832086146,
          "explained_variance": 0.5201324224472046,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9126858430638634,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.9994068145751953,
          "mse": 0.0003998118918389082,
          "explained_variance": 0.5180493593215942,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9126540565414837,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 864,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9994238018989563,
        0.99943608045578,
        0.999464213848114,
        0.9994068145751953,
        0.9988862872123718,
        0.9989099502563477,
        0.9988521337509155,
        0.9989214837551117,
        0.9988633990287781,
        0.9988895058631897
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
      "selected_checkpoint_seed": 1011,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
          "alignment_to_ref": 0.9994068145751953,
          "explained_variance": 0.5180493593215942,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:32:32+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "e7ff8714bae14dfa1da307bb06be8de1ba76a6f4f2cb0ecf4edbd0c983a71502",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6008084902357144,
                    "test_auc": 0.6010654722672262,
                    "test_f1": 0.5673617775548091
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.596958570726893,
                    "test_auc": 0.630305052365858,
                    "test_f1": 0.571368838587414
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6139254093145695,
                    "test_auc": 0.6392954155264232,
                    "test_f1": 0.596392390315998
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6139254093145695,
                  "test_auc": 0.6392954155264232,
                  "test_f1": 0.596392390315998
                },
                "best_minus_llm_auc": -0.05352105086829129
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:35:03+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "491a3c15c13935c7122597ede518d1a0a857d01de1bd073b117d6a5fe5efd95c",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "96bad52266a644d9fecfecbf4396128e6d2015ab4aa8344d7a063af27af9f919",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.69216621875763,
                "independent_score_mean_max": 15.623788080215455,
                "interpretability_score_mean_max": 14.364149336814881,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:35:03",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.69216621875763,
                "independent_score_mean_max": 15.623788080215455,
                "interpretability_score_mean_max": 14.364149336814881
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.81914121150971,
                "independent_score_mean_max": -35.37547826766968,
                "interpretability_score_mean_max": -33.58746224880218
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05352105086829129,
          "cebench_delta": -33.58746224880218,
          "cebench_interpretability_max": 14.364149336814881,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.7989355576645798,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.1832731970017899,
              "alignment": 0.0,
              "explained_variance": 0.4288915622862265
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt",
          "alignment_to_ref": 0.99943608045578,
          "explained_variance": 0.5158818960189819,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:26:19+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "a83d6a9f19cab7c556fb2dc81e9b80518d944d9c233b29e7472eed82ec36d59c",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5878341661380411,
                    "test_auc": 0.6086008871854737,
                    "test_f1": 0.5507209076080434
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6047083991939219,
                    "test_auc": 0.6210274661691355,
                    "test_f1": 0.5830591919818804
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6129701735324887,
                    "test_auc": 0.6375346183576178,
                    "test_f1": 0.5939422638371942
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6129701735324887,
                  "test_auc": 0.6375346183576178,
                  "test_f1": 0.5939422638371942
                },
                "best_minus_llm_auc": -0.05528184803709668
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:28:48+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "24d7c1893249ce428135f1286ce96f0d32cc5beaadd05586980a0c4d2a58a362",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "0391c45e5ea18df7e66adcaea4ad5d610dfcaf9ccad6d97872dcd96d35e183d9",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.08_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.529748129844666,
                "independent_score_mean_max": 16.251275062561035,
                "interpretability_score_mean_max": 14.238390259742737,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:28:48",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.529748129844666,
                "independent_score_mean_max": 16.251275062561035,
                "interpretability_score_mean_max": 14.238390259742737
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.981559300422674,
                "independent_score_mean_max": -34.7479912853241,
                "interpretability_score_mean_max": -33.71322132587433
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05528184803709668,
          "cebench_delta": -33.71322132587433,
          "cebench_interpretability_max": 14.238390259742737,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.652310821636778,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.8232775217083224,
              "cebench": 0.06239620063953885,
              "alignment": 0.509865005192108,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt",
          "alignment_to_ref": 0.999464213848114,
          "explained_variance": 0.5201324224472046,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:23:16+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "ba0742030afafad5508cd8c966eabf7b569f8e2bab58e16964ed553cd63fe262",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6035507306715023,
                    "test_auc": 0.6143334976588454,
                    "test_f1": 0.5623110373518677
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6022696648496513,
                    "test_auc": 0.6215473079702509,
                    "test_f1": 0.5640224215271035
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6060716734325212,
                    "test_auc": 0.6298006261382599,
                    "test_f1": 0.5757701558039282
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6060716734325212,
                  "test_auc": 0.6298006261382599,
                  "test_f1": 0.5757701558039282
                },
                "best_minus_llm_auc": -0.06301584025645457
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:25:44+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "3b378d990d8f5d1940eb8909190089345ea62bd0f91678d20dba6af8d52ece52",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "0d23c28bc6142eb892c5442851cf955731ff98487abd98b3fcae573f4d3b45be",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.08_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 15.310425510406494,
                "independent_score_mean_max": 16.845168018341063,
                "interpretability_score_mean_max": 15.213862781524659,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:25:44",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 15.310425510406494,
                "independent_score_mean_max": 16.845168018341063,
                "interpretability_score_mean_max": 15.213862781524659
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.20088191986084,
                "independent_score_mean_max": -34.15409832954407,
                "interpretability_score_mean_max": -32.737748804092405
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.06301584025645457,
          "cebench_delta": -32.737748804092405,
          "cebench_interpretability_max": 15.213862781524659,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.27734542510524,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.047055083197271266,
              "cebench": 1.0,
              "alignment": 1.0,
              "explained_variance": 0.8410822541457316
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt",
          "alignment_to_ref": 0.9994238018989563,
          "explained_variance": 0.5209355354309082,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T14:29:23+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "5f36ad397dbf3d1baaca6d42c0922a62426cc3399b794ae9341fbb345911b953",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5951020187939368,
                    "test_auc": 0.6109618351040809,
                    "test_f1": 0.5658560813541762
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5916353466394714,
                    "test_auc": 0.6120628464006502,
                    "test_f1": 0.5651946659641527
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6069475810991407,
                    "test_auc": 0.629331786757596,
                    "test_f1": 0.5754561847893795
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6069475810991407,
                  "test_auc": 0.629331786757596,
                  "test_f1": 0.5754561847893795
                },
                "best_minus_llm_auc": -0.06348467963711846
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T14:31:58+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "187407e65ebab39f97dab18e2731e14351b04e78f26139636a37631d1e26781b",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "c6a523a45fca09b69cfbe8d96cc4a061bec5cde56a2d8bf8a19352e21aa2c304",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.08_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 14.591936388015746,
                "independent_score_mean_max": 15.730177035331726,
                "interpretability_score_mean_max": 14.173473949432372,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 14:31:57",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 14.591936388015746,
                "independent_score_mean_max": 15.730177035331726,
                "interpretability_score_mean_max": 14.173473949432372
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -35.91937104225159,
                "independent_score_mean_max": -35.269089312553405,
                "interpretability_score_mean_max": -33.778137636184695
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.06348467963711846,
          "cebench_delta": -33.778137636184695,
          "cebench_interpretability_max": 14.173473949432372,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.064797507788162,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.0,
              "alignment": 0.29595015576323985,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
        "candidate_tag": "seed1011",
        "saebench": {
          "timestamp_utc": "2026-02-17T14:32:32+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "e7ff8714bae14dfa1da307bb06be8de1ba76a6f4f2cb0ecf4edbd0c983a71502",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6008084902357144,
                "test_auc": 0.6010654722672262,
                "test_f1": 0.5673617775548091
              },
              {
                "k": 2,
                "test_accuracy": 0.596958570726893,
                "test_auc": 0.630305052365858,
                "test_f1": 0.571368838587414
              },
              {
                "k": 5,
                "test_accuracy": 0.6139254093145695,
                "test_auc": 0.6392954155264232,
                "test_f1": 0.596392390315998
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6139254093145695,
              "test_auc": 0.6392954155264232,
              "test_f1": 0.596392390315998
            },
            "best_minus_llm_auc": -0.05352105086829129
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T14:35:03+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "491a3c15c13935c7122597ede518d1a0a857d01de1bd073b117d6a5fe5efd95c",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.08/sae_seed1011.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "96bad52266a644d9fecfecbf4396128e6d2015ab4aa8344d7a063af27af9f919",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 14.69216621875763,
            "independent_score_mean_max": 15.623788080215455,
            "interpretability_score_mean_max": 14.364149336814881,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.08_seed1011",
            "sae_id": "custom_sae",
            "date": "2026-02-17 14:35:03",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 14.69216621875763,
            "independent_score_mean_max": 15.623788080215455,
            "interpretability_score_mean_max": 14.364149336814881
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -35.81914121150971,
            "independent_score_mean_max": -35.37547826766968,
            "interpretability_score_mean_max": -33.58746224880218
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.08/seed1011/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8347434273548424,
        "ev_drop": 0.26709018945693974,
        "ev_neg_drop": -0.26709018945693974,
        "saebench_delta": -0.05352105086829129,
        "cebench_delta": -33.58746224880218,
        "cebench_interpretability_max": 14.364149336814881
      },
      "selection": {
        "joint_score": 0.7481107743721055,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    },
    {
      "lambda_consistency": 0.0,
      "d_sae": 3072,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.18844734728336335,
        "std": 0.0003059837005938743,
        "min": 0.18794596940279007,
        "max": 0.18887364864349365,
        "median": 0.1885439231991768,
        "ci95_low": 0.18826177448034287,
        "ci95_high": 0.18862040981650355,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.1640252225100994,
        "std": 0.0002914492152231403,
        "min": 0.1635504812002182,
        "max": 0.16462378203868866,
        "median": 0.16401520371437073,
        "ci95_low": 0.16386052513495086,
        "ci95_high": 0.1641972922347486,
        "n": 10
      },
      "delta_pwmcc": 0.024422124773263942,
      "delta_pwmcc_ci_low_conservative": 0.024064482245594265,
      "ratio_pwmcc": 1.1488924959194018,
      "explained_variance": {
        "mean": 0.8527127146720886,
        "std": 0.00029619645172861494,
        "min": 0.8522933721542358,
        "max": 0.8531134128570557,
        "median": 0.8526833057403564,
        "ci95_low": 0.8524707198143006,
        "ci95_high": 0.8529362440109253,
        "n": 5
      },
      "mse": {
        "mean": 0.00012218514020787553,
        "std": 2.457315501250927e-07,
        "min": 0.00012185269588371739,
        "max": 0.00012253301974851638,
        "median": 0.00012220953067298979,
        "ci95_low": 0.00012199542979942634,
        "ci95_high": 0.00012238164199516178,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.17893202230334282,
        "std": 0.00025345869798676964,
        "min": 0.17862744629383087,
        "max": 0.17914609611034393,
        "median": 0.17897727340459824,
        "ci95_low": 0.1787232756614685,
        "ci95_high": 0.17914076894521713,
        "n": 4
      },
      "runtime_sec": 130.26984858512878,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.00012185269588371739,
          "explained_variance": 0.8531134128570557,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.17862744629383087,
          "mse": 0.00012209962005726993,
          "explained_variance": 0.8528158068656921,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.17913544178009033,
          "mse": 0.00012220953067298979,
          "explained_variance": 0.8526833057403564,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.17881910502910614,
          "mse": 0.00012253301974851638,
          "explained_variance": 0.8522933721542358,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.17914609611034393,
          "mse": 0.00012223083467688411,
          "explained_variance": 0.852657675743103,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 1,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.0,
          "supervised_proxy_loss_train": null,
          "supervised_proxy_accuracy_eval": null,
          "supervised_proxy_num_classes": 0
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.18794596940279007,
        0.18825341761112213,
        0.18811380118131638,
        0.1886357069015503,
        0.18847618252038956,
        0.18817367404699326,
        0.18861166387796402,
        0.1887010708451271,
        0.18868833780288696,
        0.18887364864349365
      ],
      "random_pairwise_pwmcc_values": [
        0.1635504812002182,
        0.1640143245458603,
        0.16401608288288116,
        0.1637066900730133,
        0.16404613107442856,
        0.1639215648174286,
        0.1641985848546028,
        0.16396436095237732,
        0.16462378203868866,
        0.1642102226614952
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
      "selected_checkpoint_seed": 456,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
          "alignment_to_ref": 0.17913544178009033,
          "explained_variance": 0.8526833057403564,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-17T13:49:43+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "cf080d6390d2ad3f2e25945fb5827bb778fa0ad5d2cf8c3f26b44bc7e39d6083",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5922339463042303,
                    "test_auc": 0.5977728124763309,
                    "test_f1": 0.513670665689709
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5939358844384306,
                    "test_auc": 0.6044448816311556,
                    "test_f1": 0.5224244083386272
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.5990433882190835,
                    "test_auc": 0.6216382091990383,
                    "test_f1": 0.5512589180003198
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.5990433882190835,
                  "test_auc": 0.6216382091990383,
                  "test_f1": 0.5512589180003198
                },
                "best_minus_llm_auc": -0.07117825719567616
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T13:51:53+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "06b88d0f2f18c557770a146ecb8e2d83967709b413840f8445e09e42f34ce1b4",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "11a07de24fcf49207b4de552f9a2ef897603f80e1ef3d2b58099257f877e0a85",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.0_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 10.196092100143433,
                "independent_score_mean_max": 10.429015238285064,
                "interpretability_score_mean_max": 10.441005325317382,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-17 13:51:53",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 10.196092100143433,
                "independent_score_mean_max": 10.429015238285064,
                "interpretability_score_mean_max": 10.441005325317382
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -40.315215330123905,
                "independent_score_mean_max": -40.570251109600065,
                "interpretability_score_mean_max": -37.51060626029968
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.07117825719567616,
          "cebench_delta": -37.51060626029968,
          "cebench_interpretability_max": 10.441005325317382,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9172841854463769,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.5399495019351912,
              "alignment": 0.9794575647876803,
              "explained_variance": 0.746377638334284
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt",
          "alignment_to_ref": 0.17881910502910614,
          "explained_variance": 0.8522933721542358,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-17T13:52:30+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "dabf1952126fd34801d502577b7f5b2aedd0752e3ecf2ae26b6a7f124daf4ff1",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5813078403928299,
                    "test_auc": 0.5910117571295512,
                    "test_f1": 0.49264823545271164
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5804280390427752,
                    "test_auc": 0.6059040932864593,
                    "test_f1": 0.5129210078643981
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.5902378746011774,
                    "test_auc": 0.6180760062642267,
                    "test_f1": 0.5388127078496961
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.5902378746011774,
                  "test_auc": 0.6180760062642267,
                  "test_f1": 0.5388127078496961
                },
                "best_minus_llm_auc": -0.07474046013048785
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T13:54:55+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "889c7e6e11e80271a57fe5a0a579fc83d19f9ee3d2bc7351e314f3273daf94e3",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "f10967e9f0e131861579845b90183a4cd6658ebb5f950c479d914e580b7fd64a",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.0_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 10.361549708843231,
                "independent_score_mean_max": 10.78331934928894,
                "interpretability_score_mean_max": 10.674233231544495,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-17 13:54:55",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 10.361549708843231,
                "independent_score_mean_max": 10.78331934928894,
                "interpretability_score_mean_max": 10.674233231544495
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -40.14975772142411,
                "independent_score_mean_max": -40.215946998596195,
                "interpretability_score_mean_max": -37.27737835407257
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.07474046013048785,
          "cebench_delta": -37.27737835407257,
          "cebench_interpretability_max": 10.674233231544495,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.5896514948808999,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.5615663939483461,
              "cebench": 1.0,
              "alignment": 0.3695339883928058,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt",
          "alignment_to_ref": 0.17914609611034393,
          "explained_variance": 0.852657675743103,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-17T13:46:42+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "acd3f245f48d0a140e64700576a688bdcbf8e10e8769973c24c9332b8234bcb5",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5704222937912591,
                    "test_auc": 0.5759697473068347,
                    "test_f1": 0.4755615746549608
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5869041249394854,
                    "test_auc": 0.6080147834373766,
                    "test_f1": 0.5204035619485314
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.598790133810647,
                    "test_auc": 0.6182154097797055,
                    "test_f1": 0.5422254688402578
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.598790133810647,
                  "test_auc": 0.6182154097797055,
                  "test_f1": 0.5422254688402578
                },
                "best_minus_llm_auc": -0.07460105661500904
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T13:49:06+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "7c9ca32c42ff6e3b266995da4b58a7199686291e5fe60ed966fe13fd887d17cd",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "8639d97807bff9b8fcbe6a3e6ae2159fc1f33cafc1c31f46d6b5eb8969b451b4",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.877204098701476,
                "independent_score_mean_max": 11.0145872092247,
                "interpretability_score_mean_max": 10.16727169752121,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-17 13:49:06",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.877204098701476,
                "independent_score_mean_max": 11.0145872092247,
                "interpretability_score_mean_max": 10.16727169752121
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -40.63410333156586,
                "independent_score_mean_max": -39.98467913866043,
                "interpretability_score_mean_max": -37.78433988809586
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.07460105661500904,
          "cebench_delta": -37.78433988809586,
          "cebench_interpretability_max": 10.16727169752121,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.5189090096499562,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.5787240874054941,
              "cebench": 0.0,
              "alignment": 1.0,
              "explained_variance": 0.6973188819167142
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt",
          "alignment_to_ref": 0.17862744629383087,
          "explained_variance": 0.8528158068656921,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-17T13:55:33+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "333a0757af9a572d88217bf513073c02c9499907e9b0bbef4f16bad0c405d0ae",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.5844798733918964,
                    "test_auc": 0.5879168889685746,
                    "test_f1": 0.5085568718667245
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.5917775648840801,
                    "test_auc": 0.5961223460293172,
                    "test_f1": 0.5254993035676552
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.5978387803822386,
                    "test_auc": 0.6135133691191654,
                    "test_f1": 0.5527361780240143
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.5978387803822386,
                  "test_auc": 0.6135133691191654,
                  "test_f1": 0.5527361780240143
                },
                "best_minus_llm_auc": -0.07930309727554907
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-17T13:57:59+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "2b1c9f207a8583f6bc3aa028ece6cde940459abb7e10e89b6b8b92de51f593cd",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "d7f2012fdda5cd84a5f892f20c9d7af72d9c4604c0341614dc8e09dfa4e95aae",
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 3072,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.0_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 10.35431608915329,
                "independent_score_mean_max": 10.762057542800903,
                "interpretability_score_mean_max": 10.65065663099289,
                "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-17 13:57:59",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 10.35431608915329,
                "independent_score_mean_max": 10.762057542800903,
                "interpretability_score_mean_max": 10.65065663099289
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -40.15699134111405,
                "independent_score_mean_max": -40.23720880508423,
                "interpretability_score_mean_max": -37.300954954624174
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.07930309727554907,
          "cebench_delta": -37.300954954624174,
          "cebench_interpretability_max": 10.65065663099289,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.19302414513646599,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.75,
              "cebench": 0.15,
              "alignment": 0.05,
              "explained_variance": 0.05
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.9534943009097732,
              "alignment": 0.0,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
        "candidate_tag": "seed456",
        "saebench": {
          "timestamp_utc": "2026-02-17T13:49:43+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "cf080d6390d2ad3f2e25945fb5827bb778fa0ad5d2cf8c3f26b44bc7e39d6083",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.5922339463042303,
                "test_auc": 0.5977728124763309,
                "test_f1": 0.513670665689709
              },
              {
                "k": 2,
                "test_accuracy": 0.5939358844384306,
                "test_auc": 0.6044448816311556,
                "test_f1": 0.5224244083386272
              },
              {
                "k": 5,
                "test_accuracy": 0.5990433882190835,
                "test_auc": 0.6216382091990383,
                "test_f1": 0.5512589180003198
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.5990433882190835,
              "test_auc": 0.6216382091990383,
              "test_f1": 0.5512589180003198
            },
            "best_minus_llm_auc": -0.07117825719567616
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-17T13:51:53+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.0_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "06b88d0f2f18c557770a146ecb8e2d83967709b413840f8445e09e42f34ce1b4",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.0/sae_seed456.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "11a07de24fcf49207b4de552f9a2ef897603f80e1ef3d2b58099257f877e0a85",
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 3072,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.0_seed456/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 10.196092100143433,
            "independent_score_mean_max": 10.429015238285064,
            "interpretability_score_mean_max": 10.441005325317382,
            "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.0_seed456",
            "sae_id": "custom_sae",
            "date": "2026-02-17 13:51:53",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 10.196092100143433,
            "independent_score_mean_max": 10.429015238285064,
            "interpretability_score_mean_max": 10.441005325317382
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -40.315215330123905,
            "independent_score_mean_max": -40.570251109600065,
            "interpretability_score_mean_max": -37.51060626029968
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.0/seed456/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.024064482245594265,
        "ev_drop": 0.0,
        "ev_neg_drop": -0.0,
        "saebench_delta": -0.07117825719567616,
        "cebench_delta": -37.51060626029968,
        "cebench_interpretability_max": 10.441005325317382
      },
      "selection": {
        "joint_score": 0.05,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.55,
          "cebench_delta": 0.2
        }
      }
    }
  ],
  "selected": {
    "lambda_consistency": 0.1,
    "d_sae": 3072,
    "k": 48,
    "n_models": 5,
    "seed_ref": 42,
    "train_seeds": [
      123,
      456,
      789,
      1011
    ],
    "trained_pwmcc": {
      "mean": 0.9992468476295471,
      "std": 0.00023886581625513065,
      "min": 0.9990355670452118,
      "max": 0.9995493292808533,
      "median": 0.9990836828947067,
      "ci95_low": 0.9991079920530319,
      "ci95_high": 0.9993876112997532,
      "n": 10
    },
    "random_pwmcc": {
      "mean": 0.1640252225100994,
      "std": 0.0002914492152231403,
      "min": 0.1635504812002182,
      "max": 0.16462378203868866,
      "median": 0.16401520371437073,
      "ci95_low": 0.16386052513495086,
      "ci95_high": 0.1641972922347486,
      "n": 10
    },
    "delta_pwmcc": 0.8352216251194476,
    "delta_pwmcc_ci_low_conservative": 0.8349106998182834,
    "ratio_pwmcc": 6.092031654265984,
    "explained_variance": {
      "mean": 0.5791060209274292,
      "std": 0.15318464653674643,
      "min": 0.5077364444732666,
      "max": 0.8531134128570557,
      "median": 0.5118701457977295,
      "ci95_low": 0.5093899250030518,
      "ci95_high": 0.7164300680160522,
      "n": 5
    },
    "mse": {
      "mean": 0.0003491615687380545,
      "std": 0.0001270776986426151,
      "min": 0.00012185269588371739,
      "max": 0.0004083674284629524,
      "median": 0.00040493832784704864,
      "ci95_low": 0.0002352798022911884,
      "ci95_high": 0.0004069574817549437,
      "n": 5
    },
    "alignment_to_ref": {
      "mean": 0.9995235204696655,
      "std": 1.916645410251353e-05,
      "min": 0.9995052814483643,
      "max": 0.9995493292808533,
      "median": 0.9995197355747223,
      "ci95_low": 0.9995094537734985,
      "ci95_high": 0.9995404034852982,
      "n": 4
    },
    "runtime_sec": 1430.774831533432,
    "per_seed_metrics": [
      {
        "seed": 42,
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed42.pt",
        "lambda_consistency": 0.0,
        "alignment_to_ref": 1.0,
        "mse": 0.00012185269588371739,
        "explained_variance": 0.8531134128570557,
        "l0": 48.0,
        "assignment_alignment_mean_train": null,
        "assignment_update_interval": 1,
        "assignment_hungarian_solves_train": 0,
        "train_steps": 864,
        "supervised_proxy_weight": 0.0,
        "supervised_proxy_loss_train": null,
        "supervised_proxy_accuracy_eval": null,
        "supervised_proxy_num_classes": 0
      },
      {
        "seed": 123,
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
        "lambda_consistency": 0.1,
        "alignment_to_ref": 0.9995258450508118,
        "mse": 0.0004047467955388129,
        "explained_variance": 0.5121017694473267,
        "l0": 48.0,
        "assignment_alignment_mean_train": 0.9130210986326414,
        "assignment_update_interval": 1,
        "assignment_hungarian_solves_train": 864,
        "train_steps": 864,
        "supervised_proxy_weight": 0.0,
        "supervised_proxy_loss_train": null,
        "supervised_proxy_accuracy_eval": null,
        "supervised_proxy_num_classes": 0
      },
      {
        "seed": 456,
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
        "lambda_consistency": 0.1,
        "alignment_to_ref": 0.9995136260986328,
        "mse": 0.0004083674284629524,
        "explained_variance": 0.5077364444732666,
        "l0": 48.0,
        "assignment_alignment_mean_train": 0.9130018554731376,
        "assignment_update_interval": 1,
        "assignment_hungarian_solves_train": 864,
        "train_steps": 864,
        "supervised_proxy_weight": 0.0,
        "supervised_proxy_loss_train": null,
        "supervised_proxy_accuracy_eval": null,
        "supervised_proxy_num_classes": 0
      },
      {
        "seed": 789,
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
        "lambda_consistency": 0.1,
        "alignment_to_ref": 0.9995493292808533,
        "mse": 0.00040493832784704864,
        "explained_variance": 0.5118701457977295,
        "l0": 48.0,
        "assignment_alignment_mean_train": 0.9130613664165139,
        "assignment_update_interval": 1,
        "assignment_hungarian_solves_train": 864,
        "train_steps": 864,
        "supervised_proxy_weight": 0.0,
        "supervised_proxy_loss_train": null,
        "supervised_proxy_accuracy_eval": null,
        "supervised_proxy_num_classes": 0
      },
      {
        "seed": 1011,
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
        "lambda_consistency": 0.1,
        "alignment_to_ref": 0.9995052814483643,
        "mse": 0.00040590259595774114,
        "explained_variance": 0.5107083320617676,
        "l0": 48.0,
        "assignment_alignment_mean_train": 0.9130352277964078,
        "assignment_update_interval": 1,
        "assignment_hungarian_solves_train": 864,
        "train_steps": 864,
        "supervised_proxy_weight": 0.0,
        "supervised_proxy_loss_train": null,
        "supervised_proxy_accuracy_eval": null,
        "supervised_proxy_num_classes": 0
      }
    ],
    "trained_pairwise_pwmcc_values": [
      0.9995259046554565,
      0.9995136260986328,
      0.9995493292808533,
      0.9995052814483643,
      0.9990586638450623,
      0.9990898370742798,
      0.9990452527999878,
      0.9990775287151337,
      0.9990355670452118,
      0.999067485332489
    ],
    "random_pairwise_pwmcc_values": [
      0.1635504812002182,
      0.1640143245458603,
      0.16401608288288116,
      0.1637066900730133,
      0.16404613107442856,
      0.1639215648174286,
      0.1641985848546028,
      0.16396436095237732,
      0.16462378203868866,
      0.1642102226614952
    ],
    "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
    "selected_checkpoint_seed": 1011,
    "selected_checkpoint_policy": "external_score",
    "external_candidate_evals": [
      {
        "seed": 1011,
        "candidate_tag": "seed1011",
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
        "alignment_to_ref": 0.9995052814483643,
        "explained_variance": 0.5107083320617676,
        "external_eval": {
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
          "candidate_tag": "seed1011",
          "saebench": {
            "timestamp_utc": "2026-02-17T14:44:49+00:00",
            "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
            "config": {
              "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
              "architecture_override": "topk",
              "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
              "model_name": "pythia-70m-deduped",
              "hook_layer": 0,
              "hook_name": "blocks.0.hook_resid_pre",
              "reg_type": "l1",
              "setting": "normal",
              "ks": [
                1,
                2,
                5
              ],
              "dataset_names": [
                "100_news_fake",
                "105_click_bait",
                "106_hate_hate",
                "107_hate_offensive",
                "110_aimade_humangpt3",
                "113_movie_sent",
                "114_nyc_borough_Manhattan",
                "115_nyc_borough_Brooklyn",
                "116_nyc_borough_Bronx",
                "117_us_state_FL",
                "118_us_state_CA",
                "119_us_state_TX",
                "120_us_timezone_Chicago",
                "121_us_timezone_New_York",
                "122_us_timezone_Los_Angeles",
                "123_world_country_United_Kingdom"
              ],
              "dataset_names_inferred_from_cache": false,
              "dataset_count": 16,
              "binarize": false,
              "device": "cuda",
              "dtype": "float32",
              "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
              "model_cache_path": "/tmp/sae_bench_model_cache",
              "force_rerun": true
            },
            "config_hash": "c690dface618319f2e5550c5ea683feb28167c6dcc1b4fd7c4d825a9fd96a257",
            "sae_meta": {
              "architecture": "topk",
              "eval_architecture": "topk",
              "d_model": 512,
              "d_sae": 3072,
              "k": 48,
              "dead_features_repaired": 0,
              "decoder_norm_max_deviation": 1.1920928955078125e-07
            },
            "summary": {
              "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011_custom_sae",
              "llm_metrics": {
                "llm_test_accuracy": 0.6605360072070458,
                "llm_test_auc": 0.6928164663947145,
                "llm_test_f1": 0.6491238078533221
              },
              "sae_metrics_by_k": [
                {
                  "k": 1,
                  "test_accuracy": 0.6005670166803218,
                  "test_auc": 0.610328512906832,
                  "test_f1": 0.560869596403959
                },
                {
                  "k": 2,
                  "test_accuracy": 0.5994583508065682,
                  "test_auc": 0.6212511983198329,
                  "test_f1": 0.5613903360397708
                },
                {
                  "k": 5,
                  "test_accuracy": 0.6167744931570085,
                  "test_auc": 0.6453791395072228,
                  "test_f1": 0.5994146554784834
                }
              ],
              "best_by_auc": {
                "k": 5,
                "test_accuracy": 0.6167744931570085,
                "test_auc": 0.6453791395072228,
                "test_f1": 0.5994146554784834
              },
              "best_minus_llm_auc": -0.04743732688749169
            }
          },
          "cebench": {
            "timestamp_utc": "2026-02-17T14:47:18+00:00",
            "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
            "config_hash": "3d52b0da409f2cf568e21830ca41dc989c118af2ac9f16d3da4e976d724f6bb5",
            "config": {
              "cebench_repo": "/workspace/CE-Bench",
              "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
              "architecture_override": "topk",
              "checkpoint_sha256": "67f87d4a084ff529329bec9a03f006a2840bc5d158a1ca9f4c728e00cc1f1c54",
              "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
              "model_name": "pythia-70m-deduped",
              "hook_layer": 0,
              "hook_name": "blocks.0.hook_resid_pre",
              "device": "cuda",
              "sae_dtype": "float32",
              "llm_batch_size": 512,
              "llm_dtype": "float32",
              "random_seed": 42,
              "dataset_name": "GulkoA/contrastive-stories-v4",
              "dataset_rows_total": 5000,
              "dataset_rows_used": 200,
              "max_rows": 200,
              "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench",
              "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
              "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
            },
            "sae_meta": {
              "architecture": "topk",
              "eval_architecture": "topk",
              "d_model": 512,
              "d_sae": 3072,
              "k": 48,
              "dead_features_repaired": 0,
              "decoder_norm_max_deviation": 1.1920928955078125e-07
            },
            "cebench_summary": {
              "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench",
              "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011/custom_sae/results.json",
              "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/scores_dump.txt",
              "total_rows": 200,
              "contrastive_score_mean_max": 14.53305012702942,
              "independent_score_mean_max": 15.707403116226196,
              "interpretability_score_mean_max": 14.274428329467774,
              "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
              "sae_id": "custom_sae",
              "date": "2026-02-17 14:47:18",
              "scores_dump_line_count": 200
            },
            "custom_metrics": {
              "contrastive_score_mean_max": 14.53305012702942,
              "independent_score_mean_max": 15.707403116226196,
              "interpretability_score_mean_max": 14.274428329467774
            },
            "matched_baseline_metrics": {
              "contrastive_score_mean_max": 50.51130743026734,
              "independent_score_mean_max": 50.99926634788513,
              "interpretability_score_mean_max": 47.951611585617066
            },
            "delta_vs_matched_baseline": {
              "contrastive_score_mean_max": -35.97825730323792,
              "independent_score_mean_max": -35.29186323165894,
              "interpretability_score_mean_max": -33.67718325614929
            },
            "matched_baseline_payload": {
              "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
              "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
              "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
              "total_rows": 200,
              "contrastive_score_mean_max": 50.51130743026734,
              "independent_score_mean_max": 50.99926634788513,
              "interpretability_score_mean_max": 47.951611585617066,
              "sae_release": "pythia-70m-deduped-res-sm",
              "sae_id": "blocks.0.hook_resid_pre",
              "date": "2026-02-13 18:59:31",
              "scores_dump_line_count": 200
            },
            "artifacts": {
              "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.json",
              "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.md"
            }
          },
          "saebench_returncode": 0,
          "cebench_returncode": 0,
          "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/saebench/husai_custom_sae_summary.json",
          "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/husai_custom_cebench_summary.json",
          "external_skip_reason": null
        },
        "saebench_delta": -0.04743732688749169,
        "cebench_delta": -33.67718325614929,
        "cebench_interpretability_max": 14.274428329467774,
        "selection": {
          "policy": "external_score",
          "checkpoint_score": 0.7962082570378375,
          "passes_external_floor": false,
          "weights": {
            "saebench": 0.75,
            "cebench": 0.15,
            "alignment": 0.05,
            "explained_variance": 0.05
          },
          "normalized": {
            "saebench": 1.0,
            "cebench": 0.08112367249580285,
            "alignment": 0.0,
            "explained_variance": 0.6807941232693411
          }
        }
      },
      {
        "seed": 123,
        "candidate_tag": "seed123",
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
        "alignment_to_ref": 0.9995258450508118,
        "explained_variance": 0.5121017694473267,
        "external_eval": {
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
          "candidate_tag": "seed123",
          "saebench": {
            "timestamp_utc": "2026-02-17T14:38:42+00:00",
            "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
            "config": {
              "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
              "architecture_override": "topk",
              "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed123",
              "model_name": "pythia-70m-deduped",
              "hook_layer": 0,
              "hook_name": "blocks.0.hook_resid_pre",
              "reg_type": "l1",
              "setting": "normal",
              "ks": [
                1,
                2,
                5
              ],
              "dataset_names": [
                "100_news_fake",
                "105_click_bait",
                "106_hate_hate",
                "107_hate_offensive",
                "110_aimade_humangpt3",
                "113_movie_sent",
                "114_nyc_borough_Manhattan",
                "115_nyc_borough_Brooklyn",
                "116_nyc_borough_Bronx",
                "117_us_state_FL",
                "118_us_state_CA",
                "119_us_state_TX",
                "120_us_timezone_Chicago",
                "121_us_timezone_New_York",
                "122_us_timezone_Los_Angeles",
                "123_world_country_United_Kingdom"
              ],
              "dataset_names_inferred_from_cache": false,
              "dataset_count": 16,
              "binarize": false,
              "device": "cuda",
              "dtype": "float32",
              "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
              "model_cache_path": "/tmp/sae_bench_model_cache",
              "force_rerun": true
            },
            "config_hash": "a15678ef469de3ed87d0ecd8931606d35a1428a03815359a0f92290d3101ec62",
            "sae_meta": {
              "architecture": "topk",
              "eval_architecture": "topk",
              "d_model": 512,
              "d_sae": 3072,
              "k": 48,
              "dead_features_repaired": 0,
              "decoder_norm_max_deviation": 1.1920928955078125e-07
            },
            "summary": {
              "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed123_custom_sae",
              "llm_metrics": {
                "llm_test_accuracy": 0.6605360072070458,
                "llm_test_auc": 0.6928164663947145,
                "llm_test_f1": 0.6491238078533221
              },
              "sae_metrics_by_k": [
                {
                  "k": 1,
                  "test_accuracy": 0.5857180551684256,
                  "test_auc": 0.5898490248552595,
                  "test_f1": 0.5497016292959489
                },
                {
                  "k": 2,
                  "test_accuracy": 0.5976258767401619,
                  "test_auc": 0.6182818100662946,
                  "test_f1": 0.5617583060413073
                },
                {
                  "k": 5,
                  "test_accuracy": 0.6108792386330605,
                  "test_auc": 0.6370931803979578,
                  "test_f1": 0.5721131684000194
                }
              ],
              "best_by_auc": {
                "k": 5,
                "test_accuracy": 0.6108792386330605,
                "test_auc": 0.6370931803979578,
                "test_f1": 0.5721131684000194
              },
              "best_minus_llm_auc": -0.05572328599675669
            }
          },
          "cebench": {
            "timestamp_utc": "2026-02-17T14:41:11+00:00",
            "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
            "config_hash": "0e56d4bf48f77762e8d7598e984c428072dffe4599f1ae90608edd24bdc080e4",
            "config": {
              "cebench_repo": "/workspace/CE-Bench",
              "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed123.pt",
              "architecture_override": "topk",
              "checkpoint_sha256": "3c673315941ba48695ade32d013f1fa20e99d927559aaefd558b43f4a21376a5",
              "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed123",
              "model_name": "pythia-70m-deduped",
              "hook_layer": 0,
              "hook_name": "blocks.0.hook_resid_pre",
              "device": "cuda",
              "sae_dtype": "float32",
              "llm_batch_size": 512,
              "llm_dtype": "float32",
              "random_seed": 42,
              "dataset_name": "GulkoA/contrastive-stories-v4",
              "dataset_rows_total": 5000,
              "dataset_rows_used": 200,
              "max_rows": 200,
              "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench",
              "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
              "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
            },
            "sae_meta": {
              "architecture": "topk",
              "eval_architecture": "topk",
              "d_model": 512,
              "d_sae": 3072,
              "k": 48,
              "dead_features_repaired": 0,
              "decoder_norm_max_deviation": 1.1920928955078125e-07
            },
            "cebench_summary": {
              "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench",
              "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed123/custom_sae/results.json",
              "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/scores_dump.txt",
              "total_rows": 200,
              "contrastive_score_mean_max": 14.454545342922211,
              "independent_score_mean_max": 15.87158621788025,
              "interpretability_score_mean_max": 14.233841514587402,
              "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed123",
              "sae_id": "custom_sae",
              "date": "2026-02-17 14:41:11",
              "scores_dump_line_count": 200
            },
            "custom_metrics": {
              "contrastive_score_mean_max": 14.454545342922211,
              "independent_score_mean_max": 15.87158621788025,
              "interpretability_score_mean_max": 14.233841514587402
            },
            "matched_baseline_metrics": {
              "contrastive_score_mean_max": 50.51130743026734,
              "independent_score_mean_max": 50.99926634788513,
              "interpretability_score_mean_max": 47.951611585617066
            },
            "delta_vs_matched_baseline": {
              "contrastive_score_mean_max": -36.05676208734513,
              "independent_score_mean_max": -35.12768013000488,
              "interpretability_score_mean_max": -33.71777007102966
            },
            "matched_baseline_payload": {
              "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
              "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
              "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
              "total_rows": 200,
              "contrastive_score_mean_max": 50.51130743026734,
              "independent_score_mean_max": 50.99926634788513,
              "interpretability_score_mean_max": 47.951611585617066,
              "sae_release": "pythia-70m-deduped-res-sm",
              "sae_id": "blocks.0.hook_resid_pre",
              "date": "2026-02-13 18:59:31",
              "scores_dump_line_count": 200
            },
            "artifacts": {
              "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.json",
              "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.md"
            }
          },
          "saebench_returncode": 0,
          "cebench_returncode": 0,
          "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/saebench/husai_custom_sae_summary.json",
          "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed123/cebench/husai_custom_cebench_summary.json",
          "external_skip_reason": null
        },
        "saebench_delta": -0.05572328599675669,
        "cebench_delta": -33.71777007102966,
        "cebench_interpretability_max": 14.233841514587402,
        "selection": {
          "policy": "external_score",
          "checkpoint_score": 0.32226806614881404,
          "passes_external_floor": false,
          "weights": {
            "saebench": 0.75,
            "cebench": 0.15,
            "alignment": 0.05,
            "explained_variance": 0.05
          },
          "normalized": {
            "saebench": 0.3319009488208815,
            "cebench": 0.0,
            "alignment": 0.4668470906630582,
            "explained_variance": 1.0
          }
        }
      },
      {
        "seed": 789,
        "candidate_tag": "seed789",
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
        "alignment_to_ref": 0.9995493292808533,
        "explained_variance": 0.5118701457977295,
        "external_eval": {
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
          "candidate_tag": "seed789",
          "saebench": {
            "timestamp_utc": "2026-02-17T14:35:37+00:00",
            "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
            "config": {
              "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
              "architecture_override": "topk",
              "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed789",
              "model_name": "pythia-70m-deduped",
              "hook_layer": 0,
              "hook_name": "blocks.0.hook_resid_pre",
              "reg_type": "l1",
              "setting": "normal",
              "ks": [
                1,
                2,
                5
              ],
              "dataset_names": [
                "100_news_fake",
                "105_click_bait",
                "106_hate_hate",
                "107_hate_offensive",
                "110_aimade_humangpt3",
                "113_movie_sent",
                "114_nyc_borough_Manhattan",
                "115_nyc_borough_Brooklyn",
                "116_nyc_borough_Bronx",
                "117_us_state_FL",
                "118_us_state_CA",
                "119_us_state_TX",
                "120_us_timezone_Chicago",
                "121_us_timezone_New_York",
                "122_us_timezone_Los_Angeles",
                "123_world_country_United_Kingdom"
              ],
              "dataset_names_inferred_from_cache": false,
              "dataset_count": 16,
              "binarize": false,
              "device": "cuda",
              "dtype": "float32",
              "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
              "model_cache_path": "/tmp/sae_bench_model_cache",
              "force_rerun": true
            },
            "config_hash": "45dba9bfe33e056e2d15b409257967058cd016b364f703977225dfba167932d1",
            "sae_meta": {
              "architecture": "topk",
              "eval_architecture": "topk",
              "d_model": 512,
              "d_sae": 3072,
              "k": 48,
              "dead_features_repaired": 0,
              "decoder_norm_max_deviation": 1.1920928955078125e-07
            },
            "summary": {
              "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed789_custom_sae",
              "llm_metrics": {
                "llm_test_accuracy": 0.6605360072070458,
                "llm_test_auc": 0.6928164663947145,
                "llm_test_f1": 0.6491238078533221
              },
              "sae_metrics_by_k": [
                {
                  "k": 1,
                  "test_accuracy": 0.6013639660591745,
                  "test_auc": 0.6112161036980954,
                  "test_f1": 0.5556944197807919
                },
                {
                  "k": 2,
                  "test_accuracy": 0.6057861750352806,
                  "test_auc": 0.6193888294894893,
                  "test_f1": 0.5697745452494726
                },
                {
                  "k": 5,
                  "test_accuracy": 0.6090151503413785,
                  "test_auc": 0.6329768481184815,
                  "test_f1": 0.5811284768526122
                }
              ],
              "best_by_auc": {
                "k": 5,
                "test_accuracy": 0.6090151503413785,
                "test_auc": 0.6329768481184815,
                "test_f1": 0.5811284768526122
              },
              "best_minus_llm_auc": -0.059839618276232964
            }
          },
          "cebench": {
            "timestamp_utc": "2026-02-17T14:38:08+00:00",
            "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
            "config_hash": "7ccc8168801496d3189507ce2d5976ab9a84af74877a26146afaf8e3bcdc0d5e",
            "config": {
              "cebench_repo": "/workspace/CE-Bench",
              "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed789.pt",
              "architecture_override": "topk",
              "checkpoint_sha256": "e8ab6ad2f04b82568dce36ce788ee286f746ba6a9d1ac0861fb9f27de9284492",
              "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed789",
              "model_name": "pythia-70m-deduped",
              "hook_layer": 0,
              "hook_name": "blocks.0.hook_resid_pre",
              "device": "cuda",
              "sae_dtype": "float32",
              "llm_batch_size": 512,
              "llm_dtype": "float32",
              "random_seed": 42,
              "dataset_name": "GulkoA/contrastive-stories-v4",
              "dataset_rows_total": 5000,
              "dataset_rows_used": 200,
              "max_rows": 200,
              "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench",
              "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
              "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
            },
            "sae_meta": {
              "architecture": "topk",
              "eval_architecture": "topk",
              "d_model": 512,
              "d_sae": 3072,
              "k": 48,
              "dead_features_repaired": 0,
              "decoder_norm_max_deviation": 1.1920928955078125e-07
            },
            "cebench_summary": {
              "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench",
              "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed789/custom_sae/results.json",
              "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/scores_dump.txt",
              "total_rows": 200,
              "contrastive_score_mean_max": 14.963360185623168,
              "independent_score_mean_max": 16.489828758239746,
              "interpretability_score_mean_max": 14.734149422645569,
              "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed789",
              "sae_id": "custom_sae",
              "date": "2026-02-17 14:38:07",
              "scores_dump_line_count": 200
            },
            "custom_metrics": {
              "contrastive_score_mean_max": 14.963360185623168,
              "independent_score_mean_max": 16.489828758239746,
              "interpretability_score_mean_max": 14.734149422645569
            },
            "matched_baseline_metrics": {
              "contrastive_score_mean_max": 50.51130743026734,
              "independent_score_mean_max": 50.99926634788513,
              "interpretability_score_mean_max": 47.951611585617066
            },
            "delta_vs_matched_baseline": {
              "contrastive_score_mean_max": -35.54794724464417,
              "independent_score_mean_max": -34.50943758964539,
              "interpretability_score_mean_max": -33.2174621629715
            },
            "matched_baseline_payload": {
              "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
              "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
              "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
              "total_rows": 200,
              "contrastive_score_mean_max": 50.51130743026734,
              "independent_score_mean_max": 50.99926634788513,
              "interpretability_score_mean_max": 47.951611585617066,
              "sae_release": "pythia-70m-deduped-res-sm",
              "sae_id": "blocks.0.hook_resid_pre",
              "date": "2026-02-13 18:59:31",
              "scores_dump_line_count": 200
            },
            "artifacts": {
              "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/cebench_metrics_summary.json",
              "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/cebench_metrics_summary.md"
            }
          },
          "saebench_returncode": 0,
          "cebench_returncode": 0,
          "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/saebench/husai_custom_sae_summary.json",
          "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed789/cebench/husai_custom_cebench_summary.json",
          "external_skip_reason": null
        },
        "saebench_delta": -0.059839618276232964,
        "cebench_delta": -33.2174621629715,
        "cebench_interpretability_max": 14.734149422645569,
        "selection": {
          "policy": "external_score",
          "checkpoint_score": 0.2473470056528032,
          "passes_external_floor": false,
          "weights": {
            "saebench": 0.75,
            "cebench": 0.15,
            "alignment": 0.05,
            "explained_variance": 0.05
          },
          "normalized": {
            "saebench": 0.0,
            "cebench": 1.0,
            "alignment": 1.0,
            "explained_variance": 0.9469401130560637
          }
        }
      },
      {
        "seed": 456,
        "candidate_tag": "seed456",
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
        "alignment_to_ref": 0.9995136260986328,
        "explained_variance": 0.5077364444732666,
        "external_eval": {
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
          "candidate_tag": "seed456",
          "saebench": {
            "timestamp_utc": "2026-02-17T14:41:45+00:00",
            "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
            "config": {
              "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
              "architecture_override": "topk",
              "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed456",
              "model_name": "pythia-70m-deduped",
              "hook_layer": 0,
              "hook_name": "blocks.0.hook_resid_pre",
              "reg_type": "l1",
              "setting": "normal",
              "ks": [
                1,
                2,
                5
              ],
              "dataset_names": [
                "100_news_fake",
                "105_click_bait",
                "106_hate_hate",
                "107_hate_offensive",
                "110_aimade_humangpt3",
                "113_movie_sent",
                "114_nyc_borough_Manhattan",
                "115_nyc_borough_Brooklyn",
                "116_nyc_borough_Bronx",
                "117_us_state_FL",
                "118_us_state_CA",
                "119_us_state_TX",
                "120_us_timezone_Chicago",
                "121_us_timezone_New_York",
                "122_us_timezone_Los_Angeles",
                "123_world_country_United_Kingdom"
              ],
              "dataset_names_inferred_from_cache": false,
              "dataset_count": 16,
              "binarize": false,
              "device": "cuda",
              "dtype": "float32",
              "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
              "model_cache_path": "/tmp/sae_bench_model_cache",
              "force_rerun": true
            },
            "config_hash": "b46916ae31f36fb7c4849231404eee90530a4e6886cbcec44eaefc1a650feb37",
            "sae_meta": {
              "architecture": "topk",
              "eval_architecture": "topk",
              "d_model": 512,
              "d_sae": 3072,
              "k": 48,
              "dead_features_repaired": 0,
              "decoder_norm_max_deviation": 1.1920928955078125e-07
            },
            "summary": {
              "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed456_custom_sae",
              "llm_metrics": {
                "llm_test_accuracy": 0.6605360072070458,
                "llm_test_auc": 0.6928164663947145,
                "llm_test_f1": 0.6491238078533221
              },
              "sae_metrics_by_k": [
                {
                  "k": 1,
                  "test_accuracy": 0.5934354760787593,
                  "test_auc": 0.60302511348788,
                  "test_f1": 0.557938764186839
                },
                {
                  "k": 2,
                  "test_accuracy": 0.6025555326857831,
                  "test_auc": 0.6164667363208649,
                  "test_f1": 0.5770236893266685
                },
                {
                  "k": 5,
                  "test_accuracy": 0.6143169135212134,
                  "test_auc": 0.634824852518261,
                  "test_f1": 0.59718468201138
                }
              ],
              "best_by_auc": {
                "k": 5,
                "test_accuracy": 0.6143169135212134,
                "test_auc": 0.634824852518261,
                "test_f1": 0.59718468201138
              },
              "best_minus_llm_auc": -0.05799161387645346
            }
          },
          "cebench": {
            "timestamp_utc": "2026-02-17T14:44:15+00:00",
            "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
            "config_hash": "69b33b33626adc1552ef6aef823c6dea1e9b72aaae20da1d5e55aa3d97925d9b",
            "config": {
              "cebench_repo": "/workspace/CE-Bench",
              "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed456.pt",
              "architecture_override": "topk",
              "checkpoint_sha256": "72ae14220abccf9403ef15747038d3bc7ec4b3c28f2d6a8ff3a1e53d2b0395ea",
              "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed456",
              "model_name": "pythia-70m-deduped",
              "hook_layer": 0,
              "hook_name": "blocks.0.hook_resid_pre",
              "device": "cuda",
              "sae_dtype": "float32",
              "llm_batch_size": 512,
              "llm_dtype": "float32",
              "random_seed": 42,
              "dataset_name": "GulkoA/contrastive-stories-v4",
              "dataset_rows_total": 5000,
              "dataset_rows_used": 200,
              "max_rows": 200,
              "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench",
              "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
              "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
            },
            "sae_meta": {
              "architecture": "topk",
              "eval_architecture": "topk",
              "d_model": 512,
              "d_sae": 3072,
              "k": 48,
              "dead_features_repaired": 0,
              "decoder_norm_max_deviation": 1.1920928955078125e-07
            },
            "cebench_summary": {
              "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench",
              "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed456/custom_sae/results.json",
              "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/scores_dump.txt",
              "total_rows": 200,
              "contrastive_score_mean_max": 14.621507120132446,
              "independent_score_mean_max": 16.828977513313294,
              "interpretability_score_mean_max": 14.498566346168518,
              "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed456",
              "sae_id": "custom_sae",
              "date": "2026-02-17 14:44:15",
              "scores_dump_line_count": 200
            },
            "custom_metrics": {
              "contrastive_score_mean_max": 14.621507120132446,
              "independent_score_mean_max": 16.828977513313294,
              "interpretability_score_mean_max": 14.498566346168518
            },
            "matched_baseline_metrics": {
              "contrastive_score_mean_max": 50.51130743026734,
              "independent_score_mean_max": 50.99926634788513,
              "interpretability_score_mean_max": 47.951611585617066
            },
            "delta_vs_matched_baseline": {
              "contrastive_score_mean_max": -35.88980031013489,
              "independent_score_mean_max": -34.170288834571835,
              "interpretability_score_mean_max": -33.45304523944855
            },
            "matched_baseline_payload": {
              "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
              "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
              "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
              "total_rows": 200,
              "contrastive_score_mean_max": 50.51130743026734,
              "independent_score_mean_max": 50.99926634788513,
              "interpretability_score_mean_max": 47.951611585617066,
              "sae_release": "pythia-70m-deduped-res-sm",
              "sae_id": "blocks.0.hook_resid_pre",
              "date": "2026-02-13 18:59:31",
              "scores_dump_line_count": 200
            },
            "artifacts": {
              "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/cebench_metrics_summary.json",
              "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/cebench_metrics_summary.md"
            }
          },
          "saebench_returncode": 0,
          "cebench_returncode": 0,
          "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/saebench/husai_custom_sae_summary.json",
          "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed456/cebench/husai_custom_cebench_summary.json",
          "external_skip_reason": null
        },
        "saebench_delta": -0.05799161387645346,
        "cebench_delta": -33.45304523944855,
        "cebench_interpretability_max": 14.498566346168518,
        "selection": {
          "policy": "external_score",
          "checkpoint_score": 0.20059464158167215,
          "passes_external_floor": false,
          "weights": {
            "saebench": 0.75,
            "cebench": 0.15,
            "alignment": 0.05,
            "explained_variance": 0.05
          },
          "normalized": {
            "saebench": 0.14900507832424492,
            "cebench": 0.5291238201862243,
            "alignment": 0.18944519621109607,
            "explained_variance": 0.0
          }
        }
      }
    ],
    "external_eval": {
      "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
      "candidate_tag": "seed1011",
      "saebench": {
        "timestamp_utc": "2026-02-17T14:44:49+00:00",
        "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle8_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
        "config": {
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
          "architecture_override": "topk",
          "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "reg_type": "l1",
          "setting": "normal",
          "ks": [
            1,
            2,
            5
          ],
          "dataset_names": [
            "100_news_fake",
            "105_click_bait",
            "106_hate_hate",
            "107_hate_offensive",
            "110_aimade_humangpt3",
            "113_movie_sent",
            "114_nyc_borough_Manhattan",
            "115_nyc_borough_Brooklyn",
            "116_nyc_borough_Bronx",
            "117_us_state_FL",
            "118_us_state_CA",
            "119_us_state_TX",
            "120_us_timezone_Chicago",
            "121_us_timezone_New_York",
            "122_us_timezone_Los_Angeles",
            "123_world_country_United_Kingdom"
          ],
          "dataset_names_inferred_from_cache": false,
          "dataset_count": 16,
          "binarize": false,
          "device": "cuda",
          "dtype": "float32",
          "results_path": "/tmp/husai_saebench_probe_results_cycle8_assignment",
          "model_cache_path": "/tmp/sae_bench_model_cache",
          "force_rerun": true
        },
        "config_hash": "c690dface618319f2e5550c5ea683feb28167c6dcc1b4fd7c4d825a9fd96a257",
        "sae_meta": {
          "architecture": "topk",
          "eval_architecture": "topk",
          "d_model": 512,
          "d_sae": 3072,
          "k": 48,
          "dead_features_repaired": 0,
          "decoder_norm_max_deviation": 1.1920928955078125e-07
        },
        "summary": {
          "result_key": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011_custom_sae",
          "llm_metrics": {
            "llm_test_accuracy": 0.6605360072070458,
            "llm_test_auc": 0.6928164663947145,
            "llm_test_f1": 0.6491238078533221
          },
          "sae_metrics_by_k": [
            {
              "k": 1,
              "test_accuracy": 0.6005670166803218,
              "test_auc": 0.610328512906832,
              "test_f1": 0.560869596403959
            },
            {
              "k": 2,
              "test_accuracy": 0.5994583508065682,
              "test_auc": 0.6212511983198329,
              "test_f1": 0.5613903360397708
            },
            {
              "k": 5,
              "test_accuracy": 0.6167744931570085,
              "test_auc": 0.6453791395072228,
              "test_f1": 0.5994146554784834
            }
          ],
          "best_by_auc": {
            "k": 5,
            "test_accuracy": 0.6167744931570085,
            "test_auc": 0.6453791395072228,
            "test_f1": 0.5994146554784834
          },
          "best_minus_llm_auc": -0.04743732688749169
        }
      },
      "cebench": {
        "timestamp_utc": "2026-02-17T14:47:18+00:00",
        "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle8_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
        "config_hash": "3d52b0da409f2cf568e21830ca41dc989c118af2ac9f16d3da4e976d724f6bb5",
        "config": {
          "cebench_repo": "/workspace/CE-Bench",
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
          "architecture_override": "topk",
          "checkpoint_sha256": "67f87d4a084ff529329bec9a03f006a2840bc5d158a1ca9f4c728e00cc1f1c54",
          "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "device": "cuda",
          "sae_dtype": "float32",
          "llm_batch_size": 512,
          "llm_dtype": "float32",
          "random_seed": 42,
          "dataset_name": "GulkoA/contrastive-stories-v4",
          "dataset_rows_total": 5000,
          "dataset_rows_used": 200,
          "max_rows": 200,
          "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench",
          "artifacts_path": "/tmp/ce_bench_artifacts_cycle8_assignment",
          "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
        },
        "sae_meta": {
          "architecture": "topk",
          "eval_architecture": "topk",
          "d_model": 512,
          "d_sae": 3072,
          "k": 48,
          "dead_features_repaired": 0,
          "decoder_norm_max_deviation": 1.1920928955078125e-07
        },
        "cebench_summary": {
          "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench",
          "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011/custom_sae/results.json",
          "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/scores_dump.txt",
          "total_rows": 200,
          "contrastive_score_mean_max": 14.53305012702942,
          "independent_score_mean_max": 15.707403116226196,
          "interpretability_score_mean_max": 14.274428329467774,
          "sae_release": "husai_assignv3_run_20260217T111709Z_lambda0.1_seed1011",
          "sae_id": "custom_sae",
          "date": "2026-02-17 14:47:18",
          "scores_dump_line_count": 200
        },
        "custom_metrics": {
          "contrastive_score_mean_max": 14.53305012702942,
          "independent_score_mean_max": 15.707403116226196,
          "interpretability_score_mean_max": 14.274428329467774
        },
        "matched_baseline_metrics": {
          "contrastive_score_mean_max": 50.51130743026734,
          "independent_score_mean_max": 50.99926634788513,
          "interpretability_score_mean_max": 47.951611585617066
        },
        "delta_vs_matched_baseline": {
          "contrastive_score_mean_max": -35.97825730323792,
          "independent_score_mean_max": -35.29186323165894,
          "interpretability_score_mean_max": -33.67718325614929
        },
        "matched_baseline_payload": {
          "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
          "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
          "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
          "total_rows": 200,
          "contrastive_score_mean_max": 50.51130743026734,
          "independent_score_mean_max": 50.99926634788513,
          "interpretability_score_mean_max": 47.951611585617066,
          "sae_release": "pythia-70m-deduped-res-sm",
          "sae_id": "blocks.0.hook_resid_pre",
          "date": "2026-02-13 18:59:31",
          "scores_dump_line_count": 200
        },
        "artifacts": {
          "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.json",
          "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.md"
        }
      },
      "saebench_returncode": 0,
      "cebench_returncode": 0,
      "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/saebench/husai_custom_sae_summary.json",
      "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/external_eval/0.1/seed1011/cebench/husai_custom_cebench_summary.json",
      "external_skip_reason": null
    },
    "selection_metrics": {
      "internal_lcb": 0.8349106998182834,
      "ev_drop": 0.2736066937446594,
      "ev_neg_drop": -0.2736066937446594,
      "saebench_delta": -0.04743732688749169,
      "cebench_delta": -33.67718325614929,
      "cebench_interpretability_max": 14.274428329467774
    },
    "selection": {
      "joint_score": 0.884928575903846,
      "is_pareto": true,
      "weights": {
        "internal_lcb": 0.2,
        "ev_neg_drop": 0.05,
        "saebench_delta": 0.55,
        "cebench_delta": 0.2
      }
    }
  },
  "acceptance": {
    "best_lambda": 0.1,
    "best_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle8_robust/run_20260217T111709Z/checkpoints/lambda_0.1/sae_seed1011.pt",
    "gate_internal_lcb": true,
    "gate_ev_drop": false,
    "gate_saebench": false,
    "gate_cebench": true,
    "min_internal_lcb": 0.0,
    "max_ev_drop": 0.05,
    "min_saebench_delta": -0.02,
    "min_cebench_delta": -35.5,
    "require_external": true,
    "pass_all": false
  }
}
