{
  "run_metadata": {
    "timestamp_utc": "2026-02-18T02:42:16+00:00",
    "git_commit": "4531c8fee2e59dbd66bb00001713e3b9582a22ce",
    "command": "python scripts/experiments/run_assignment_consistency_v3.py --activation-cache-dir /tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped --activation-glob *_blocks.0.hook_resid_pre.pt --max-files 80 --max-rows-per-file 2048 --max-total-rows 150000 --d-sae 2048 --k 48 --device cuda --epochs 24 --batch-size 4096 --learning-rate 0.0005 --assignment-update-interval 4 --supervised-proxy-mode file_id --supervised-proxy-weight 0.05 --supervised-proxy-num-classes 0 --train-seeds 123,456,789,1011 --lambdas 0.0,0.02,0.04,0.06,0.08,0.1,0.15 --run-saebench --run-cebench --cebench-repo /workspace/CE-Bench --cebench-max-rows 200 --cebench-matched-baseline-summary docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json --saebench-datasets 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --saebench-results-path /tmp/husai_saebench_probe_results_cycle10_assignment --saebench-model-cache-path /tmp/sae_bench_model_cache --cebench-artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --external-checkpoint-policy external_score --external-checkpoint-candidates-per-lambda 4 --external-candidate-require-both --external-candidate-min-saebench-delta -0.03 --external-candidate-min-cebench-delta -35.5 --external-candidate-weight-saebench 0.82 --external-candidate-weight-cebench 0.10 --external-candidate-weight-alignment 0.04 --external-candidate-weight-ev 0.04 --weight-internal-lcb 0.20 --weight-ev 0.05 --weight-saebench 0.60 --weight-cebench 0.15 --force-rerun-external --require-external --min-saebench-delta -0.005 --min-cebench-delta -35.0 --output-dir results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery",
    "config_hash": "c0de1fb21888432d6b27e689ea63c02b8d7643bd39eddc5f6c3cebbd79cafb3e",
    "run_id": "run_20260218T004251Z"
  },
  "config": {
    "transformer_checkpoint": "/workspace/HUSAI/results/transformer_5000ep/transformer_best.pt",
    "activation_cache": "/workspace/HUSAI/results/cache/assignment_consistency_v3/layer1_answer_acts.pt",
    "activation_source": {
      "source": "external_cache",
      "activation_cache_dir": "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped",
      "activation_glob": "*_blocks.0.hook_resid_pre.pt",
      "max_files": 80,
      "max_rows_per_file": 2048,
      "max_total_rows": 150000,
      "source_cache_seed": 42,
      "data_meta": {
        "num_files_discovered": 113,
        "num_files_used": 80,
        "total_rows": 144042,
        "d_model": 512
      },
      "source_files": [
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/100_news_fake_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/105_click_bait_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/106_hate_hate_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/107_hate_offensive_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/110_aimade_humangpt3_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/113_movie_sent_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/114_nyc_borough_Manhattan_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/115_nyc_borough_Brooklyn_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/116_nyc_borough_Bronx_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/117_us_state_FL_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/118_us_state_CA_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/119_us_state_TX_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/120_us_timezone_Chicago_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/121_us_timezone_New_York_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/122_us_timezone_Los_Angeles_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/123_world_country_United_Kingdom_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/124_world_country_United_States_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/125_world_country_Italy_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/126_art_type_book_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/127_art_type_song_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/128_art_type_movie_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/129_arith_mc_A_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/130_temp_cat_Frequency_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/131_temp_cat_Typical Time_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/132_temp_cat_Event Ordering_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/133_context_type_Causality_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/134_context_type_Belief_states_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/135_context_type_Event_duration_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/136_glue_mnli_entailment_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/137_glue_mnli_neutral_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/138_glue_mnli_contradiction_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/139_news_class_Politics_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/140_news_class_Technology_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/141_news_class_Entertainment_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/142_cancer_cat_Thyroid_Cancer_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/143_cancer_cat_Lung_Cancer_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/144_cancer_cat_Colon_Cancer_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/145_disease_class_digestive system diseases_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/146_disease_class_cardiovascular diseases_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/147_disease_class_nervous system diseases_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/148_twt_emotion_worry_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/149_twt_emotion_happiness_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/150_twt_emotion_sadness_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/151_it_tick_HR Support_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/152_it_tick_Hardware_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/153_it_tick_Administrative rights_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/154_athlete_sport_football_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/155_athlete_sport_basketball_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/156_athlete_sport_baseball_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/157_amazon_5star_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/158_code_C_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/159_code_Python_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/160_code_HTML_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/161_agnews_0_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/162_agnews_1_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/163_agnews_2_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/21_headline_istrump_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/22_headline_isobama_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/23_headline_ischina_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/24_headline_isiran_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/26_headline_isfrontpage_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/36_sciq_tf_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/41_truthqa_tf_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/42_temp_sense_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/44_phys_tf_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/47_reasoning_tf_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/48_cm_correct_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/49_cm_isshort_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/50_deon_isvalid_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/51_just_is_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/52_virtue_is_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/54_cs_tf_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/56_wikidatasex_or_gender_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/57_wikidatais_alive_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/58_wikidatapolitical_party_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/59_wikidata_occupation_isjournalist_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/5_hist_fig_ismale_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/60_wikidata_occupation_isathlete_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/61_wikidata_occupation_isactor_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/62_wikidata_occupation_ispolitician_blocks.0.hook_resid_pre.pt"
      ]
    },
    "layer": 1,
    "modulus": 113,
    "seed_ref": 42,
    "train_seeds": [
      123,
      456,
      789,
      1011
    ],
    "lambdas": [
      0.0,
      0.02,
      0.04,
      0.06,
      0.08,
      0.1,
      0.15
    ],
    "d_sae": 2048,
    "k": 48,
    "epochs": 24,
    "batch_size": 4096,
    "learning_rate": 0.0005,
    "assignment_update_interval": 4,
    "supervised_proxy_mode": "file_id",
    "supervised_proxy_weight": 0.05,
    "supervised_proxy_num_classes": 0,
    "supervised_proxy_meta": {
      "mode": "file_id",
      "num_classes": 80,
      "class_files": [
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/100_news_fake_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/105_click_bait_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/106_hate_hate_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/107_hate_offensive_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/110_aimade_humangpt3_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/113_movie_sent_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/114_nyc_borough_Manhattan_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/115_nyc_borough_Brooklyn_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/116_nyc_borough_Bronx_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/117_us_state_FL_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/118_us_state_CA_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/119_us_state_TX_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/120_us_timezone_Chicago_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/121_us_timezone_New_York_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/122_us_timezone_Los_Angeles_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/123_world_country_United_Kingdom_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/124_world_country_United_States_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/125_world_country_Italy_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/126_art_type_book_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/127_art_type_song_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/128_art_type_movie_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/129_arith_mc_A_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/130_temp_cat_Frequency_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/131_temp_cat_Typical Time_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/132_temp_cat_Event Ordering_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/133_context_type_Causality_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/134_context_type_Belief_states_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/135_context_type_Event_duration_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/136_glue_mnli_entailment_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/137_glue_mnli_neutral_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/138_glue_mnli_contradiction_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/139_news_class_Politics_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/140_news_class_Technology_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/141_news_class_Entertainment_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/142_cancer_cat_Thyroid_Cancer_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/143_cancer_cat_Lung_Cancer_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/144_cancer_cat_Colon_Cancer_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/145_disease_class_digestive system diseases_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/146_disease_class_cardiovascular diseases_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/147_disease_class_nervous system diseases_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/148_twt_emotion_worry_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/149_twt_emotion_happiness_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/150_twt_emotion_sadness_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/151_it_tick_HR Support_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/152_it_tick_Hardware_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/153_it_tick_Administrative rights_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/154_athlete_sport_football_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/155_athlete_sport_basketball_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/156_athlete_sport_baseball_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/157_amazon_5star_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/158_code_C_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/159_code_Python_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/160_code_HTML_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/161_agnews_0_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/162_agnews_1_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/163_agnews_2_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/21_headline_istrump_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/22_headline_isobama_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/23_headline_ischina_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/24_headline_isiran_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/26_headline_isfrontpage_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/36_sciq_tf_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/41_truthqa_tf_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/42_temp_sense_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/44_phys_tf_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/47_reasoning_tf_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/48_cm_correct_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/49_cm_isshort_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/50_deon_isvalid_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/51_just_is_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/52_virtue_is_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/54_cs_tf_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/56_wikidatasex_or_gender_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/57_wikidatais_alive_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/58_wikidatapolitical_party_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/59_wikidata_occupation_isjournalist_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/5_hist_fig_ismale_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/60_wikidata_occupation_isathlete_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/61_wikidata_occupation_isactor_blocks.0.hook_resid_pre.pt",
        "/tmp/sae_bench_model_cache/model_activations_pythia-70m-deduped/62_wikidata_occupation_ispolitician_blocks.0.hook_resid_pre.pt"
      ]
    },
    "device": "cuda",
    "bootstrap_samples": 10000,
    "run_saebench": true,
    "run_cebench": true,
    "cebench_repo": "/workspace/CE-Bench",
    "cebench_max_rows": 200,
    "cebench_matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
    "saebench_datasets": [
      "100_news_fake",
      "105_click_bait",
      "106_hate_hate",
      "107_hate_offensive",
      "110_aimade_humangpt3",
      "113_movie_sent",
      "114_nyc_borough_Manhattan",
      "115_nyc_borough_Brooklyn",
      "116_nyc_borough_Bronx",
      "117_us_state_FL",
      "118_us_state_CA",
      "119_us_state_TX",
      "120_us_timezone_Chicago",
      "121_us_timezone_New_York",
      "122_us_timezone_Los_Angeles",
      "123_world_country_United_Kingdom"
    ],
    "model_name": "pythia-70m-deduped",
    "hook_layer": 0,
    "hook_name": "blocks.0.hook_resid_pre",
    "dtype": "float32",
    "external_checkpoint_policy": "external_score",
    "external_checkpoint_candidates_per_lambda": 4,
    "external_checkpoint_include_ref": false,
    "external_candidate_require_both": true,
    "external_candidate_thresholds": {
      "min_saebench_delta": -0.03,
      "min_cebench_delta": -35.5
    },
    "weights": {
      "internal_lcb": 0.2,
      "ev_neg_drop": 0.05,
      "saebench_delta": 0.6,
      "cebench_delta": 0.15
    },
    "external_checkpoint_weights": {
      "saebench": 0.82,
      "cebench": 0.1,
      "alignment": 0.04,
      "explained_variance": 0.04
    }
  },
  "records": [
    {
      "lambda_consistency": 0.0,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.1639976441860199,
        "std": 0.00031743714213769815,
        "min": 0.1636180281639099,
        "max": 0.16453917324543,
        "median": 0.16395213454961777,
        "ci95_low": 0.1638154529593885,
        "ci95_high": 0.1641866184026003,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.004615412652492518,
      "delta_pwmcc_ci_low_conservative": 0.004315220117568991,
      "ratio_pwmcc": 1.0289581379811565,
      "explained_variance": {
        "mean": -1.5690999984741212,
        "std": 0.01972055792502961,
        "min": -1.5908684730529785,
        "max": -1.5404713153839111,
        "median": -1.574693202972412,
        "ci95_low": -1.5834693908691406,
        "ci95_high": -1.5521761894226074,
        "n": 5
      },
      "mse": {
        "mean": 0.0021312625613063574,
        "std": 1.6371495174561724e-05,
        "min": 0.002107499400153756,
        "max": 0.0021493355743587017,
        "median": 0.002135912189260125,
        "ci95_low": 0.0021172127686440944,
        "ci95_high": 0.002143192058429122,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.15734173730015755,
        "std": 0.0002745345560657119,
        "min": 0.1571110486984253,
        "max": 0.15770940482616425,
        "median": 0.15727324783802032,
        "ci95_low": 0.15713264048099518,
        "ci95_high": 0.15757061168551445,
        "n": 4
      },
      "runtime_sec": 187.082337141037,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.15739226341247559,
          "mse": 0.0021228771656751633,
          "explained_variance": -1.5590085983276367,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.791447404358122,
          "supervised_proxy_accuracy_eval": 0.24927452206611633,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.1571110486984253,
          "mse": 0.002107499400153756,
          "explained_variance": -1.5404713153839111,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.7927430832275637,
          "supervised_proxy_accuracy_eval": 0.24942030012607574,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.15770940482616425,
          "mse": 0.002135912189260125,
          "explained_variance": -1.574693202972412,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.791701413139149,
          "supervised_proxy_accuracy_eval": 0.24978825449943542,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.15715423226356506,
          "mse": 0.0021493355743587017,
          "explained_variance": -1.5908684730529785,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.791906225460547,
          "supervised_proxy_accuracy_eval": 0.2493925392627716,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.1638329178094864,
        0.1636180281639099,
        0.16430993378162384,
        0.16385231167078018,
        0.16425057500600815,
        0.16453917324543,
        0.16370029747486115,
        0.16405195742845535,
        0.164187453687191,
        0.163633793592453
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
      "selected_checkpoint_seed": 123,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
          "alignment_to_ref": 0.15739226341247559,
          "explained_variance": -1.5590085983276367,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:23:57+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "9257b944016719b7d6711961097ba7d5e0a826f11868c62ee621767907b0b93e",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6095639466639499,
                    "test_auc": 0.613725945597959,
                    "test_f1": 0.5715989710586425
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6191709406629907,
                    "test_auc": 0.637182756585181,
                    "test_f1": 0.5903520686254913
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6326485670979377,
                    "test_auc": 0.6503870215344647,
                    "test_f1": 0.6081474084577569
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6326485670979377,
                  "test_auc": 0.6503870215344647,
                  "test_f1": 0.6081474084577569
                },
                "best_minus_llm_auc": -0.0424294448602498
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:26:24+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "0291c26bd4a586a301f79711d9275ad7fae3be2bc574e0944e1584a5b1086234",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "0e5e0c58629761ae3d6d84d3af9509cb03ad019760c360741f8d698f082e2c10",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.0_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.021288571357728,
                "independent_score_mean_max": 9.214037716388702,
                "interpretability_score_mean_max": 8.566019394397735,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:26:24",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.021288571357728,
                "independent_score_mean_max": 9.214037716388702,
                "interpretability_score_mean_max": 8.566019394397735
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.49001885890961,
                "independent_score_mean_max": -41.78522863149643,
                "interpretability_score_mean_max": -39.38559219121933
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.0424294448602498,
          "cebench_delta": -39.38559219121933,
          "cebench_interpretability_max": 8.566019394397735,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9382642792095021,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.7417808499290421,
              "alignment": 0.46997883202589963,
              "explained_variance": 0.6321760233890463
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt",
          "alignment_to_ref": 0.15770940482616425,
          "explained_variance": -1.574693202972412,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:19:44+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "38f8b1b9ee01b955240e5e010b05a34af09a2dd994ced6403f467785b41e36a1",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6158911174233761,
                    "test_auc": 0.6239583527794297,
                    "test_f1": 0.5888470688358332
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6184968313845628,
                    "test_auc": 0.6329032346480699,
                    "test_f1": 0.593792981172296
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6336536681132151,
                    "test_auc": 0.6474125626919695,
                    "test_f1": 0.6164575437282069
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6336536681132151,
                  "test_auc": 0.6474125626919695,
                  "test_f1": 0.6164575437282069
                },
                "best_minus_llm_auc": -0.04540390370274505
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:23:22+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "7b04d5f47dc2f1a39ab939ec5e646cf732df2f2e1f6ff3b4a942a9d44893df3d",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "ffae5c067f32a391900a401f3bf6b3832fba3a1dcc75b27059c4294160a94423",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.0_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.480449571609498,
                "independent_score_mean_max": 9.384900243282319,
                "interpretability_score_mean_max": 8.152732031345368,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:23:21",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.480449571609498,
                "independent_score_mean_max": 9.384900243282319,
                "interpretability_score_mean_max": 8.152732031345368
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -42.03085785865784,
                "independent_score_mean_max": -41.614366104602816,
                "interpretability_score_mean_max": -39.7988795542717
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04540390370274505,
          "cebench_delta": -39.7988795542717,
          "cebench_interpretability_max": 8.152732031345368,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6726408245731844,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.7558568105095648,
              "cebench": 0.0,
              "alignment": 1.0,
              "explained_variance": 0.3209559988835326
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt",
          "alignment_to_ref": 0.15715423226356506,
          "explained_variance": -1.5908684730529785,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:26:59+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "39dee9b69d498b157e1431a1d65759e909de242aeed688060c7c9f6dc7b173c7",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6080592329131207,
                    "test_auc": 0.6107044843836973,
                    "test_f1": 0.5703834278935486
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6187726119813808,
                    "test_auc": 0.6283164334467757,
                    "test_f1": 0.594458324057106
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6240938620263734,
                    "test_auc": 0.6466313721281483,
                    "test_f1": 0.5918920671930044
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6240938620263734,
                  "test_auc": 0.6466313721281483,
                  "test_f1": 0.5918920671930044
                },
                "best_minus_llm_auc": -0.04618509426656625
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:29:30+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "1adebf7cbfefd34764bc9a3ae1fcc661c25ad3352b97d3b83ca4471fc80b2355",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "5b8bfcd586d6855945fd277b09d690907924cd724898905764e8b3bfb6c8da1b",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.043372192382812,
                "independent_score_mean_max": 9.96780168056488,
                "interpretability_score_mean_max": 8.709887642860412,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:29:30",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.043372192382812,
                "independent_score_mean_max": 9.96780168056488,
                "interpretability_score_mean_max": 8.709887642860412
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.467935237884525,
                "independent_score_mean_max": -41.03146466732025,
                "interpretability_score_mean_max": -39.24172394275665
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04618509426656625,
          "cebench_delta": -39.24172394275665,
          "cebench_interpretability_max": 8.709887642860412,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6701109830884754,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.6917367920623964,
              "cebench": 1.0,
              "alignment": 0.07217033993276055,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt",
          "alignment_to_ref": 0.1571110486984253,
          "explained_variance": -1.5404713153839111,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:30:08+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "51ff97700d0a63663e3fe8abe3750a72df1bdba04e7d305403fde524389db1d4",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6134250718608376,
                    "test_auc": 0.6185233752075329,
                    "test_f1": 0.5881539110179038
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6130454144004632,
                    "test_auc": 0.6286125726786732,
                    "test_f1": 0.5788946870308778
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6194074983307263,
                    "test_auc": 0.6382037660903812,
                    "test_f1": 0.5873725860211302
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6194074983307263,
                  "test_auc": 0.6382037660903812,
                  "test_f1": 0.5873725860211302
                },
                "best_minus_llm_auc": -0.054612700304333295
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:32:34+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "83efb68178352d726429b1e0d3111910710ffc1e29ed6b2689d18d27280cfaa1",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "eab7ecb162bd0287c3971faf1bb062870edeea512789601307fe004374056347",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.0_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.945289239883422,
                "independent_score_mean_max": 9.859105889797211,
                "interpretability_score_mean_max": 8.491308145523071,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:32:34",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.945289239883422,
                "independent_score_mean_max": 9.859105889797211,
                "interpretability_score_mean_max": 8.491308145523071
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.566018190383915,
                "independent_score_mean_max": -41.14016045808792,
                "interpretability_score_mean_max": -39.460303440093995
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.054612700304333295,
          "cebench_delta": -39.460303440093995,
          "cebench_interpretability_max": 8.491308145523071,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.10076868063071812,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.6076868063071812,
              "alignment": 0.0,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
        "candidate_tag": "seed123",
        "saebench": {
          "timestamp_utc": "2026-02-18T01:23:57+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "9257b944016719b7d6711961097ba7d5e0a826f11868c62ee621767907b0b93e",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6095639466639499,
                "test_auc": 0.613725945597959,
                "test_f1": 0.5715989710586425
              },
              {
                "k": 2,
                "test_accuracy": 0.6191709406629907,
                "test_auc": 0.637182756585181,
                "test_f1": 0.5903520686254913
              },
              {
                "k": 5,
                "test_accuracy": 0.6326485670979377,
                "test_auc": 0.6503870215344647,
                "test_f1": 0.6081474084577569
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6326485670979377,
              "test_auc": 0.6503870215344647,
              "test_f1": 0.6081474084577569
            },
            "best_minus_llm_auc": -0.0424294448602498
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T01:26:24+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "0291c26bd4a586a301f79711d9275ad7fae3be2bc574e0944e1584a5b1086234",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "0e5e0c58629761ae3d6d84d3af9509cb03ad019760c360741f8d698f082e2c10",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.0_seed123/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 9.021288571357728,
            "independent_score_mean_max": 9.214037716388702,
            "interpretability_score_mean_max": 8.566019394397735,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123",
            "sae_id": "custom_sae",
            "date": "2026-02-18 01:26:24",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 9.021288571357728,
            "independent_score_mean_max": 9.214037716388702,
            "interpretability_score_mean_max": 8.566019394397735
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.49001885890961,
            "independent_score_mean_max": -41.78522863149643,
            "interpretability_score_mean_max": -39.38559219121933
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.004315220117568991,
        "ev_drop": 0.0,
        "ev_neg_drop": -0.0,
        "saebench_delta": -0.0424294448602498,
        "cebench_delta": -39.38559219121933,
        "cebench_interpretability_max": 8.566019394397735
      },
      "selection": {
        "joint_score": 0.3830015368682677,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    },
    {
      "lambda_consistency": 0.02,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9154020756483078,
        "std": 0.025309991871390825,
        "min": 0.8939613997936249,
        "max": 0.9465415179729462,
        "median": 0.8970813900232315,
        "ci95_low": 0.9006726033240557,
        "ci95_high": 0.9302934140712023,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.7560198441147804,
      "delta_pwmcc_ci_low_conservative": 0.7411723704822362,
      "ratio_pwmcc": 5.743438693514247,
      "explained_variance": {
        "mean": -2.0178246974945067,
        "std": 0.24481421368811002,
        "min": -2.1441211700439453,
        "max": -1.580458402633667,
        "median": -2.1178841590881348,
        "ci95_low": -2.1358046531677246,
        "ci95_high": -1.7986218452453613,
        "n": 5
      },
      "mse": {
        "mean": 0.0025035038124769926,
        "std": 0.00020308462193059258,
        "min": 0.0021406884770840406,
        "max": 0.0026082710828632116,
        "median": 0.0025865095667541027,
        "ci95_low": 0.002320823073387146,
        "ci95_high": 0.0026013726368546487,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9447744190692902,
        "std": 0.0013084077911017149,
        "min": 0.9435033798217773,
        "max": 0.9465415477752686,
        "median": 0.9445263743400574,
        "ci95_low": 0.9438296556472778,
        "ci95_high": 0.945945143699646,
        "n": 4
      },
      "runtime_sec": 268.68646478652954,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt",
          "lambda_consistency": 0.02,
          "alignment_to_ref": 0.9465415477752686,
          "mse": 0.0026082710828632116,
          "explained_variance": -2.1441211700439453,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.8829708685236121,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.806984913018015,
          "supervised_proxy_accuracy_eval": 0.24428291618824005,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt",
          "lambda_consistency": 0.02,
          "alignment_to_ref": 0.9448968172073364,
          "mse": 0.0025865095667541027,
          "explained_variance": -2.1178841590881348,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.8808948058048608,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.808379919440658,
          "supervised_proxy_accuracy_eval": 0.2445606142282486,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt",
          "lambda_consistency": 0.02,
          "alignment_to_ref": 0.9441559314727783,
          "mse": 0.002582294400781393,
          "explained_variance": -2.112809896469116,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.8815496075829422,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.808260926493892,
          "supervised_proxy_accuracy_eval": 0.2445397824048996,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
          "lambda_consistency": 0.02,
          "alignment_to_ref": 0.9435033798217773,
          "mse": 0.002599755534902215,
          "explained_variance": -2.133849859237671,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.8799779883723844,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.806140339208974,
          "supervised_proxy_accuracy_eval": 0.24425514042377472,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9465415179729462,
        0.9448967576026917,
        0.9441559910774231,
        0.943503350019455,
        0.8977592885494232,
        0.8964034914970398,
        0.8961204886436462,
        0.8958680927753448,
        0.8948103785514832,
        0.8939613997936249
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
      "selected_checkpoint_seed": 1011,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
          "alignment_to_ref": 0.9435033798217773,
          "explained_variance": -2.133849859237671,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:41:51+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "89c226380f3511f3ceb020051f106393eaa3819be62cbb679b6715cdbdbab1ee",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6066127580020733,
                    "test_auc": 0.6107881724887381,
                    "test_f1": 0.5726167192791645
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6139508276333686,
                    "test_auc": 0.6213140735358289,
                    "test_f1": 0.5897523618627115
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6292440448068571,
                    "test_auc": 0.6438836519134908,
                    "test_f1": 0.6100145438585959
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6292440448068571,
                  "test_auc": 0.6438836519134908,
                  "test_f1": 0.6100145438585959
                },
                "best_minus_llm_auc": -0.04893281448122366
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:44:10+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "a6e8948d969ac588ef09602b2067c0e13d8a99bdc75e0018b171c9fa682e51e3",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "8e2b1c288a298f73fcc5e0e4b8590b414c9734406ec74bcc014c88587d21a9d4",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.041743602752685,
                "independent_score_mean_max": 9.729872329235077,
                "interpretability_score_mean_max": 8.498405346870422,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:44:10",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.041743602752685,
                "independent_score_mean_max": 9.729872329235077,
                "interpretability_score_mean_max": 8.498405346870422
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.46956382751465,
                "independent_score_mean_max": -41.269394018650054,
                "interpretability_score_mean_max": -39.453206238746645
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04893281448122366,
          "cebench_delta": -39.453206238746645,
          "cebench_interpretability_max": 8.498405346870422,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8782350812219107,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.9858915633402866,
              "cebench": 0.5668244958707356,
              "alignment": 0.0,
              "explained_variance": 0.32803874239505365
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt",
          "alignment_to_ref": 0.9441559314727783,
          "explained_variance": -2.112809896469116,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:38:59+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "4f61c2372b23c6819397f3324308921abc9394cf187f2c6956397884d2934f3e",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6164301740472958,
                    "test_auc": 0.6189447531222287,
                    "test_f1": 0.5802173923720336
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6211374955051561,
                    "test_auc": 0.6323487941504077,
                    "test_f1": 0.5905349037939289
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6208000524578717,
                    "test_auc": 0.644044479372317,
                    "test_f1": 0.5990724600859644
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6208000524578717,
                  "test_auc": 0.644044479372317,
                  "test_f1": 0.5990724600859644
                },
                "best_minus_llm_auc": -0.04877198702239749
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:41:19+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "a66b108aa44da4672be79b796974583a1d71831db97a807ad6e1a92cbbd81fd9",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "c518d144bc604c5f6b5f65a634994d0faf3d02d6840f437dd36d733798e123d1",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.02_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.74711392879486,
                "independent_score_mean_max": 9.405555453300476,
                "interpretability_score_mean_max": 8.29776478767395,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:41:19",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.74711392879486,
                "independent_score_mean_max": 9.405555453300476,
                "interpretability_score_mean_max": 8.29776478767395
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.76419350147248,
                "independent_score_mean_max": -41.59371089458466,
                "interpretability_score_mean_max": -39.65384679794312
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04877198702239749,
          "cebench_delta": -39.65384679794312,
          "cebench_interpretability_max": 8.29776478767395,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8685913835046692,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.0,
              "alignment": 0.21478458761673075,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt",
          "alignment_to_ref": 0.9465415477752686,
          "explained_variance": -2.1441211700439453,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:33:08+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "cc426ab7f12a9217f7db4ee601cbd6fbe19abd983ef9fa7fffddc1abc5a809d2",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6162019935830344,
                    "test_auc": 0.6199432689373412,
                    "test_f1": 0.5842961532193424
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6211300733157904,
                    "test_auc": 0.6380554320253848,
                    "test_f1": 0.5987463558363155
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6260852202172976,
                    "test_auc": 0.6422096255561176,
                    "test_f1": 0.6029368366203476
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6260852202172976,
                  "test_auc": 0.6422096255561176,
                  "test_f1": 0.6029368366203476
                },
                "best_minus_llm_auc": -0.0506068408385969
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:35:33+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "1a51837259096a4acdfb07df48563f5c68fa0ef5811c8ffed5e44324d2848d8b",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "1a750497966c2261094fcbbc1b0eecc7fd2d24e1e4e92e6654cc191007356735",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.02_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.296842222213746,
                "independent_score_mean_max": 9.369706768989563,
                "interpretability_score_mean_max": 8.651737773418427,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:35:33",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.296842222213746,
                "independent_score_mean_max": 9.369706768989563,
                "interpretability_score_mean_max": 8.651737773418427
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.21446520805359,
                "independent_score_mean_max": -41.62955957889557,
                "interpretability_score_mean_max": -39.29987381219864
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.0506068408385969,
          "cebench_delta": -39.29987381219864,
          "cebench_interpretability_max": 8.651737773418427,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8280121317069195,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.8390391850084384,
              "cebench": 1.0,
              "alignment": 1.0,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt",
          "alignment_to_ref": 0.9448968172073364,
          "explained_variance": -2.1178841590881348,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:36:07+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "bae70fede0570963a2bc7f84feeef726d5521a3541c2acf1e997d9ef2ed4e618",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6109195613778943,
                    "test_auc": 0.614928433559824,
                    "test_f1": 0.5865321377766118
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6130554611053121,
                    "test_auc": 0.6221364904622736,
                    "test_f1": 0.5890425077562615
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6192134282367925,
                    "test_auc": 0.6326450973780372,
                    "test_f1": 0.5965036409238097
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6192134282367925,
                  "test_auc": 0.6326450973780372,
                  "test_f1": 0.5965036409238097
                },
                "best_minus_llm_auc": -0.0601713690166773
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:38:26+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "a1a1e35bec70a1c5905372dffdfd445a3b5b4f287827ffda99e784f135b06f85",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "ec8ea5eec33de59a953cf48bf6f0233b8b7488bdf1d030c355ec5be9a5db8bc1",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.02_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.747363641262055,
                "independent_score_mean_max": 9.70739779472351,
                "interpretability_score_mean_max": 8.51431446313858,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:38:25",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.747363641262055,
                "independent_score_mean_max": 9.70739779472351,
                "interpretability_score_mean_max": 8.51431446313858
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.76394378900528,
                "independent_score_mean_max": -41.29186855316162,
                "interpretability_score_mean_max": -39.43729712247848
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.0601713690166773,
          "cebench_delta": -39.43729712247848,
          "cebench_interpretability_max": 8.51431446313858,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.113040305796754,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.6117689320533495,
              "alignment": 0.45864396139056735,
              "explained_variance": 0.8379413533949089
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
        "candidate_tag": "seed1011",
        "saebench": {
          "timestamp_utc": "2026-02-18T01:41:51+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "89c226380f3511f3ceb020051f106393eaa3819be62cbb679b6715cdbdbab1ee",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6066127580020733,
                "test_auc": 0.6107881724887381,
                "test_f1": 0.5726167192791645
              },
              {
                "k": 2,
                "test_accuracy": 0.6139508276333686,
                "test_auc": 0.6213140735358289,
                "test_f1": 0.5897523618627115
              },
              {
                "k": 5,
                "test_accuracy": 0.6292440448068571,
                "test_auc": 0.6438836519134908,
                "test_f1": 0.6100145438585959
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6292440448068571,
              "test_auc": 0.6438836519134908,
              "test_f1": 0.6100145438585959
            },
            "best_minus_llm_auc": -0.04893281448122366
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T01:44:10+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "a6e8948d969ac588ef09602b2067c0e13d8a99bdc75e0018b171c9fa682e51e3",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "8e2b1c288a298f73fcc5e0e4b8590b414c9734406ec74bcc014c88587d21a9d4",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 9.041743602752685,
            "independent_score_mean_max": 9.729872329235077,
            "interpretability_score_mean_max": 8.498405346870422,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011",
            "sae_id": "custom_sae",
            "date": "2026-02-18 01:44:10",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 9.041743602752685,
            "independent_score_mean_max": 9.729872329235077,
            "interpretability_score_mean_max": 8.498405346870422
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.46956382751465,
            "independent_score_mean_max": -41.269394018650054,
            "interpretability_score_mean_max": -39.453206238746645
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.7411723704822362,
        "ev_drop": 0.4487246990203855,
        "ev_neg_drop": -0.4487246990203855,
        "saebench_delta": -0.04893281448122366,
        "cebench_delta": -39.453206238746645,
        "cebench_interpretability_max": 8.498405346870422
      },
      "selection": {
        "joint_score": 0.250468152530456,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    },
    {
      "lambda_consistency": 0.04,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9545239537954331,
        "std": 0.013875252132609919,
        "min": 0.9430154263973236,
        "max": 0.9710472226142883,
        "median": 0.9444089233875275,
        "ci95_low": 0.9464572265744209,
        "ci95_high": 0.9626533912122249,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.7951417222619057,
      "delta_pwmcc_ci_low_conservative": 0.7869569937326013,
      "ratio_pwmcc": 5.988898163937685,
      "explained_variance": {
        "mean": -2.2060025691986085,
        "std": 0.3498881411418583,
        "min": -2.382702589035034,
        "max": -1.580458402633667,
        "median": -2.3553390502929688,
        "ci95_low": -2.371536064147949,
        "ci95_high": -1.8907987117767333,
        "n": 5
      },
      "mse": {
        "mean": 0.002659630076959729,
        "std": 0.0002902619370049403,
        "min": 0.0021406884770840406,
        "max": 0.0028062264900654554,
        "median": 0.00278349663130939,
        "ci95_low": 0.0023979608435183764,
        "ci95_high": 0.002796950750052929,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9706359058618546,
        "std": 0.00041085226516615435,
        "min": 0.9702154397964478,
        "max": 0.9710472226142883,
        "median": 0.9706404805183411,
        "ci95_low": 0.9702863693237305,
        "ci95_high": 0.9709854423999786,
        "n": 4
      },
      "runtime_sec": 269.3000237941742,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
          "lambda_consistency": 0.04,
          "alignment_to_ref": 0.970923662185669,
          "mse": 0.0027825776487588882,
          "explained_variance": -2.354233503341675,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9027743291592708,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8109846128909677,
          "supervised_proxy_accuracy_eval": 0.24257507920265198,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt",
          "lambda_consistency": 0.04,
          "alignment_to_ref": 0.9710472226142883,
          "mse": 0.0027851611375808716,
          "explained_variance": -2.3572793006896973,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9024880815262871,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8129605129361153,
          "supervised_proxy_accuracy_eval": 0.24215853214263916,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt",
          "lambda_consistency": 0.04,
          "alignment_to_ref": 0.9703572988510132,
          "mse": 0.0028062264900654554,
          "explained_variance": -2.382702589035034,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9022240903642442,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.812351369195514,
          "supervised_proxy_accuracy_eval": 0.2431790679693222,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt",
          "lambda_consistency": 0.04,
          "alignment_to_ref": 0.9702154397964478,
          "mse": 0.00278349663130939,
          "explained_variance": -2.3553390502929688,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9013843169884274,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.810880299795557,
          "supervised_proxy_accuracy_eval": 0.24277640879154205,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.970923662185669,
        0.9710472226142883,
        0.9703572988510132,
        0.9702154695987701,
        0.9446422457695007,
        0.9436520338058472,
        0.9435916841030121,
        0.9441756010055542,
        0.943618893623352,
        0.9430154263973236
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
      "selected_checkpoint_seed": 123,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
          "alignment_to_ref": 0.970923662185669,
          "explained_variance": -2.354233503341675,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:47:37+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "48f91575a35b364341944e1515d9337cb1dbda85d9047b2fbf372511ae882494",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6146857625588232,
                    "test_auc": 0.6204569909261866,
                    "test_f1": 0.5895111258745126
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6248548346293367,
                    "test_auc": 0.6381960728564616,
                    "test_f1": 0.6040005402332591
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6277629996730051,
                    "test_auc": 0.6474857911964319,
                    "test_f1": 0.6084575154962668
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6277629996730051,
                  "test_auc": 0.6474857911964319,
                  "test_f1": 0.6084575154962668
                },
                "best_minus_llm_auc": -0.0453306751982826
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:49:56+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "20dd2d66de887e01e9abab7a7c66e346c72d8af99f7b0c434d6207ec66e458a4",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "456f8a0340751ae227dd0577967f5adfa34f1e906b4b9ec7fc9e5eebe523be25",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.04_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.344703226089477,
                "independent_score_mean_max": 9.525979993343354,
                "interpretability_score_mean_max": 8.744984805583954,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:49:56",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.344703226089477,
                "independent_score_mean_max": 9.525979993343354,
                "interpretability_score_mean_max": 8.744984805583954
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.16660420417786,
                "independent_score_mean_max": -41.47328635454178,
                "interpretability_score_mean_max": -39.20662678003311
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.0453306751982826,
          "cebench_delta": -39.20662678003311,
          "cebench_interpretability_max": 8.744984805583954,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9940580437119312,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 1.0,
              "alignment": 0.8514510927982802,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt",
          "alignment_to_ref": 0.9702154397964478,
          "explained_variance": -2.3553390502929688,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:53:20+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "a5f14c447f5126bd97d6ed5e862686e2eea4ebf7750f525b1161170d98213cd4",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6083871776451527,
                    "test_auc": 0.6125943116732853,
                    "test_f1": 0.5682157176288499
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6147171759871368,
                    "test_auc": 0.6267843826401306,
                    "test_f1": 0.5850996670594092
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6304372506547544,
                    "test_auc": 0.6452609426235408,
                    "test_f1": 0.611727303826725
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6304372506547544,
                  "test_auc": 0.6452609426235408,
                  "test_f1": 0.611727303826725
                },
                "best_minus_llm_auc": -0.04755552377117367
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:55:39+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "aee5f07065dc17f05f265f16db6f4ab2c4fe95bf8ef03da6f4a128bb7a5f74fb",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "5928420557585e19053e1b8859289128a1ec4034557050921e7503485c5664a5",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.094920408725738,
                "independent_score_mean_max": 9.751197476387023,
                "interpretability_score_mean_max": 8.47542240381241,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:55:39",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.094920408725738,
                "independent_score_mean_max": 9.751197476387023,
                "interpretability_score_mean_max": 8.47542240381241
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.416387021541595,
                "independent_score_mean_max": -41.248068871498106,
                "interpretability_score_mean_max": -39.476189181804656
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04755552377117367,
          "cebench_delta": -39.476189181804656,
          "cebench_interpretability_max": 8.47542240381241,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6451790010366498,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.6961888304841599,
              "cebench": 0.35857489799788705,
              "alignment": 0.0,
              "explained_variance": 0.9611667559962481
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt",
          "alignment_to_ref": 0.9703572988510132,
          "explained_variance": -2.382702589035034,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:50:29+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "47e4788e9babed3f9e1dbbcf33c16e7569d6fd46a299b7affbe8716f20902386",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6111614662553402,
                    "test_auc": 0.6163508920121484,
                    "test_f1": 0.5824876470857958
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6109982958814504,
                    "test_auc": 0.6244914730316864,
                    "test_f1": 0.5836271344307097
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6196722292231289,
                    "test_auc": 0.6435047653693398,
                    "test_f1": 0.5957830570252136
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6196722292231289,
                  "test_auc": 0.6435047653693398,
                  "test_f1": 0.5957830570252136
                },
                "best_minus_llm_auc": -0.04931170102537474
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:52:47+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "61ce832f9fbcde1269a369dbf8f6acbc7dd4f0bf405651b1780daa4caf6142ef",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "8033c23af26918c23da69a8dc767c4a0dba6ce63e89dbafe8237373c1ea17f2f",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.04_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.795378754138946,
                "independent_score_mean_max": 9.445503854751587,
                "interpretability_score_mean_max": 8.324729344844819,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:52:47",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.795378754138946,
                "independent_score_mean_max": 9.445503854751587,
                "interpretability_score_mean_max": 8.324729344844819
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.71592867612839,
                "independent_score_mean_max": -41.55376249313355,
                "interpretability_score_mean_max": -39.62688224077225
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04931170102537474,
          "cebench_delta": -39.62688224077225,
          "cebench_interpretability_max": 8.324729344844819,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.38105060446403716,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.45637643517015836,
              "cebench": 0.0,
              "alignment": 0.17054819061268361,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt",
          "alignment_to_ref": 0.9710472226142883,
          "explained_variance": -2.3572793006896973,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:44:43+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "38813e75ddb69db7062feb49ccf189853eafaf1a085662a346541e03462600ee",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.611097792433858,
                    "test_auc": 0.61463131202268,
                    "test_f1": 0.5903357252599749
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6121689491708484,
                    "test_auc": 0.6198665277563611,
                    "test_f1": 0.5894566907587226
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6255122302929822,
                    "test_auc": 0.6401626615812942,
                    "test_f1": 0.6083836575169431
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6255122302929822,
                  "test_auc": 0.6401626615812942,
                  "test_f1": 0.6083836575169431
                },
                "best_minus_llm_auc": -0.0526538048134203
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:47:03+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "3bb7b359ef9951bd112024b04360aa574daa69651e0ad2c93a7eb7be4afb88aa",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "5b471f4e1c5f7e2adffaf03a23ee1be6fa480a48e45b00baf742ad14748ff72d",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.04_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.917762355804443,
                "independent_score_mean_max": 9.434153938293457,
                "interpretability_score_mean_max": 8.407541389465331,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:47:03",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.917762355804443,
                "independent_score_mean_max": 9.434153938293457,
                "interpretability_score_mean_max": 8.407541389465331
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.593545074462895,
                "independent_score_mean_max": -41.56511240959168,
                "interpretability_score_mean_max": -39.544070196151736
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.0526538048134203,
          "cebench_delta": -39.544070196151736,
          "cebench_interpretability_max": 8.407541389465331,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.09542572274923866,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.19705168012537597,
              "alignment": 1.0,
              "explained_variance": 0.8930138684175265
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
        "candidate_tag": "seed123",
        "saebench": {
          "timestamp_utc": "2026-02-18T01:47:37+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "48f91575a35b364341944e1515d9337cb1dbda85d9047b2fbf372511ae882494",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6146857625588232,
                "test_auc": 0.6204569909261866,
                "test_f1": 0.5895111258745126
              },
              {
                "k": 2,
                "test_accuracy": 0.6248548346293367,
                "test_auc": 0.6381960728564616,
                "test_f1": 0.6040005402332591
              },
              {
                "k": 5,
                "test_accuracy": 0.6277629996730051,
                "test_auc": 0.6474857911964319,
                "test_f1": 0.6084575154962668
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6277629996730051,
              "test_auc": 0.6474857911964319,
              "test_f1": 0.6084575154962668
            },
            "best_minus_llm_auc": -0.0453306751982826
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T01:49:56+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "20dd2d66de887e01e9abab7a7c66e346c72d8af99f7b0c434d6207ec66e458a4",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "456f8a0340751ae227dd0577967f5adfa34f1e906b4b9ec7fc9e5eebe523be25",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.04_seed123/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 9.344703226089477,
            "independent_score_mean_max": 9.525979993343354,
            "interpretability_score_mean_max": 8.744984805583954,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123",
            "sae_id": "custom_sae",
            "date": "2026-02-18 01:49:56",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 9.344703226089477,
            "independent_score_mean_max": 9.525979993343354,
            "interpretability_score_mean_max": 8.744984805583954
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.16660420417786,
            "independent_score_mean_max": -41.47328635454178,
            "interpretability_score_mean_max": -39.20662678003311
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.7869569937326013,
        "ev_drop": 0.6369025707244873,
        "ev_neg_drop": -0.6369025707244873,
        "saebench_delta": -0.0453306751982826,
        "cebench_delta": -39.20662678003311,
        "cebench_interpretability_max": 8.744984805583954
      },
      "selection": {
        "joint_score": 0.49141810720430446,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    },
    {
      "lambda_consistency": 0.06,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9681186109781266,
        "std": 0.009838954662492403,
        "min": 0.9601444900035858,
        "max": 0.9797812402248383,
        "median": 0.9608248621225357,
        "ci95_low": 0.9623981320112943,
        "ci95_high": 0.9738675156235694,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.8087363794445992,
      "delta_pwmcc_ci_low_conservative": 0.8028978991694748,
      "ratio_pwmcc": 6.074194103465509,
      "explained_variance": {
        "mean": -2.329409646987915,
        "std": 0.4187447785603769,
        "min": -2.52327299118042,
        "max": -1.580458402633667,
        "median": -2.518995761871338,
        "ci95_low": -2.521308708190918,
        "ci95_high": -1.953693675994873,
        "n": 5
      },
      "mse": {
        "mean": 0.002762017771601677,
        "std": 0.0003473902750689829,
        "min": 0.0021406884770840406,
        "max": 0.0029228038620203733,
        "median": 0.0029193018563091755,
        "ci95_low": 0.0024503146298229693,
        "ci95_high": 0.002921218238770962,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9795472472906113,
        "std": 0.0001880140151201936,
        "min": 0.979352593421936,
        "max": 0.9797812700271606,
        "median": 0.9795275628566742,
        "ci95_low": 0.9794003665447235,
        "ci95_high": 0.9796979874372482,
        "n": 4
      },
      "runtime_sec": 268.9666953086853,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
          "lambda_consistency": 0.06,
          "alignment_to_ref": 0.9796069860458374,
          "mse": 0.0029205908067524433,
          "explained_variance": -2.520500898361206,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9097435071167571,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.812829249435001,
          "supervised_proxy_accuracy_eval": 0.24256813526153564,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt",
          "lambda_consistency": 0.06,
          "alignment_to_ref": 0.9797812700271606,
          "mse": 0.002906703855842352,
          "explained_variance": -2.5038201808929443,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9097489164279843,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8153301408445395,
          "supervised_proxy_accuracy_eval": 0.24207521975040436,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt",
          "lambda_consistency": 0.06,
          "alignment_to_ref": 0.979448139667511,
          "mse": 0.0029228038620203733,
          "explained_variance": -2.52327299118042,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9096436232190441,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8148281574249268,
          "supervised_proxy_accuracy_eval": 0.24182529747486115,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt",
          "lambda_consistency": 0.06,
          "alignment_to_ref": 0.979352593421936,
          "mse": 0.0029193018563091755,
          "explained_variance": -2.518995761871338,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9091199791334845,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8131889860939094,
          "supervised_proxy_accuracy_eval": 0.24274864792823792,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.979606956243515,
        0.9797812402248383,
        0.979448139667511,
        0.9793526232242584,
        0.9608666002750397,
        0.9604319036006927,
        0.9603134095668793,
        0.9607831239700317,
        0.9604576230049133,
        0.9601444900035858
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
      "selected_checkpoint_seed": 123,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
          "alignment_to_ref": 0.9796069860458374,
          "explained_variance": -2.520500898361206,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:59:01+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "1552d9a1971ecf45d4097317e2acf36feb378b5833ed3fb35d6d7de5136a7242",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.61076241259786,
                    "test_auc": 0.6192862990943566,
                    "test_f1": 0.5870402719274258
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6179064471544655,
                    "test_auc": 0.630808743734321,
                    "test_f1": 0.5973822557115149
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6235874590147227,
                    "test_auc": 0.6458201881628807,
                    "test_f1": 0.6035104425986537
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6235874590147227,
                  "test_auc": 0.6458201881628807,
                  "test_f1": 0.6035104425986537
                },
                "best_minus_llm_auc": -0.04699627823183383
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:01:21+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "cb57ba926c88ff2aa82149f75ac7d10b50ade76a43791f4314796cd4b9c68ce7",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "ffa38dd075098b784983a2a47415f8aaec1f77aea00f8d65393ca2e3b3c9f7c6",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.06_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.323262963294983,
                "independent_score_mean_max": 9.562152352333069,
                "interpretability_score_mean_max": 8.776485645771027,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:01:21",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.323262963294983,
                "independent_score_mean_max": 9.562152352333069,
                "interpretability_score_mean_max": 8.776485645771027
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.18804446697236,
                "independent_score_mean_max": -41.43711399555207,
                "interpretability_score_mean_max": -39.17512593984604
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04699627823183383,
          "cebench_delta": -39.17512593984604,
          "cebench_interpretability_max": 8.776485645771027,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9494376245913292,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 1.0,
              "alignment": 0.5934371523915462,
              "explained_variance": 0.14250346239168535
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt",
          "alignment_to_ref": 0.979448139667511,
          "explained_variance": -2.52327299118042,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:01:55+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "a7cdd629d2e2d545aee188a7bca75a99f5c60b3a6b7255c0cc050df7e47f37d2",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6093208201542288,
                    "test_auc": 0.6165606017089982,
                    "test_f1": 0.5806128648378149
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6173678296925773,
                    "test_auc": 0.6274434864562592,
                    "test_f1": 0.5882589810035678
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6184078786922815,
                    "test_auc": 0.6455708465147107,
                    "test_f1": 0.593947762209651
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6184078786922815,
                  "test_auc": 0.6455708465147107,
                  "test_f1": 0.593947762209651
                },
                "best_minus_llm_auc": -0.04724561988000375
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:04:13+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "ec69e07e80e52e2d29f3979b1611ee39519afd22ac3114e1c01ee2e2554741d0",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "a834c021912a17ea3fa9a7514f0ea76eb19ecb795f3d652a40a38a16ecf0df3e",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.06_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.306574618816375,
                "independent_score_mean_max": 9.626006660461426,
                "interpretability_score_mean_max": 8.73435683965683,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:04:13",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.306574618816375,
                "independent_score_mean_max": 9.626006660461426,
                "interpretability_score_mean_max": 8.73435683965683
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.20473281145096,
                "independent_score_mean_max": -41.373259687423705,
                "interpretability_score_mean_max": -39.21725474596023
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04724561988000375,
          "cebench_delta": -39.21725474596023,
          "cebench_interpretability_max": 8.73435683965683,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8860560367613738,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.9621726575052905,
              "cebench": 0.8815899598300908,
              "alignment": 0.2228865406006674,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt",
          "alignment_to_ref": 0.979352593421936,
          "explained_variance": -2.518995761871338,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:04:46+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "1ef94175a10e00c1f4ca0f17cc3d75f4917eca206d6fc44bee3f967002b9c3a6",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6121279219852305,
                    "test_auc": 0.616596364286113,
                    "test_f1": 0.5796602215545684
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6199687825338468,
                    "test_auc": 0.6299578455922862,
                    "test_f1": 0.597176245894299
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6261087658276124,
                    "test_auc": 0.6449032768370149,
                    "test_f1": 0.6043170151729031
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6261087658276124,
                  "test_auc": 0.6449032768370149,
                  "test_f1": 0.6043170151729031
                },
                "best_minus_llm_auc": -0.04791318955769963
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:07:06+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "c830f7240716f647cb77462598e14f771a2eb8c4bd09c677308a4f8ae643d4e6",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "0ebac0a93ed2490d0d4b82ac175b0818c84625975844bf8c6f92df659ff539fc",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.218267641067506,
                "independent_score_mean_max": 9.982866225242615,
                "interpretability_score_mean_max": 8.650985288619996,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:07:06",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.218267641067506,
                "independent_score_mean_max": 9.982866225242615,
                "interpretability_score_mean_max": 8.650985288619996
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.29303978919983,
                "independent_score_mean_max": -41.016400122642516,
                "interpretability_score_mean_max": -39.300626296997066
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04791318955769963,
          "cebench_delta": -39.300626296997066,
          "cebench_interpretability_max": 8.650985288619996,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.7794561729306902,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.8608964085407534,
              "cebench": 0.6472603023377689,
              "alignment": 0.0,
              "explained_variance": 0.21987719233739014
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt",
          "alignment_to_ref": 0.9797812700271606,
          "explained_variance": -2.5038201808929443,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:56:13+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "68510c1ed57c27ba91e30ee959c0f4fd6f7ab3f73225788ab8ef96d1eb647b72",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6182205159505856,
                    "test_auc": 0.6223844212885853,
                    "test_f1": 0.5968479814492081
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6187410749718603,
                    "test_auc": 0.6264093828065349,
                    "test_f1": 0.5957431482007058
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6271955407564472,
                    "test_auc": 0.6392286162541537,
                    "test_f1": 0.6094174026510344
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6271955407564472,
                  "test_auc": 0.6392286162541537,
                  "test_f1": 0.6094174026510344
                },
                "best_minus_llm_auc": -0.05358785014056078
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:58:28+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "4759dcda1efebf4a2f6e7fca64d4e78b6df9f5b4031d8d835496b2f6d131106e",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "396b40cf2277759332258975eff0afa91c61cc81bddbf811ae8f188448f6ceaa",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.06_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.87888109445572,
                "independent_score_mean_max": 9.479971313476563,
                "interpretability_score_mean_max": 8.42069819688797,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:58:28",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.87888109445572,
                "independent_score_mean_max": 9.479971313476563,
                "interpretability_score_mean_max": 8.42069819688797
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.632426335811616,
                "independent_score_mean_max": -41.51929503440857,
                "interpretability_score_mean_max": -39.5309133887291
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05358785014056078,
          "cebench_delta": -39.5309133887291,
          "cebench_interpretability_max": 8.42069819688797,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.08,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.0,
              "alignment": 1.0,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
        "candidate_tag": "seed123",
        "saebench": {
          "timestamp_utc": "2026-02-18T01:59:01+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "1552d9a1971ecf45d4097317e2acf36feb378b5833ed3fb35d6d7de5136a7242",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.61076241259786,
                "test_auc": 0.6192862990943566,
                "test_f1": 0.5870402719274258
              },
              {
                "k": 2,
                "test_accuracy": 0.6179064471544655,
                "test_auc": 0.630808743734321,
                "test_f1": 0.5973822557115149
              },
              {
                "k": 5,
                "test_accuracy": 0.6235874590147227,
                "test_auc": 0.6458201881628807,
                "test_f1": 0.6035104425986537
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6235874590147227,
              "test_auc": 0.6458201881628807,
              "test_f1": 0.6035104425986537
            },
            "best_minus_llm_auc": -0.04699627823183383
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T02:01:21+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "cb57ba926c88ff2aa82149f75ac7d10b50ade76a43791f4314796cd4b9c68ce7",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "ffa38dd075098b784983a2a47415f8aaec1f77aea00f8d65393ca2e3b3c9f7c6",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.06_seed123/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 9.323262963294983,
            "independent_score_mean_max": 9.562152352333069,
            "interpretability_score_mean_max": 8.776485645771027,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123",
            "sae_id": "custom_sae",
            "date": "2026-02-18 02:01:21",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 9.323262963294983,
            "independent_score_mean_max": 9.562152352333069,
            "interpretability_score_mean_max": 8.776485645771027
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.18804446697236,
            "independent_score_mean_max": -41.43711399555207,
            "interpretability_score_mean_max": -39.17512593984604
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8028978991694748,
        "ev_drop": 0.7603096485137937,
        "ev_neg_drop": -0.7603096485137937,
        "saebench_delta": -0.04699627823183383,
        "cebench_delta": -39.17512593984604,
        "cebench_interpretability_max": 8.776485645771027
      },
      "selection": {
        "joint_score": 0.4328521991514872,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    },
    {
      "lambda_consistency": 0.08,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9747705280780792,
        "std": 0.007844285995831132,
        "min": 0.9685008525848389,
        "max": 0.984014481306076,
        "median": 0.9689109027385712,
        "ci95_low": 0.9702102871984243,
        "ci95_high": 0.9793499407172204,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.8153882965445518,
      "delta_pwmcc_ci_low_conservative": 0.8107100543566048,
      "ratio_pwmcc": 6.115929728798082,
      "explained_variance": {
        "mean": -2.4191874504089355,
        "std": 0.4691919304665274,
        "min": -2.6448686122894287,
        "max": -1.580458402633667,
        "median": -2.623063802719116,
        "ci95_low": -2.6405057430267336,
        "ci95_high": -1.9977852821350097,
        "n": 5
      },
      "mse": {
        "mean": 0.0028364653699100018,
        "std": 0.0003892235598038787,
        "min": 0.0021406884770840406,
        "max": 0.003023694735020399,
        "median": 0.003005585866048932,
        "ci95_low": 0.0024868846405297516,
        "ci95_high": 0.0030200666282325984,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9838831424713135,
        "std": 0.00011833445094846322,
        "min": 0.983731210231781,
        "max": 0.9840144515037537,
        "median": 0.9838934540748596,
        "ci95_low": 0.9837785512208939,
        "ci95_high": 0.983977422118187,
        "n": 4
      },
      "runtime_sec": 268.2694137096405,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.9839205741882324,
          "mse": 0.003005585866048932,
          "explained_variance": -2.623063802719116,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9131930586537002,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8144381970719055,
          "supervised_proxy_accuracy_eval": 0.24164479970932007,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.9840144515037537,
          "mse": 0.0029886788688600063,
          "explained_variance": -2.602682590484619,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9131614778156357,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.816991641013711,
          "supervised_proxy_accuracy_eval": 0.24116577208042145,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.9838663339614868,
          "mse": 0.003023694735020399,
          "explained_variance": -2.6448638439178467,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9130703440556923,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.816312135645637,
          "supervised_proxy_accuracy_eval": 0.2415475994348526,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.983731210231781,
          "mse": 0.0030236789025366306,
          "explained_variance": -2.6448686122894287,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9128318099408514,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.81474747646738,
          "supervised_proxy_accuracy_eval": 0.241755872964859,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.98392054438591,
        0.984014481306076,
        0.9838663339614868,
        0.9837311804294586,
        0.9689271152019501,
        0.9686734676361084,
        0.9685624539852142,
        0.9688946902751923,
        0.9686141610145569,
        0.9685008525848389
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
      "selected_checkpoint_seed": 123,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
          "alignment_to_ref": 0.9839205741882324,
          "explained_variance": -2.623063802719116,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:10:32+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "fdd61c4458ceae892036a5c54a408067476096b976b563f4734a6b3715179334",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6128424980210215,
                    "test_auc": 0.6205806044507268,
                    "test_f1": 0.5959745774473204
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6170747715145863,
                    "test_auc": 0.6283252501789226,
                    "test_f1": 0.60026776545585
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6318974173392169,
                    "test_auc": 0.6514054620513933,
                    "test_f1": 0.614888519402617
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6318974173392169,
                  "test_auc": 0.6514054620513933,
                  "test_f1": 0.614888519402617
                },
                "best_minus_llm_auc": -0.041411004343321234
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:12:51+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "a94c560d79a26a6af16a3b001da2b94215c98db944a47bd0a65149d01c4ae989",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "e77898e809d3a19d0af3d53cb90609879eef6488ebde9107a24d288a3f35523d",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.08_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.373173317909242,
                "independent_score_mean_max": 9.58368507862091,
                "interpretability_score_mean_max": 8.772915959358215,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:12:51",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.373173317909242,
                "independent_score_mean_max": 9.58368507862091,
                "interpretability_score_mean_max": 8.772915959358215
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.138134112358095,
                "independent_score_mean_max": -41.41558126926422,
                "interpretability_score_mean_max": -39.17869562625885
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.041411004343321234,
          "cebench_delta": -39.17869562625885,
          "cebench_interpretability_max": 8.772915959358215,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9674173384793732,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 1.0,
              "alignment": 0.6685606060606061,
              "explained_variance": 0.516872855923726
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt",
          "alignment_to_ref": 0.983731210231781,
          "explained_variance": -2.6448686122894287,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:16:16+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "0ddfa8980699144721a75585b5b3c425053ecadd1693d4fb5a78094567733fd2",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6144496510710359,
                    "test_auc": 0.6206795133671118,
                    "test_f1": 0.5826807966087421
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.621280939471338,
                    "test_auc": 0.6369276022879068,
                    "test_f1": 0.5983685053844366
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6239888093854862,
                    "test_auc": 0.6513206842908162,
                    "test_f1": 0.6034041408368241
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6239888093854862,
                  "test_auc": 0.6513206842908162,
                  "test_f1": 0.6034041408368241
                },
                "best_minus_llm_auc": -0.04149578210389826
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:18:36+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "cb78cda2bce607ed8600d1d88e385113e7305c0b9875e1f3fef9f381c1f4f081",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "be3d1cbd329c5d2a2995a2399d0d49583ce943f47ad3d6aa383b33d04ebaf88e",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.333460154533386,
                "independent_score_mean_max": 9.871870572566985,
                "interpretability_score_mean_max": 8.67175435781479,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:18:36",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.333460154533386,
                "independent_score_mean_max": 9.871870572566985,
                "interpretability_score_mean_max": 8.67175435781479
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.17784727573395,
                "independent_score_mean_max": -41.12739577531815,
                "interpretability_score_mean_max": -39.279857227802275
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04149578210389826,
          "cebench_delta": -39.279857227802275,
          "cebench_interpretability_max": 8.67175435781479,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8811450487725544,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.9913566958319231,
              "cebench": 0.6823255819037752,
              "alignment": 0.0,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt",
          "alignment_to_ref": 0.9840144515037537,
          "explained_variance": -2.602682590484619,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:07:38+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "357b7f2858cf25858320ba3fb6cccd91699f1035044ba6f21163d42cc464a945",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6144931185952843,
                    "test_auc": 0.6193712919999841,
                    "test_f1": 0.5911847234401085
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6202802832815334,
                    "test_auc": 0.6343474960605368,
                    "test_f1": 0.5981638147080279
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6315813342483471,
                    "test_auc": 0.6500274693123005,
                    "test_f1": 0.6155606002196424
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6315813342483471,
                  "test_auc": 0.6500274693123005,
                  "test_f1": 0.6155606002196424
                },
                "best_minus_llm_auc": -0.042788997082414015
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:09:59+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "54a9f236b168791510247044769d6b945a1e351d12215f0d79010bd2de18af5a",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "7ead6aa5a5a1df7ae3dbce89cd92d8b754acf23f7d82e27783fcedfc0ec44520",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.08_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.908987884521485,
                "independent_score_mean_max": 9.48186628818512,
                "interpretability_score_mean_max": 8.454471678733826,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:09:59",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.908987884521485,
                "independent_score_mean_max": 9.48186628818512,
                "interpretability_score_mean_max": 8.454471678733826
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.60231954574585,
                "independent_score_mean_max": -41.51740005970001,
                "interpretability_score_mean_max": -39.49713990688324
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.042788997082414015,
          "cebench_delta": -39.49713990688324,
          "cebench_interpretability_max": 8.454471678733826,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.7847983663458734,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.8595102028608211,
              "cebench": 0.0,
              "alignment": 1.0,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt",
          "alignment_to_ref": 0.9838663339614868,
          "explained_variance": -2.6448638439178467,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:13:24+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "8592e3a38b3a1966363df9923197d64e90a0efbe710893cd34a347a2ec326361",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6140367022782678,
                    "test_auc": 0.6193655476308826,
                    "test_f1": 0.5876936801649649
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6161735978760723,
                    "test_auc": 0.6251952759332265,
                    "test_f1": 0.588112954146787
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6180647047436452,
                    "test_auc": 0.6415969722738214,
                    "test_f1": 0.5977376812346283
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6180647047436452,
                  "test_auc": 0.6415969722738214,
                  "test_f1": 0.5977376812346283
                },
                "best_minus_llm_auc": -0.051219494120893105
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:15:43+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "b7dd1da5a59b495c44334275d54c9971a922c158fd1ffc5b025809013edfa10c",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "738d461950cf5bc7e9f03aa8b742219c7b7ca3cffe73412d5440e34e64ed9f92",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.08_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.337759158611298,
                "independent_score_mean_max": 9.598845899105072,
                "interpretability_score_mean_max": 8.727591137886048,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:15:43",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.337759158611298,
                "independent_score_mean_max": 9.598845899105072,
                "interpretability_score_mean_max": 8.727591137886048
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.17354827165604,
                "independent_score_mean_max": -41.40042044878006,
                "interpretability_score_mean_max": -39.22402044773102
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.051219494120893105,
          "cebench_delta": -39.22402044773102,
          "cebench_interpretability_max": 8.727591137886048,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.10485380968491168,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.8576679682131508,
              "alignment": 0.4770622895622896,
              "explained_variance": 0.00011303202762502755
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
        "candidate_tag": "seed123",
        "saebench": {
          "timestamp_utc": "2026-02-18T02:10:32+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "fdd61c4458ceae892036a5c54a408067476096b976b563f4734a6b3715179334",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6128424980210215,
                "test_auc": 0.6205806044507268,
                "test_f1": 0.5959745774473204
              },
              {
                "k": 2,
                "test_accuracy": 0.6170747715145863,
                "test_auc": 0.6283252501789226,
                "test_f1": 0.60026776545585
              },
              {
                "k": 5,
                "test_accuracy": 0.6318974173392169,
                "test_auc": 0.6514054620513933,
                "test_f1": 0.614888519402617
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6318974173392169,
              "test_auc": 0.6514054620513933,
              "test_f1": 0.614888519402617
            },
            "best_minus_llm_auc": -0.041411004343321234
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T02:12:51+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "a94c560d79a26a6af16a3b001da2b94215c98db944a47bd0a65149d01c4ae989",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "e77898e809d3a19d0af3d53cb90609879eef6488ebde9107a24d288a3f35523d",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.08_seed123/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 9.373173317909242,
            "independent_score_mean_max": 9.58368507862091,
            "interpretability_score_mean_max": 8.772915959358215,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123",
            "sae_id": "custom_sae",
            "date": "2026-02-18 02:12:51",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 9.373173317909242,
            "independent_score_mean_max": 9.58368507862091,
            "interpretability_score_mean_max": 8.772915959358215
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.138134112358095,
            "independent_score_mean_max": -41.41558126926422,
            "interpretability_score_mean_max": -39.17869562625885
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8107100543566048,
        "ev_drop": 0.8500874519348143,
        "ev_neg_drop": -0.8500874519348143,
        "saebench_delta": -0.041411004343321234,
        "cebench_delta": -39.17869562625885,
        "cebench_interpretability_max": 8.772915959358215
      },
      "selection": {
        "joint_score": 0.6580321431949383,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    },
    {
      "lambda_consistency": 0.1,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9788384407758712,
        "std": 0.006614514059738005,
        "min": 0.9735570549964905,
        "max": 0.9866441190242767,
        "median": 0.9738956689834595,
        "ci95_low": 0.9749921846389771,
        "ci95_high": 0.9826941414177418,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.8194562092423439,
      "delta_pwmcc_ci_low_conservative": 0.8154919517971575,
      "ratio_pwmcc": 6.141452728812901,
      "explained_variance": {
        "mean": -2.4885371685028077,
        "std": 0.5077803603085385,
        "min": -2.7284700870513916,
        "max": -1.580458402633667,
        "median": -2.7121241092681885,
        "ci95_low": -2.723662519454956,
        "ci95_high": -2.0333708763122558,
        "n": 5
      },
      "mse": {
        "mean": 0.0028940031304955484,
        "std": 0.0004212393212176025,
        "min": 0.0021406884770840406,
        "max": 0.0030930284410715103,
        "median": 0.003079495392739773,
        "ci95_low": 0.0025162112433463335,
        "ci95_high": 0.0030890597961843015,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9865223914384842,
        "std": 9.653968341050701e-05,
        "min": 0.9864216446876526,
        "max": 0.9866440892219543,
        "median": 0.9865119159221649,
        "ci95_low": 0.9864481389522552,
        "ci95_high": 0.9866017252206802,
        "n": 4
      },
      "runtime_sec": 270.40073323249817,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9864746332168579,
          "mse": 0.003079495392739773,
          "explained_variance": -2.7121241092681885,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9153307746336968,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.815023952336223,
          "supervised_proxy_accuracy_eval": 0.24196414649486542,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9866440892219543,
          "mse": 0.0030669299885630608,
          "explained_variance": -2.6970090866088867,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9153897756089767,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.817760556384369,
          "supervised_proxy_accuracy_eval": 0.239957794547081,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9865491986274719,
          "mse": 0.0030898733530193567,
          "explained_variance": -2.7246241569519043,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9153193437183896,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8176178399611405,
          "supervised_proxy_accuracy_eval": 0.2411796599626541,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9864216446876526,
          "mse": 0.0030930284410715103,
          "explained_variance": -2.7284700870513916,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9151390490846502,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8158723872016975,
          "supervised_proxy_accuracy_eval": 0.24215853214263916,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9864746332168579,
        0.9866441190242767,
        0.9865491390228271,
        0.9864217042922974,
        0.9738341569900513,
        0.9736634492874146,
        0.9735570549964905,
        0.9739571809768677,
        0.9736941158771515,
        0.9735888540744781
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
      "selected_checkpoint_seed": 123,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
          "alignment_to_ref": 0.9864746332168579,
          "explained_variance": -2.7121241092681885,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:25:29+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "b99726e4c74e2840b0834339a452dc71ca4d38d15df6b091ff9a4e360596a142",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6127733046972033,
                    "test_auc": 0.6166040704693733,
                    "test_f1": 0.5858084643758337
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6174290751682622,
                    "test_auc": 0.6308304395327535,
                    "test_f1": 0.594891254280754
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.630347376204789,
                    "test_auc": 0.6538284846897228,
                    "test_f1": 0.6115256712833682
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.630347376204789,
                  "test_auc": 0.6538284846897228,
                  "test_f1": 0.6115256712833682
                },
                "best_minus_llm_auc": -0.03898798170499174
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:27:50+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "d5cb4a1c84d68d9b4fedea988ec158bde6c6cb0667f265baf028ed87827d2670",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "cca15283c6e1887c803c31558890cd50ab50c2215a2dfc9f464deb05e019107a",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.1_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.423079979419708,
                "independent_score_mean_max": 9.542028293609619,
                "interpretability_score_mean_max": 8.79195578098297,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:27:50",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.423079979419708,
                "independent_score_mean_max": 9.542028293609619,
                "interpretability_score_mean_max": 8.79195578098297
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.088227450847626,
                "independent_score_mean_max": -41.457238054275514,
                "interpretability_score_mean_max": -39.1596558046341
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.03898798170499174,
          "cebench_delta": -39.1596558046341,
          "cebench_interpretability_max": 8.79195578098297,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9503109306426519,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 1.0,
              "alignment": 0.23821007502679528,
              "explained_variance": 0.5195631910395053
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt",
          "alignment_to_ref": 0.9866440892219543,
          "explained_variance": -2.6970090866088867,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:19:08+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "d7293bd37632dffcf422953aa126641beb0be13fc44d1402cdc237cf77601b62",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6116017831481293,
                    "test_auc": 0.6178851906565316,
                    "test_f1": 0.5916254067406483
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6180227419781835,
                    "test_auc": 0.6264974814889942,
                    "test_f1": 0.5878748683420699
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6286962034480289,
                    "test_auc": 0.6497976857688603,
                    "test_f1": 0.6105809769570683
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6286962034480289,
                  "test_auc": 0.6497976857688603,
                  "test_f1": 0.6105809769570683
                },
                "best_minus_llm_auc": -0.04301878062585418
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:21:27+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "2daa9788cc15969eb2360fbd57132b0e4828748a4926c42809a140dbcb24ecf9",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "073fd9cde788de350534990dd20f8ea94e85d0d55a7a645b92fb81ce5dd819f8",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.1_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.869666619300842,
                "independent_score_mean_max": 9.462925579547882,
                "interpretability_score_mean_max": 8.417672142982482,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:21:27",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.869666619300842,
                "independent_score_mean_max": 9.462925579547882,
                "interpretability_score_mean_max": 8.417672142982482
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.64164081096649,
                "independent_score_mean_max": -41.536340768337254,
                "interpretability_score_mean_max": -39.53393944263458
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04301878062585418,
          "cebench_delta": -39.53393944263458,
          "cebench_interpretability_max": 8.417672142982482,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6152568401077271,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.6527522440338135,
              "cebench": 0.0,
              "alignment": 1.0,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt",
          "alignment_to_ref": 0.9864216446876526,
          "explained_variance": -2.7284700870513916,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:28:22+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "83134cee351a42f1f93a6563b1235deb4e9aa74219a32bdcaafbf86975480cc1",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6159903898711686,
                    "test_auc": 0.6213535672721163,
                    "test_f1": 0.5877971477390748
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6280376261856176,
                    "test_auc": 0.6369663028698589,
                    "test_f1": 0.6068774555129514
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6227623115830492,
                    "test_auc": 0.6434298407227366,
                    "test_f1": 0.5880194483596572
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6227623115830492,
                  "test_auc": 0.6434298407227366,
                  "test_f1": 0.5880194483596572
                },
                "best_minus_llm_auc": -0.049386625671977935
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:30:42+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "f40b9e55bb05b9d2dd962703853e1de7e9115b8400d31a46d0a719d290f8d6f4",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "ffae6187f51a5dab7afe10bffb37a3ffdff2ec0ace07aa682cb67bcbd7251d3b",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.211817078590393,
                "independent_score_mean_max": 9.850099985599519,
                "interpretability_score_mean_max": 8.580634999275208,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:30:42",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.211817078590393,
                "independent_score_mean_max": 9.850099985599519,
                "interpretability_score_mean_max": 8.580634999275208
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.299490351676944,
                "independent_score_mean_max": -41.14916636228561,
                "interpretability_score_mean_max": -39.370976586341854
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.049386625671977935,
          "cebench_delta": -39.370976586341854,
          "cebench_interpretability_max": 8.580634999275208,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.12896031542105563,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.10417119446517109,
              "cebench": 0.4353993595961533,
              "alignment": 0.0,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt",
          "alignment_to_ref": 0.9865491986274719,
          "explained_variance": -2.7246241569519043,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:22:01+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "862c24ead3160ea582ed2a7b47815a171349e26f418dfe77a02c79d7a6bff95a",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6137313871482782,
                    "test_auc": 0.6213659203877381,
                    "test_f1": 0.5831502372348302
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6206710878247801,
                    "test_auc": 0.6314086315556385,
                    "test_f1": 0.6007893382877508
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6141925833145672,
                    "test_auc": 0.6422206374060244,
                    "test_f1": 0.5956594054607046
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6141925833145672,
                  "test_auc": 0.6422206374060244,
                  "test_f1": 0.5956594054607046
                },
                "best_minus_llm_auc": -0.050595828988690084
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:24:57+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "980552145e20c45f9fdabd770f5981d37155fda9f7a72fc8e362f3ab3c90dab7",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "ce836abc08f8145f3d33851b2cd56c30d62443acee0aa2faa544822d215a321c",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.1_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.265457112789154,
                "independent_score_mean_max": 9.594468398094177,
                "interpretability_score_mean_max": 8.702605471611022,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:24:57",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.265457112789154,
                "independent_score_mean_max": 9.594468398094177,
                "interpretability_score_mean_max": 8.702605471611022
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.24585031747819,
                "independent_score_mean_max": -41.404797949790954,
                "interpretability_score_mean_max": -39.24900611400604
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.050595828988690084,
          "cebench_delta": -39.24900611400604,
          "cebench_interpretability_max": 8.702605471611022,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.10395418534007218,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.7612764751104913,
              "alignment": 0.5734190782422294,
              "explained_variance": 0.12224436748334684
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
        "candidate_tag": "seed123",
        "saebench": {
          "timestamp_utc": "2026-02-18T02:25:29+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "b99726e4c74e2840b0834339a452dc71ca4d38d15df6b091ff9a4e360596a142",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6127733046972033,
                "test_auc": 0.6166040704693733,
                "test_f1": 0.5858084643758337
              },
              {
                "k": 2,
                "test_accuracy": 0.6174290751682622,
                "test_auc": 0.6308304395327535,
                "test_f1": 0.594891254280754
              },
              {
                "k": 5,
                "test_accuracy": 0.630347376204789,
                "test_auc": 0.6538284846897228,
                "test_f1": 0.6115256712833682
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.630347376204789,
              "test_auc": 0.6538284846897228,
              "test_f1": 0.6115256712833682
            },
            "best_minus_llm_auc": -0.03898798170499174
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T02:27:50+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "d5cb4a1c84d68d9b4fedea988ec158bde6c6cb0667f265baf028ed87827d2670",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "cca15283c6e1887c803c31558890cd50ab50c2215a2dfc9f464deb05e019107a",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.1_seed123/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 9.423079979419708,
            "independent_score_mean_max": 9.542028293609619,
            "interpretability_score_mean_max": 8.79195578098297,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123",
            "sae_id": "custom_sae",
            "date": "2026-02-18 02:27:50",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 9.423079979419708,
            "independent_score_mean_max": 9.542028293609619,
            "interpretability_score_mean_max": 8.79195578098297
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.088227450847626,
            "independent_score_mean_max": -41.457238054275514,
            "interpretability_score_mean_max": -39.1596558046341
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8154919517971575,
        "ev_drop": 0.9194371700286865,
        "ev_neg_drop": -0.9194371700286865,
        "saebench_delta": -0.03898798170499174,
        "cebench_delta": -39.1596558046341,
        "cebench_interpretability_max": 8.79195578098297
      },
      "selection": {
        "joint_score": 0.7622241845913288,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    },
    {
      "lambda_consistency": 0.15,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9844789534807206,
        "std": 0.004897710891915029,
        "min": 0.980559766292572,
        "max": 0.990313708782196,
        "median": 0.9808094948530197,
        "ci95_low": 0.9816289275884629,
        "ci95_high": 0.9873358114808798,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.8250967219471932,
      "delta_pwmcc_ci_low_conservative": 0.8221286947466433,
      "ratio_pwmcc": 6.17684257528812,
      "explained_variance": {
        "mean": -2.6228448390960692,
        "std": 0.5831106460091582,
        "min": -2.912618637084961,
        "max": -1.580458402633667,
        "median": -2.8694798946380615,
        "ci95_low": -2.897904634475708,
        "ci95_high": -2.101074743270874,
        "n": 5
      },
      "mse": {
        "mean": 0.0030054086819291115,
        "std": 0.0004837241787473679,
        "min": 0.0021406884770840406,
        "max": 0.0032457925844937563,
        "median": 0.0032100051175802946,
        "ci95_low": 0.0025705245323479177,
        "ci95_high": 0.003233586996793747,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9901682585477829,
        "std": 0.00010138452077891467,
        "min": 0.9900867342948914,
        "max": 0.990313708782196,
        "median": 0.9901362955570221,
        "ci95_low": 0.9901003837585449,
        "ci95_high": 0.9902637898921967,
        "n": 4
      },
      "runtime_sec": 262.7422397136688,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9901140332221985,
          "mse": 0.0032100051175802946,
          "explained_variance": -2.8694798946380615,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9182703916707801,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8176790898044906,
          "supervised_proxy_accuracy_eval": 0.24187389016151428,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.990313708782196,
          "mse": 0.003199780359864235,
          "explained_variance": -2.8571486473083496,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9185301343461981,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8197697732183666,
          "supervised_proxy_accuracy_eval": 0.24027714133262634,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9901585578918457,
          "mse": 0.0032457925844937563,
          "explained_variance": -2.912618637084961,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9183936743410649,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8196849006193654,
          "supervised_proxy_accuracy_eval": 0.24020077288150787,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9900867342948914,
          "mse": 0.003230776870623231,
          "explained_variance": -2.8945186138153076,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9182685923210725,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8179253582601196,
          "supervised_proxy_accuracy_eval": 0.24147817492485046,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9901140332221985,
        0.990313708782196,
        0.9901585578918457,
        0.9900867640972137,
        0.9807675778865814,
        0.9806192517280579,
        0.980559766292572,
        0.980851411819458,
        0.9807397425174713,
        0.9805787205696106
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
      "selected_checkpoint_seed": 456,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
          "alignment_to_ref": 0.990313708782196,
          "explained_variance": -2.8571486473083496,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:31:16+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "17c436637b1860d904dbc6b2b6d3f25aa35483dfb3b21d0a52b79c0505280aa0",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6186525453979683,
                    "test_auc": 0.6204262495438384,
                    "test_f1": 0.5847039137990445
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6295869566056455,
                    "test_auc": 0.6416029824837811,
                    "test_f1": 0.6044037297966242
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6324830112901659,
                    "test_auc": 0.658527272010255,
                    "test_f1": 0.6128457716724294
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6324830112901659,
                  "test_auc": 0.658527272010255,
                  "test_f1": 0.6128457716724294
                },
                "best_minus_llm_auc": -0.03428919438445954
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:33:38+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "61fcfe4fe2431df1aa143ba25496680d6d56cad4d7eb9e2c764d28be1b01aa7c",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "3edcab31a013478eb28648c3d9c133354a523ee63c70f1e14090e84af1a33fd4",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.914502325057983,
                "independent_score_mean_max": 9.339038774967193,
                "interpretability_score_mean_max": 8.385907528400422,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:33:38",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.914502325057983,
                "independent_score_mean_max": 9.339038774967193,
                "interpretability_score_mean_max": 8.385907528400422
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.596805105209356,
                "independent_score_mean_max": -41.66022757291794,
                "interpretability_score_mean_max": -39.56570405721664
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.03428919438445954,
          "cebench_delta": -39.56570405721664,
          "cebench_interpretability_max": 8.385907528400422,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.0,
              "alignment": 1.0,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
          "alignment_to_ref": 0.9901140332221985,
          "explained_variance": -2.8694798946380615,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:37:03+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "9593422f3b11ce6476105b0e781c166ffa9f57d3ec6005ec3f55cae9b3cd7c72",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6159512520981157,
                    "test_auc": 0.6197763498570634,
                    "test_f1": 0.5879030266578763
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6285442338323799,
                    "test_auc": 0.6440351004826336,
                    "test_f1": 0.6069153331852646
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6321928943101278,
                    "test_auc": 0.6566222045522296,
                    "test_f1": 0.6134238265321097
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6321928943101278,
                  "test_auc": 0.6566222045522296,
                  "test_f1": 0.6134238265321097
                },
                "best_minus_llm_auc": -0.036194261842484865
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:39:23+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "f7aad5934967d6486f7e562b246d91d678ef05c5eb540a875746a35afce9a270",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "af0d8710e76b69d331f36e1620b48726373ba1c5695bbf86f73aaad433de52e2",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.389745931625367,
                "independent_score_mean_max": 9.589236640930176,
                "interpretability_score_mean_max": 8.73444492340088,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:39:23",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.389745931625367,
                "independent_score_mean_max": 9.589236640930176,
                "interpretability_score_mean_max": 8.73444492340088
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.12156149864197,
                "independent_score_mean_max": -41.41002970695496,
                "interpretability_score_mean_max": -39.21716666221619
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.036194261842484865,
          "cebench_delta": -39.21716666221619,
          "cebench_interpretability_max": 8.73444492340088,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8630099471428296,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.8866966054452565,
              "cebench": 1.0,
              "alignment": 0.12027310924369748,
              "explained_variance": 0.7776951576992839
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
          "alignment_to_ref": 0.9901585578918457,
          "explained_variance": -2.912618637084961,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:34:11+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "8ec02395cff28376cef045dda824466d32fa903f628f9297f82e0a6a744ca15b",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6072364014961638,
                    "test_auc": 0.6158422479252132,
                    "test_f1": 0.5774071030758309
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6226430373844046,
                    "test_auc": 0.6369499031597436,
                    "test_f1": 0.5982762282392745
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6274351321488251,
                    "test_auc": 0.6471052761712061,
                    "test_f1": 0.6049916010612982
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6274351321488251,
                  "test_auc": 0.6471052761712061,
                  "test_f1": 0.6049916010612982
                },
                "best_minus_llm_auc": -0.04571119022350845
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:36:30+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "1e2c1b29065c9e35b2ffe2edbf7752d56f4880897639c4e7a856591c72267de5",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "afb257f8f8a193a673676d263954deed93dfe991e40df51924f19e7df486f4b2",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.27641587972641,
                "independent_score_mean_max": 9.445425384044647,
                "interpretability_score_mean_max": 8.64591790676117,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:36:30",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.27641587972641,
                "independent_score_mean_max": 9.445425384044647,
                "interpretability_score_mean_max": 8.64591790676117
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.23489155054093,
                "independent_score_mean_max": -41.553840963840486,
                "interpretability_score_mean_max": -39.305693678855896
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04571119022350845,
          "cebench_delta": -39.305693678855896,
          "cebench_interpretability_max": 8.64591790676117,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.3502153834423737,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.32067975036651186,
              "cebench": 0.7460042511662388,
              "alignment": 0.3164390756302521,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
          "alignment_to_ref": 0.9900867342948914,
          "explained_variance": -2.8945186138153076,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:39:55+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "6957db2471ce8b0102650b1be48c85470c8baa8604cd2ee5b084d17af325dd19",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6127747220388311,
                    "test_auc": 0.6206160923563389,
                    "test_f1": 0.5793105215779103
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6217375314944588,
                    "test_auc": 0.6330082404807384,
                    "test_f1": 0.5911823535485532
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6193885733798464,
                    "test_auc": 0.6417134116178828,
                    "test_f1": 0.5994312217515192
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6193885733798464,
                  "test_auc": 0.6417134116178828,
                  "test_f1": 0.5994312217515192
                },
                "best_minus_llm_auc": -0.05110305477683175
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:42:14+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "cc5f03d2728fe198b507ab1bd8f3eee120a5c8b0a622469fbc49750d8e16889d",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "7ba66b8aadf67b0843a1ae57d0e708c44ff6ff2280818d7f748c4c80064856e0",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.27909141778946,
                "independent_score_mean_max": 9.879950060844422,
                "interpretability_score_mean_max": 8.667007133960723,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:42:14",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.27909141778946,
                "independent_score_mean_max": 9.879950060844422,
                "interpretability_score_mean_max": 8.667007133960723
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.23221601247788,
                "independent_score_mean_max": -41.11931628704071,
                "interpretability_score_mean_max": -39.28460445165634
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05110305477683175,
          "cebench_delta": -39.28460445165634,
          "cebench_interpretability_max": 8.667007133960723,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.09370332344924262,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.8065120402932153,
              "alignment": 0.0,
              "explained_variance": 0.32630298549802716
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
        "candidate_tag": "seed456",
        "saebench": {
          "timestamp_utc": "2026-02-18T02:31:16+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "17c436637b1860d904dbc6b2b6d3f25aa35483dfb3b21d0a52b79c0505280aa0",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6186525453979683,
                "test_auc": 0.6204262495438384,
                "test_f1": 0.5847039137990445
              },
              {
                "k": 2,
                "test_accuracy": 0.6295869566056455,
                "test_auc": 0.6416029824837811,
                "test_f1": 0.6044037297966242
              },
              {
                "k": 5,
                "test_accuracy": 0.6324830112901659,
                "test_auc": 0.658527272010255,
                "test_f1": 0.6128457716724294
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6324830112901659,
              "test_auc": 0.658527272010255,
              "test_f1": 0.6128457716724294
            },
            "best_minus_llm_auc": -0.03428919438445954
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T02:33:38+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "61fcfe4fe2431df1aa143ba25496680d6d56cad4d7eb9e2c764d28be1b01aa7c",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "3edcab31a013478eb28648c3d9c133354a523ee63c70f1e14090e84af1a33fd4",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed456/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 8.914502325057983,
            "independent_score_mean_max": 9.339038774967193,
            "interpretability_score_mean_max": 8.385907528400422,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
            "sae_id": "custom_sae",
            "date": "2026-02-18 02:33:38",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 8.914502325057983,
            "independent_score_mean_max": 9.339038774967193,
            "interpretability_score_mean_max": 8.385907528400422
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.596805105209356,
            "independent_score_mean_max": -41.66022757291794,
            "interpretability_score_mean_max": -39.56570405721664
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8221286947466433,
        "ev_drop": 1.053744840621948,
        "ev_neg_drop": -1.053744840621948,
        "saebench_delta": -0.03428919438445954,
        "cebench_delta": -39.56570405721664,
        "cebench_interpretability_max": 8.385907528400422
      },
      "selection": {
        "joint_score": 0.8,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    }
  ],
  "pareto_front": [
    {
      "lambda_consistency": 0.0,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.1639976441860199,
        "std": 0.00031743714213769815,
        "min": 0.1636180281639099,
        "max": 0.16453917324543,
        "median": 0.16395213454961777,
        "ci95_low": 0.1638154529593885,
        "ci95_high": 0.1641866184026003,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.004615412652492518,
      "delta_pwmcc_ci_low_conservative": 0.004315220117568991,
      "ratio_pwmcc": 1.0289581379811565,
      "explained_variance": {
        "mean": -1.5690999984741212,
        "std": 0.01972055792502961,
        "min": -1.5908684730529785,
        "max": -1.5404713153839111,
        "median": -1.574693202972412,
        "ci95_low": -1.5834693908691406,
        "ci95_high": -1.5521761894226074,
        "n": 5
      },
      "mse": {
        "mean": 0.0021312625613063574,
        "std": 1.6371495174561724e-05,
        "min": 0.002107499400153756,
        "max": 0.0021493355743587017,
        "median": 0.002135912189260125,
        "ci95_low": 0.0021172127686440944,
        "ci95_high": 0.002143192058429122,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.15734173730015755,
        "std": 0.0002745345560657119,
        "min": 0.1571110486984253,
        "max": 0.15770940482616425,
        "median": 0.15727324783802032,
        "ci95_low": 0.15713264048099518,
        "ci95_high": 0.15757061168551445,
        "n": 4
      },
      "runtime_sec": 187.082337141037,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.15739226341247559,
          "mse": 0.0021228771656751633,
          "explained_variance": -1.5590085983276367,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.791447404358122,
          "supervised_proxy_accuracy_eval": 0.24927452206611633,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.1571110486984253,
          "mse": 0.002107499400153756,
          "explained_variance": -1.5404713153839111,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.7927430832275637,
          "supervised_proxy_accuracy_eval": 0.24942030012607574,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.15770940482616425,
          "mse": 0.002135912189260125,
          "explained_variance": -1.574693202972412,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.791701413139149,
          "supervised_proxy_accuracy_eval": 0.24978825449943542,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.15715423226356506,
          "mse": 0.0021493355743587017,
          "explained_variance": -1.5908684730529785,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.791906225460547,
          "supervised_proxy_accuracy_eval": 0.2493925392627716,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.1638329178094864,
        0.1636180281639099,
        0.16430993378162384,
        0.16385231167078018,
        0.16425057500600815,
        0.16453917324543,
        0.16370029747486115,
        0.16405195742845535,
        0.164187453687191,
        0.163633793592453
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
      "selected_checkpoint_seed": 123,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
          "alignment_to_ref": 0.15739226341247559,
          "explained_variance": -1.5590085983276367,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:23:57+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "9257b944016719b7d6711961097ba7d5e0a826f11868c62ee621767907b0b93e",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6095639466639499,
                    "test_auc": 0.613725945597959,
                    "test_f1": 0.5715989710586425
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6191709406629907,
                    "test_auc": 0.637182756585181,
                    "test_f1": 0.5903520686254913
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6326485670979377,
                    "test_auc": 0.6503870215344647,
                    "test_f1": 0.6081474084577569
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6326485670979377,
                  "test_auc": 0.6503870215344647,
                  "test_f1": 0.6081474084577569
                },
                "best_minus_llm_auc": -0.0424294448602498
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:26:24+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "0291c26bd4a586a301f79711d9275ad7fae3be2bc574e0944e1584a5b1086234",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "0e5e0c58629761ae3d6d84d3af9509cb03ad019760c360741f8d698f082e2c10",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.0_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.021288571357728,
                "independent_score_mean_max": 9.214037716388702,
                "interpretability_score_mean_max": 8.566019394397735,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:26:24",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.021288571357728,
                "independent_score_mean_max": 9.214037716388702,
                "interpretability_score_mean_max": 8.566019394397735
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.49001885890961,
                "independent_score_mean_max": -41.78522863149643,
                "interpretability_score_mean_max": -39.38559219121933
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.0424294448602498,
          "cebench_delta": -39.38559219121933,
          "cebench_interpretability_max": 8.566019394397735,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9382642792095021,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.7417808499290421,
              "alignment": 0.46997883202589963,
              "explained_variance": 0.6321760233890463
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt",
          "alignment_to_ref": 0.15770940482616425,
          "explained_variance": -1.574693202972412,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:19:44+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "38f8b1b9ee01b955240e5e010b05a34af09a2dd994ced6403f467785b41e36a1",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6158911174233761,
                    "test_auc": 0.6239583527794297,
                    "test_f1": 0.5888470688358332
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6184968313845628,
                    "test_auc": 0.6329032346480699,
                    "test_f1": 0.593792981172296
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6336536681132151,
                    "test_auc": 0.6474125626919695,
                    "test_f1": 0.6164575437282069
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6336536681132151,
                  "test_auc": 0.6474125626919695,
                  "test_f1": 0.6164575437282069
                },
                "best_minus_llm_auc": -0.04540390370274505
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:23:22+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "7b04d5f47dc2f1a39ab939ec5e646cf732df2f2e1f6ff3b4a942a9d44893df3d",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "ffae5c067f32a391900a401f3bf6b3832fba3a1dcc75b27059c4294160a94423",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.0_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.480449571609498,
                "independent_score_mean_max": 9.384900243282319,
                "interpretability_score_mean_max": 8.152732031345368,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:23:21",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.480449571609498,
                "independent_score_mean_max": 9.384900243282319,
                "interpretability_score_mean_max": 8.152732031345368
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -42.03085785865784,
                "independent_score_mean_max": -41.614366104602816,
                "interpretability_score_mean_max": -39.7988795542717
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04540390370274505,
          "cebench_delta": -39.7988795542717,
          "cebench_interpretability_max": 8.152732031345368,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6726408245731844,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.7558568105095648,
              "cebench": 0.0,
              "alignment": 1.0,
              "explained_variance": 0.3209559988835326
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt",
          "alignment_to_ref": 0.15715423226356506,
          "explained_variance": -1.5908684730529785,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:26:59+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "39dee9b69d498b157e1431a1d65759e909de242aeed688060c7c9f6dc7b173c7",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6080592329131207,
                    "test_auc": 0.6107044843836973,
                    "test_f1": 0.5703834278935486
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6187726119813808,
                    "test_auc": 0.6283164334467757,
                    "test_f1": 0.594458324057106
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6240938620263734,
                    "test_auc": 0.6466313721281483,
                    "test_f1": 0.5918920671930044
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6240938620263734,
                  "test_auc": 0.6466313721281483,
                  "test_f1": 0.5918920671930044
                },
                "best_minus_llm_auc": -0.04618509426656625
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:29:30+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "1adebf7cbfefd34764bc9a3ae1fcc661c25ad3352b97d3b83ca4471fc80b2355",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "5b8bfcd586d6855945fd277b09d690907924cd724898905764e8b3bfb6c8da1b",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.043372192382812,
                "independent_score_mean_max": 9.96780168056488,
                "interpretability_score_mean_max": 8.709887642860412,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:29:30",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.043372192382812,
                "independent_score_mean_max": 9.96780168056488,
                "interpretability_score_mean_max": 8.709887642860412
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.467935237884525,
                "independent_score_mean_max": -41.03146466732025,
                "interpretability_score_mean_max": -39.24172394275665
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04618509426656625,
          "cebench_delta": -39.24172394275665,
          "cebench_interpretability_max": 8.709887642860412,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6701109830884754,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.6917367920623964,
              "cebench": 1.0,
              "alignment": 0.07217033993276055,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt",
          "alignment_to_ref": 0.1571110486984253,
          "explained_variance": -1.5404713153839111,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:30:08+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "51ff97700d0a63663e3fe8abe3750a72df1bdba04e7d305403fde524389db1d4",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6134250718608376,
                    "test_auc": 0.6185233752075329,
                    "test_f1": 0.5881539110179038
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6130454144004632,
                    "test_auc": 0.6286125726786732,
                    "test_f1": 0.5788946870308778
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6194074983307263,
                    "test_auc": 0.6382037660903812,
                    "test_f1": 0.5873725860211302
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6194074983307263,
                  "test_auc": 0.6382037660903812,
                  "test_f1": 0.5873725860211302
                },
                "best_minus_llm_auc": -0.054612700304333295
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:32:34+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "83efb68178352d726429b1e0d3111910710ffc1e29ed6b2689d18d27280cfaa1",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "eab7ecb162bd0287c3971faf1bb062870edeea512789601307fe004374056347",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.0_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.945289239883422,
                "independent_score_mean_max": 9.859105889797211,
                "interpretability_score_mean_max": 8.491308145523071,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:32:34",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.945289239883422,
                "independent_score_mean_max": 9.859105889797211,
                "interpretability_score_mean_max": 8.491308145523071
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.566018190383915,
                "independent_score_mean_max": -41.14016045808792,
                "interpretability_score_mean_max": -39.460303440093995
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.054612700304333295,
          "cebench_delta": -39.460303440093995,
          "cebench_interpretability_max": 8.491308145523071,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.10076868063071812,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.6076868063071812,
              "alignment": 0.0,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
        "candidate_tag": "seed123",
        "saebench": {
          "timestamp_utc": "2026-02-18T01:23:57+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "9257b944016719b7d6711961097ba7d5e0a826f11868c62ee621767907b0b93e",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6095639466639499,
                "test_auc": 0.613725945597959,
                "test_f1": 0.5715989710586425
              },
              {
                "k": 2,
                "test_accuracy": 0.6191709406629907,
                "test_auc": 0.637182756585181,
                "test_f1": 0.5903520686254913
              },
              {
                "k": 5,
                "test_accuracy": 0.6326485670979377,
                "test_auc": 0.6503870215344647,
                "test_f1": 0.6081474084577569
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6326485670979377,
              "test_auc": 0.6503870215344647,
              "test_f1": 0.6081474084577569
            },
            "best_minus_llm_auc": -0.0424294448602498
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T01:26:24+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "0291c26bd4a586a301f79711d9275ad7fae3be2bc574e0944e1584a5b1086234",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "0e5e0c58629761ae3d6d84d3af9509cb03ad019760c360741f8d698f082e2c10",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.0_seed123/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 9.021288571357728,
            "independent_score_mean_max": 9.214037716388702,
            "interpretability_score_mean_max": 8.566019394397735,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123",
            "sae_id": "custom_sae",
            "date": "2026-02-18 01:26:24",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 9.021288571357728,
            "independent_score_mean_max": 9.214037716388702,
            "interpretability_score_mean_max": 8.566019394397735
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.49001885890961,
            "independent_score_mean_max": -41.78522863149643,
            "interpretability_score_mean_max": -39.38559219121933
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.004315220117568991,
        "ev_drop": 0.0,
        "ev_neg_drop": -0.0,
        "saebench_delta": -0.0424294448602498,
        "cebench_delta": -39.38559219121933,
        "cebench_interpretability_max": 8.566019394397735
      },
      "selection": {
        "joint_score": 0.3830015368682677,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    },
    {
      "lambda_consistency": 0.02,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9154020756483078,
        "std": 0.025309991871390825,
        "min": 0.8939613997936249,
        "max": 0.9465415179729462,
        "median": 0.8970813900232315,
        "ci95_low": 0.9006726033240557,
        "ci95_high": 0.9302934140712023,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.7560198441147804,
      "delta_pwmcc_ci_low_conservative": 0.7411723704822362,
      "ratio_pwmcc": 5.743438693514247,
      "explained_variance": {
        "mean": -2.0178246974945067,
        "std": 0.24481421368811002,
        "min": -2.1441211700439453,
        "max": -1.580458402633667,
        "median": -2.1178841590881348,
        "ci95_low": -2.1358046531677246,
        "ci95_high": -1.7986218452453613,
        "n": 5
      },
      "mse": {
        "mean": 0.0025035038124769926,
        "std": 0.00020308462193059258,
        "min": 0.0021406884770840406,
        "max": 0.0026082710828632116,
        "median": 0.0025865095667541027,
        "ci95_low": 0.002320823073387146,
        "ci95_high": 0.0026013726368546487,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9447744190692902,
        "std": 0.0013084077911017149,
        "min": 0.9435033798217773,
        "max": 0.9465415477752686,
        "median": 0.9445263743400574,
        "ci95_low": 0.9438296556472778,
        "ci95_high": 0.945945143699646,
        "n": 4
      },
      "runtime_sec": 268.68646478652954,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt",
          "lambda_consistency": 0.02,
          "alignment_to_ref": 0.9465415477752686,
          "mse": 0.0026082710828632116,
          "explained_variance": -2.1441211700439453,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.8829708685236121,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.806984913018015,
          "supervised_proxy_accuracy_eval": 0.24428291618824005,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt",
          "lambda_consistency": 0.02,
          "alignment_to_ref": 0.9448968172073364,
          "mse": 0.0025865095667541027,
          "explained_variance": -2.1178841590881348,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.8808948058048608,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.808379919440658,
          "supervised_proxy_accuracy_eval": 0.2445606142282486,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt",
          "lambda_consistency": 0.02,
          "alignment_to_ref": 0.9441559314727783,
          "mse": 0.002582294400781393,
          "explained_variance": -2.112809896469116,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.8815496075829422,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.808260926493892,
          "supervised_proxy_accuracy_eval": 0.2445397824048996,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
          "lambda_consistency": 0.02,
          "alignment_to_ref": 0.9435033798217773,
          "mse": 0.002599755534902215,
          "explained_variance": -2.133849859237671,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.8799779883723844,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.806140339208974,
          "supervised_proxy_accuracy_eval": 0.24425514042377472,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9465415179729462,
        0.9448967576026917,
        0.9441559910774231,
        0.943503350019455,
        0.8977592885494232,
        0.8964034914970398,
        0.8961204886436462,
        0.8958680927753448,
        0.8948103785514832,
        0.8939613997936249
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
      "selected_checkpoint_seed": 1011,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
          "alignment_to_ref": 0.9435033798217773,
          "explained_variance": -2.133849859237671,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:41:51+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "89c226380f3511f3ceb020051f106393eaa3819be62cbb679b6715cdbdbab1ee",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6066127580020733,
                    "test_auc": 0.6107881724887381,
                    "test_f1": 0.5726167192791645
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6139508276333686,
                    "test_auc": 0.6213140735358289,
                    "test_f1": 0.5897523618627115
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6292440448068571,
                    "test_auc": 0.6438836519134908,
                    "test_f1": 0.6100145438585959
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6292440448068571,
                  "test_auc": 0.6438836519134908,
                  "test_f1": 0.6100145438585959
                },
                "best_minus_llm_auc": -0.04893281448122366
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:44:10+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "a6e8948d969ac588ef09602b2067c0e13d8a99bdc75e0018b171c9fa682e51e3",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "8e2b1c288a298f73fcc5e0e4b8590b414c9734406ec74bcc014c88587d21a9d4",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.041743602752685,
                "independent_score_mean_max": 9.729872329235077,
                "interpretability_score_mean_max": 8.498405346870422,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:44:10",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.041743602752685,
                "independent_score_mean_max": 9.729872329235077,
                "interpretability_score_mean_max": 8.498405346870422
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.46956382751465,
                "independent_score_mean_max": -41.269394018650054,
                "interpretability_score_mean_max": -39.453206238746645
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04893281448122366,
          "cebench_delta": -39.453206238746645,
          "cebench_interpretability_max": 8.498405346870422,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8782350812219107,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.9858915633402866,
              "cebench": 0.5668244958707356,
              "alignment": 0.0,
              "explained_variance": 0.32803874239505365
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt",
          "alignment_to_ref": 0.9441559314727783,
          "explained_variance": -2.112809896469116,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:38:59+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "4f61c2372b23c6819397f3324308921abc9394cf187f2c6956397884d2934f3e",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6164301740472958,
                    "test_auc": 0.6189447531222287,
                    "test_f1": 0.5802173923720336
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6211374955051561,
                    "test_auc": 0.6323487941504077,
                    "test_f1": 0.5905349037939289
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6208000524578717,
                    "test_auc": 0.644044479372317,
                    "test_f1": 0.5990724600859644
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6208000524578717,
                  "test_auc": 0.644044479372317,
                  "test_f1": 0.5990724600859644
                },
                "best_minus_llm_auc": -0.04877198702239749
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:41:19+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "a66b108aa44da4672be79b796974583a1d71831db97a807ad6e1a92cbbd81fd9",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "c518d144bc604c5f6b5f65a634994d0faf3d02d6840f437dd36d733798e123d1",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.02_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.74711392879486,
                "independent_score_mean_max": 9.405555453300476,
                "interpretability_score_mean_max": 8.29776478767395,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:41:19",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.74711392879486,
                "independent_score_mean_max": 9.405555453300476,
                "interpretability_score_mean_max": 8.29776478767395
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.76419350147248,
                "independent_score_mean_max": -41.59371089458466,
                "interpretability_score_mean_max": -39.65384679794312
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04877198702239749,
          "cebench_delta": -39.65384679794312,
          "cebench_interpretability_max": 8.29776478767395,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8685913835046692,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.0,
              "alignment": 0.21478458761673075,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt",
          "alignment_to_ref": 0.9465415477752686,
          "explained_variance": -2.1441211700439453,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:33:08+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "cc426ab7f12a9217f7db4ee601cbd6fbe19abd983ef9fa7fffddc1abc5a809d2",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6162019935830344,
                    "test_auc": 0.6199432689373412,
                    "test_f1": 0.5842961532193424
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6211300733157904,
                    "test_auc": 0.6380554320253848,
                    "test_f1": 0.5987463558363155
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6260852202172976,
                    "test_auc": 0.6422096255561176,
                    "test_f1": 0.6029368366203476
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6260852202172976,
                  "test_auc": 0.6422096255561176,
                  "test_f1": 0.6029368366203476
                },
                "best_minus_llm_auc": -0.0506068408385969
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:35:33+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "1a51837259096a4acdfb07df48563f5c68fa0ef5811c8ffed5e44324d2848d8b",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "1a750497966c2261094fcbbc1b0eecc7fd2d24e1e4e92e6654cc191007356735",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.02_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.296842222213746,
                "independent_score_mean_max": 9.369706768989563,
                "interpretability_score_mean_max": 8.651737773418427,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:35:33",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.296842222213746,
                "independent_score_mean_max": 9.369706768989563,
                "interpretability_score_mean_max": 8.651737773418427
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.21446520805359,
                "independent_score_mean_max": -41.62955957889557,
                "interpretability_score_mean_max": -39.29987381219864
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.0506068408385969,
          "cebench_delta": -39.29987381219864,
          "cebench_interpretability_max": 8.651737773418427,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8280121317069195,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.8390391850084384,
              "cebench": 1.0,
              "alignment": 1.0,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt",
          "alignment_to_ref": 0.9448968172073364,
          "explained_variance": -2.1178841590881348,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:36:07+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "bae70fede0570963a2bc7f84feeef726d5521a3541c2acf1e997d9ef2ed4e618",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6109195613778943,
                    "test_auc": 0.614928433559824,
                    "test_f1": 0.5865321377766118
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6130554611053121,
                    "test_auc": 0.6221364904622736,
                    "test_f1": 0.5890425077562615
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6192134282367925,
                    "test_auc": 0.6326450973780372,
                    "test_f1": 0.5965036409238097
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6192134282367925,
                  "test_auc": 0.6326450973780372,
                  "test_f1": 0.5965036409238097
                },
                "best_minus_llm_auc": -0.0601713690166773
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:38:26+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "a1a1e35bec70a1c5905372dffdfd445a3b5b4f287827ffda99e784f135b06f85",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "ec8ea5eec33de59a953cf48bf6f0233b8b7488bdf1d030c355ec5be9a5db8bc1",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.02_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.747363641262055,
                "independent_score_mean_max": 9.70739779472351,
                "interpretability_score_mean_max": 8.51431446313858,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:38:25",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.747363641262055,
                "independent_score_mean_max": 9.70739779472351,
                "interpretability_score_mean_max": 8.51431446313858
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.76394378900528,
                "independent_score_mean_max": -41.29186855316162,
                "interpretability_score_mean_max": -39.43729712247848
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.0601713690166773,
          "cebench_delta": -39.43729712247848,
          "cebench_interpretability_max": 8.51431446313858,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.113040305796754,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.6117689320533495,
              "alignment": 0.45864396139056735,
              "explained_variance": 0.8379413533949089
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
        "candidate_tag": "seed1011",
        "saebench": {
          "timestamp_utc": "2026-02-18T01:41:51+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "89c226380f3511f3ceb020051f106393eaa3819be62cbb679b6715cdbdbab1ee",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6066127580020733,
                "test_auc": 0.6107881724887381,
                "test_f1": 0.5726167192791645
              },
              {
                "k": 2,
                "test_accuracy": 0.6139508276333686,
                "test_auc": 0.6213140735358289,
                "test_f1": 0.5897523618627115
              },
              {
                "k": 5,
                "test_accuracy": 0.6292440448068571,
                "test_auc": 0.6438836519134908,
                "test_f1": 0.6100145438585959
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6292440448068571,
              "test_auc": 0.6438836519134908,
              "test_f1": 0.6100145438585959
            },
            "best_minus_llm_auc": -0.04893281448122366
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T01:44:10+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "a6e8948d969ac588ef09602b2067c0e13d8a99bdc75e0018b171c9fa682e51e3",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "8e2b1c288a298f73fcc5e0e4b8590b414c9734406ec74bcc014c88587d21a9d4",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 9.041743602752685,
            "independent_score_mean_max": 9.729872329235077,
            "interpretability_score_mean_max": 8.498405346870422,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011",
            "sae_id": "custom_sae",
            "date": "2026-02-18 01:44:10",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 9.041743602752685,
            "independent_score_mean_max": 9.729872329235077,
            "interpretability_score_mean_max": 8.498405346870422
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.46956382751465,
            "independent_score_mean_max": -41.269394018650054,
            "interpretability_score_mean_max": -39.453206238746645
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.7411723704822362,
        "ev_drop": 0.4487246990203855,
        "ev_neg_drop": -0.4487246990203855,
        "saebench_delta": -0.04893281448122366,
        "cebench_delta": -39.453206238746645,
        "cebench_interpretability_max": 8.498405346870422
      },
      "selection": {
        "joint_score": 0.250468152530456,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    },
    {
      "lambda_consistency": 0.04,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9545239537954331,
        "std": 0.013875252132609919,
        "min": 0.9430154263973236,
        "max": 0.9710472226142883,
        "median": 0.9444089233875275,
        "ci95_low": 0.9464572265744209,
        "ci95_high": 0.9626533912122249,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.7951417222619057,
      "delta_pwmcc_ci_low_conservative": 0.7869569937326013,
      "ratio_pwmcc": 5.988898163937685,
      "explained_variance": {
        "mean": -2.2060025691986085,
        "std": 0.3498881411418583,
        "min": -2.382702589035034,
        "max": -1.580458402633667,
        "median": -2.3553390502929688,
        "ci95_low": -2.371536064147949,
        "ci95_high": -1.8907987117767333,
        "n": 5
      },
      "mse": {
        "mean": 0.002659630076959729,
        "std": 0.0002902619370049403,
        "min": 0.0021406884770840406,
        "max": 0.0028062264900654554,
        "median": 0.00278349663130939,
        "ci95_low": 0.0023979608435183764,
        "ci95_high": 0.002796950750052929,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9706359058618546,
        "std": 0.00041085226516615435,
        "min": 0.9702154397964478,
        "max": 0.9710472226142883,
        "median": 0.9706404805183411,
        "ci95_low": 0.9702863693237305,
        "ci95_high": 0.9709854423999786,
        "n": 4
      },
      "runtime_sec": 269.3000237941742,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
          "lambda_consistency": 0.04,
          "alignment_to_ref": 0.970923662185669,
          "mse": 0.0027825776487588882,
          "explained_variance": -2.354233503341675,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9027743291592708,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8109846128909677,
          "supervised_proxy_accuracy_eval": 0.24257507920265198,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt",
          "lambda_consistency": 0.04,
          "alignment_to_ref": 0.9710472226142883,
          "mse": 0.0027851611375808716,
          "explained_variance": -2.3572793006896973,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9024880815262871,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8129605129361153,
          "supervised_proxy_accuracy_eval": 0.24215853214263916,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt",
          "lambda_consistency": 0.04,
          "alignment_to_ref": 0.9703572988510132,
          "mse": 0.0028062264900654554,
          "explained_variance": -2.382702589035034,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9022240903642442,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.812351369195514,
          "supervised_proxy_accuracy_eval": 0.2431790679693222,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt",
          "lambda_consistency": 0.04,
          "alignment_to_ref": 0.9702154397964478,
          "mse": 0.00278349663130939,
          "explained_variance": -2.3553390502929688,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9013843169884274,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.810880299795557,
          "supervised_proxy_accuracy_eval": 0.24277640879154205,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.970923662185669,
        0.9710472226142883,
        0.9703572988510132,
        0.9702154695987701,
        0.9446422457695007,
        0.9436520338058472,
        0.9435916841030121,
        0.9441756010055542,
        0.943618893623352,
        0.9430154263973236
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
      "selected_checkpoint_seed": 123,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
          "alignment_to_ref": 0.970923662185669,
          "explained_variance": -2.354233503341675,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:47:37+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "48f91575a35b364341944e1515d9337cb1dbda85d9047b2fbf372511ae882494",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6146857625588232,
                    "test_auc": 0.6204569909261866,
                    "test_f1": 0.5895111258745126
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6248548346293367,
                    "test_auc": 0.6381960728564616,
                    "test_f1": 0.6040005402332591
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6277629996730051,
                    "test_auc": 0.6474857911964319,
                    "test_f1": 0.6084575154962668
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6277629996730051,
                  "test_auc": 0.6474857911964319,
                  "test_f1": 0.6084575154962668
                },
                "best_minus_llm_auc": -0.0453306751982826
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:49:56+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "20dd2d66de887e01e9abab7a7c66e346c72d8af99f7b0c434d6207ec66e458a4",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "456f8a0340751ae227dd0577967f5adfa34f1e906b4b9ec7fc9e5eebe523be25",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.04_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.344703226089477,
                "independent_score_mean_max": 9.525979993343354,
                "interpretability_score_mean_max": 8.744984805583954,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:49:56",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.344703226089477,
                "independent_score_mean_max": 9.525979993343354,
                "interpretability_score_mean_max": 8.744984805583954
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.16660420417786,
                "independent_score_mean_max": -41.47328635454178,
                "interpretability_score_mean_max": -39.20662678003311
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.0453306751982826,
          "cebench_delta": -39.20662678003311,
          "cebench_interpretability_max": 8.744984805583954,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9940580437119312,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 1.0,
              "alignment": 0.8514510927982802,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt",
          "alignment_to_ref": 0.9702154397964478,
          "explained_variance": -2.3553390502929688,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:53:20+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "a5f14c447f5126bd97d6ed5e862686e2eea4ebf7750f525b1161170d98213cd4",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6083871776451527,
                    "test_auc": 0.6125943116732853,
                    "test_f1": 0.5682157176288499
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6147171759871368,
                    "test_auc": 0.6267843826401306,
                    "test_f1": 0.5850996670594092
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6304372506547544,
                    "test_auc": 0.6452609426235408,
                    "test_f1": 0.611727303826725
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6304372506547544,
                  "test_auc": 0.6452609426235408,
                  "test_f1": 0.611727303826725
                },
                "best_minus_llm_auc": -0.04755552377117367
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:55:39+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "aee5f07065dc17f05f265f16db6f4ab2c4fe95bf8ef03da6f4a128bb7a5f74fb",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "5928420557585e19053e1b8859289128a1ec4034557050921e7503485c5664a5",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.094920408725738,
                "independent_score_mean_max": 9.751197476387023,
                "interpretability_score_mean_max": 8.47542240381241,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:55:39",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.094920408725738,
                "independent_score_mean_max": 9.751197476387023,
                "interpretability_score_mean_max": 8.47542240381241
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.416387021541595,
                "independent_score_mean_max": -41.248068871498106,
                "interpretability_score_mean_max": -39.476189181804656
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04755552377117367,
          "cebench_delta": -39.476189181804656,
          "cebench_interpretability_max": 8.47542240381241,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6451790010366498,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.6961888304841599,
              "cebench": 0.35857489799788705,
              "alignment": 0.0,
              "explained_variance": 0.9611667559962481
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt",
          "alignment_to_ref": 0.9703572988510132,
          "explained_variance": -2.382702589035034,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:50:29+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "47e4788e9babed3f9e1dbbcf33c16e7569d6fd46a299b7affbe8716f20902386",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6111614662553402,
                    "test_auc": 0.6163508920121484,
                    "test_f1": 0.5824876470857958
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6109982958814504,
                    "test_auc": 0.6244914730316864,
                    "test_f1": 0.5836271344307097
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6196722292231289,
                    "test_auc": 0.6435047653693398,
                    "test_f1": 0.5957830570252136
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6196722292231289,
                  "test_auc": 0.6435047653693398,
                  "test_f1": 0.5957830570252136
                },
                "best_minus_llm_auc": -0.04931170102537474
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:52:47+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "61ce832f9fbcde1269a369dbf8f6acbc7dd4f0bf405651b1780daa4caf6142ef",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "8033c23af26918c23da69a8dc767c4a0dba6ce63e89dbafe8237373c1ea17f2f",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.04_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.795378754138946,
                "independent_score_mean_max": 9.445503854751587,
                "interpretability_score_mean_max": 8.324729344844819,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:52:47",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.795378754138946,
                "independent_score_mean_max": 9.445503854751587,
                "interpretability_score_mean_max": 8.324729344844819
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.71592867612839,
                "independent_score_mean_max": -41.55376249313355,
                "interpretability_score_mean_max": -39.62688224077225
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04931170102537474,
          "cebench_delta": -39.62688224077225,
          "cebench_interpretability_max": 8.324729344844819,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.38105060446403716,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.45637643517015836,
              "cebench": 0.0,
              "alignment": 0.17054819061268361,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt",
          "alignment_to_ref": 0.9710472226142883,
          "explained_variance": -2.3572793006896973,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:44:43+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "38813e75ddb69db7062feb49ccf189853eafaf1a085662a346541e03462600ee",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.611097792433858,
                    "test_auc": 0.61463131202268,
                    "test_f1": 0.5903357252599749
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6121689491708484,
                    "test_auc": 0.6198665277563611,
                    "test_f1": 0.5894566907587226
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6255122302929822,
                    "test_auc": 0.6401626615812942,
                    "test_f1": 0.6083836575169431
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6255122302929822,
                  "test_auc": 0.6401626615812942,
                  "test_f1": 0.6083836575169431
                },
                "best_minus_llm_auc": -0.0526538048134203
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:47:03+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "3bb7b359ef9951bd112024b04360aa574daa69651e0ad2c93a7eb7be4afb88aa",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "5b471f4e1c5f7e2adffaf03a23ee1be6fa480a48e45b00baf742ad14748ff72d",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.04_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.917762355804443,
                "independent_score_mean_max": 9.434153938293457,
                "interpretability_score_mean_max": 8.407541389465331,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:47:03",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.917762355804443,
                "independent_score_mean_max": 9.434153938293457,
                "interpretability_score_mean_max": 8.407541389465331
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.593545074462895,
                "independent_score_mean_max": -41.56511240959168,
                "interpretability_score_mean_max": -39.544070196151736
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.0526538048134203,
          "cebench_delta": -39.544070196151736,
          "cebench_interpretability_max": 8.407541389465331,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.09542572274923866,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.19705168012537597,
              "alignment": 1.0,
              "explained_variance": 0.8930138684175265
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
        "candidate_tag": "seed123",
        "saebench": {
          "timestamp_utc": "2026-02-18T01:47:37+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "48f91575a35b364341944e1515d9337cb1dbda85d9047b2fbf372511ae882494",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6146857625588232,
                "test_auc": 0.6204569909261866,
                "test_f1": 0.5895111258745126
              },
              {
                "k": 2,
                "test_accuracy": 0.6248548346293367,
                "test_auc": 0.6381960728564616,
                "test_f1": 0.6040005402332591
              },
              {
                "k": 5,
                "test_accuracy": 0.6277629996730051,
                "test_auc": 0.6474857911964319,
                "test_f1": 0.6084575154962668
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6277629996730051,
              "test_auc": 0.6474857911964319,
              "test_f1": 0.6084575154962668
            },
            "best_minus_llm_auc": -0.0453306751982826
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T01:49:56+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "20dd2d66de887e01e9abab7a7c66e346c72d8af99f7b0c434d6207ec66e458a4",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "456f8a0340751ae227dd0577967f5adfa34f1e906b4b9ec7fc9e5eebe523be25",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.04_seed123/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 9.344703226089477,
            "independent_score_mean_max": 9.525979993343354,
            "interpretability_score_mean_max": 8.744984805583954,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123",
            "sae_id": "custom_sae",
            "date": "2026-02-18 01:49:56",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 9.344703226089477,
            "independent_score_mean_max": 9.525979993343354,
            "interpretability_score_mean_max": 8.744984805583954
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.16660420417786,
            "independent_score_mean_max": -41.47328635454178,
            "interpretability_score_mean_max": -39.20662678003311
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.7869569937326013,
        "ev_drop": 0.6369025707244873,
        "ev_neg_drop": -0.6369025707244873,
        "saebench_delta": -0.0453306751982826,
        "cebench_delta": -39.20662678003311,
        "cebench_interpretability_max": 8.744984805583954
      },
      "selection": {
        "joint_score": 0.49141810720430446,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    },
    {
      "lambda_consistency": 0.06,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9681186109781266,
        "std": 0.009838954662492403,
        "min": 0.9601444900035858,
        "max": 0.9797812402248383,
        "median": 0.9608248621225357,
        "ci95_low": 0.9623981320112943,
        "ci95_high": 0.9738675156235694,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.8087363794445992,
      "delta_pwmcc_ci_low_conservative": 0.8028978991694748,
      "ratio_pwmcc": 6.074194103465509,
      "explained_variance": {
        "mean": -2.329409646987915,
        "std": 0.4187447785603769,
        "min": -2.52327299118042,
        "max": -1.580458402633667,
        "median": -2.518995761871338,
        "ci95_low": -2.521308708190918,
        "ci95_high": -1.953693675994873,
        "n": 5
      },
      "mse": {
        "mean": 0.002762017771601677,
        "std": 0.0003473902750689829,
        "min": 0.0021406884770840406,
        "max": 0.0029228038620203733,
        "median": 0.0029193018563091755,
        "ci95_low": 0.0024503146298229693,
        "ci95_high": 0.002921218238770962,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9795472472906113,
        "std": 0.0001880140151201936,
        "min": 0.979352593421936,
        "max": 0.9797812700271606,
        "median": 0.9795275628566742,
        "ci95_low": 0.9794003665447235,
        "ci95_high": 0.9796979874372482,
        "n": 4
      },
      "runtime_sec": 268.9666953086853,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
          "lambda_consistency": 0.06,
          "alignment_to_ref": 0.9796069860458374,
          "mse": 0.0029205908067524433,
          "explained_variance": -2.520500898361206,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9097435071167571,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.812829249435001,
          "supervised_proxy_accuracy_eval": 0.24256813526153564,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt",
          "lambda_consistency": 0.06,
          "alignment_to_ref": 0.9797812700271606,
          "mse": 0.002906703855842352,
          "explained_variance": -2.5038201808929443,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9097489164279843,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8153301408445395,
          "supervised_proxy_accuracy_eval": 0.24207521975040436,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt",
          "lambda_consistency": 0.06,
          "alignment_to_ref": 0.979448139667511,
          "mse": 0.0029228038620203733,
          "explained_variance": -2.52327299118042,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9096436232190441,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8148281574249268,
          "supervised_proxy_accuracy_eval": 0.24182529747486115,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt",
          "lambda_consistency": 0.06,
          "alignment_to_ref": 0.979352593421936,
          "mse": 0.0029193018563091755,
          "explained_variance": -2.518995761871338,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9091199791334845,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8131889860939094,
          "supervised_proxy_accuracy_eval": 0.24274864792823792,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.979606956243515,
        0.9797812402248383,
        0.979448139667511,
        0.9793526232242584,
        0.9608666002750397,
        0.9604319036006927,
        0.9603134095668793,
        0.9607831239700317,
        0.9604576230049133,
        0.9601444900035858
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
      "selected_checkpoint_seed": 123,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
          "alignment_to_ref": 0.9796069860458374,
          "explained_variance": -2.520500898361206,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:59:01+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "1552d9a1971ecf45d4097317e2acf36feb378b5833ed3fb35d6d7de5136a7242",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.61076241259786,
                    "test_auc": 0.6192862990943566,
                    "test_f1": 0.5870402719274258
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6179064471544655,
                    "test_auc": 0.630808743734321,
                    "test_f1": 0.5973822557115149
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6235874590147227,
                    "test_auc": 0.6458201881628807,
                    "test_f1": 0.6035104425986537
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6235874590147227,
                  "test_auc": 0.6458201881628807,
                  "test_f1": 0.6035104425986537
                },
                "best_minus_llm_auc": -0.04699627823183383
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:01:21+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "cb57ba926c88ff2aa82149f75ac7d10b50ade76a43791f4314796cd4b9c68ce7",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "ffa38dd075098b784983a2a47415f8aaec1f77aea00f8d65393ca2e3b3c9f7c6",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.06_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.323262963294983,
                "independent_score_mean_max": 9.562152352333069,
                "interpretability_score_mean_max": 8.776485645771027,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:01:21",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.323262963294983,
                "independent_score_mean_max": 9.562152352333069,
                "interpretability_score_mean_max": 8.776485645771027
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.18804446697236,
                "independent_score_mean_max": -41.43711399555207,
                "interpretability_score_mean_max": -39.17512593984604
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04699627823183383,
          "cebench_delta": -39.17512593984604,
          "cebench_interpretability_max": 8.776485645771027,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9494376245913292,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 1.0,
              "alignment": 0.5934371523915462,
              "explained_variance": 0.14250346239168535
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt",
          "alignment_to_ref": 0.979448139667511,
          "explained_variance": -2.52327299118042,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:01:55+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "a7cdd629d2e2d545aee188a7bca75a99f5c60b3a6b7255c0cc050df7e47f37d2",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6093208201542288,
                    "test_auc": 0.6165606017089982,
                    "test_f1": 0.5806128648378149
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6173678296925773,
                    "test_auc": 0.6274434864562592,
                    "test_f1": 0.5882589810035678
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6184078786922815,
                    "test_auc": 0.6455708465147107,
                    "test_f1": 0.593947762209651
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6184078786922815,
                  "test_auc": 0.6455708465147107,
                  "test_f1": 0.593947762209651
                },
                "best_minus_llm_auc": -0.04724561988000375
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:04:13+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "ec69e07e80e52e2d29f3979b1611ee39519afd22ac3114e1c01ee2e2554741d0",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "a834c021912a17ea3fa9a7514f0ea76eb19ecb795f3d652a40a38a16ecf0df3e",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.06_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.306574618816375,
                "independent_score_mean_max": 9.626006660461426,
                "interpretability_score_mean_max": 8.73435683965683,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:04:13",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.306574618816375,
                "independent_score_mean_max": 9.626006660461426,
                "interpretability_score_mean_max": 8.73435683965683
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.20473281145096,
                "independent_score_mean_max": -41.373259687423705,
                "interpretability_score_mean_max": -39.21725474596023
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04724561988000375,
          "cebench_delta": -39.21725474596023,
          "cebench_interpretability_max": 8.73435683965683,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8860560367613738,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.9621726575052905,
              "cebench": 0.8815899598300908,
              "alignment": 0.2228865406006674,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt",
          "alignment_to_ref": 0.979352593421936,
          "explained_variance": -2.518995761871338,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:04:46+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "1ef94175a10e00c1f4ca0f17cc3d75f4917eca206d6fc44bee3f967002b9c3a6",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6121279219852305,
                    "test_auc": 0.616596364286113,
                    "test_f1": 0.5796602215545684
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6199687825338468,
                    "test_auc": 0.6299578455922862,
                    "test_f1": 0.597176245894299
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6261087658276124,
                    "test_auc": 0.6449032768370149,
                    "test_f1": 0.6043170151729031
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6261087658276124,
                  "test_auc": 0.6449032768370149,
                  "test_f1": 0.6043170151729031
                },
                "best_minus_llm_auc": -0.04791318955769963
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:07:06+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "c830f7240716f647cb77462598e14f771a2eb8c4bd09c677308a4f8ae643d4e6",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "0ebac0a93ed2490d0d4b82ac175b0818c84625975844bf8c6f92df659ff539fc",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.218267641067506,
                "independent_score_mean_max": 9.982866225242615,
                "interpretability_score_mean_max": 8.650985288619996,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:07:06",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.218267641067506,
                "independent_score_mean_max": 9.982866225242615,
                "interpretability_score_mean_max": 8.650985288619996
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.29303978919983,
                "independent_score_mean_max": -41.016400122642516,
                "interpretability_score_mean_max": -39.300626296997066
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04791318955769963,
          "cebench_delta": -39.300626296997066,
          "cebench_interpretability_max": 8.650985288619996,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.7794561729306902,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.8608964085407534,
              "cebench": 0.6472603023377689,
              "alignment": 0.0,
              "explained_variance": 0.21987719233739014
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt",
          "alignment_to_ref": 0.9797812700271606,
          "explained_variance": -2.5038201808929443,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:56:13+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "68510c1ed57c27ba91e30ee959c0f4fd6f7ab3f73225788ab8ef96d1eb647b72",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6182205159505856,
                    "test_auc": 0.6223844212885853,
                    "test_f1": 0.5968479814492081
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6187410749718603,
                    "test_auc": 0.6264093828065349,
                    "test_f1": 0.5957431482007058
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6271955407564472,
                    "test_auc": 0.6392286162541537,
                    "test_f1": 0.6094174026510344
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6271955407564472,
                  "test_auc": 0.6392286162541537,
                  "test_f1": 0.6094174026510344
                },
                "best_minus_llm_auc": -0.05358785014056078
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:58:28+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "4759dcda1efebf4a2f6e7fca64d4e78b6df9f5b4031d8d835496b2f6d131106e",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "396b40cf2277759332258975eff0afa91c61cc81bddbf811ae8f188448f6ceaa",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.06_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.87888109445572,
                "independent_score_mean_max": 9.479971313476563,
                "interpretability_score_mean_max": 8.42069819688797,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:58:28",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.87888109445572,
                "independent_score_mean_max": 9.479971313476563,
                "interpretability_score_mean_max": 8.42069819688797
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.632426335811616,
                "independent_score_mean_max": -41.51929503440857,
                "interpretability_score_mean_max": -39.5309133887291
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05358785014056078,
          "cebench_delta": -39.5309133887291,
          "cebench_interpretability_max": 8.42069819688797,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.08,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.0,
              "alignment": 1.0,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
        "candidate_tag": "seed123",
        "saebench": {
          "timestamp_utc": "2026-02-18T01:59:01+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "1552d9a1971ecf45d4097317e2acf36feb378b5833ed3fb35d6d7de5136a7242",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.61076241259786,
                "test_auc": 0.6192862990943566,
                "test_f1": 0.5870402719274258
              },
              {
                "k": 2,
                "test_accuracy": 0.6179064471544655,
                "test_auc": 0.630808743734321,
                "test_f1": 0.5973822557115149
              },
              {
                "k": 5,
                "test_accuracy": 0.6235874590147227,
                "test_auc": 0.6458201881628807,
                "test_f1": 0.6035104425986537
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6235874590147227,
              "test_auc": 0.6458201881628807,
              "test_f1": 0.6035104425986537
            },
            "best_minus_llm_auc": -0.04699627823183383
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T02:01:21+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "cb57ba926c88ff2aa82149f75ac7d10b50ade76a43791f4314796cd4b9c68ce7",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "ffa38dd075098b784983a2a47415f8aaec1f77aea00f8d65393ca2e3b3c9f7c6",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.06_seed123/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 9.323262963294983,
            "independent_score_mean_max": 9.562152352333069,
            "interpretability_score_mean_max": 8.776485645771027,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123",
            "sae_id": "custom_sae",
            "date": "2026-02-18 02:01:21",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 9.323262963294983,
            "independent_score_mean_max": 9.562152352333069,
            "interpretability_score_mean_max": 8.776485645771027
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.18804446697236,
            "independent_score_mean_max": -41.43711399555207,
            "interpretability_score_mean_max": -39.17512593984604
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8028978991694748,
        "ev_drop": 0.7603096485137937,
        "ev_neg_drop": -0.7603096485137937,
        "saebench_delta": -0.04699627823183383,
        "cebench_delta": -39.17512593984604,
        "cebench_interpretability_max": 8.776485645771027
      },
      "selection": {
        "joint_score": 0.4328521991514872,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    },
    {
      "lambda_consistency": 0.08,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9747705280780792,
        "std": 0.007844285995831132,
        "min": 0.9685008525848389,
        "max": 0.984014481306076,
        "median": 0.9689109027385712,
        "ci95_low": 0.9702102871984243,
        "ci95_high": 0.9793499407172204,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.8153882965445518,
      "delta_pwmcc_ci_low_conservative": 0.8107100543566048,
      "ratio_pwmcc": 6.115929728798082,
      "explained_variance": {
        "mean": -2.4191874504089355,
        "std": 0.4691919304665274,
        "min": -2.6448686122894287,
        "max": -1.580458402633667,
        "median": -2.623063802719116,
        "ci95_low": -2.6405057430267336,
        "ci95_high": -1.9977852821350097,
        "n": 5
      },
      "mse": {
        "mean": 0.0028364653699100018,
        "std": 0.0003892235598038787,
        "min": 0.0021406884770840406,
        "max": 0.003023694735020399,
        "median": 0.003005585866048932,
        "ci95_low": 0.0024868846405297516,
        "ci95_high": 0.0030200666282325984,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9838831424713135,
        "std": 0.00011833445094846322,
        "min": 0.983731210231781,
        "max": 0.9840144515037537,
        "median": 0.9838934540748596,
        "ci95_low": 0.9837785512208939,
        "ci95_high": 0.983977422118187,
        "n": 4
      },
      "runtime_sec": 268.2694137096405,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.9839205741882324,
          "mse": 0.003005585866048932,
          "explained_variance": -2.623063802719116,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9131930586537002,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8144381970719055,
          "supervised_proxy_accuracy_eval": 0.24164479970932007,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.9840144515037537,
          "mse": 0.0029886788688600063,
          "explained_variance": -2.602682590484619,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9131614778156357,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.816991641013711,
          "supervised_proxy_accuracy_eval": 0.24116577208042145,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.9838663339614868,
          "mse": 0.003023694735020399,
          "explained_variance": -2.6448638439178467,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9130703440556923,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.816312135645637,
          "supervised_proxy_accuracy_eval": 0.2415475994348526,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.983731210231781,
          "mse": 0.0030236789025366306,
          "explained_variance": -2.6448686122894287,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9128318099408514,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.81474747646738,
          "supervised_proxy_accuracy_eval": 0.241755872964859,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.98392054438591,
        0.984014481306076,
        0.9838663339614868,
        0.9837311804294586,
        0.9689271152019501,
        0.9686734676361084,
        0.9685624539852142,
        0.9688946902751923,
        0.9686141610145569,
        0.9685008525848389
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
      "selected_checkpoint_seed": 123,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
          "alignment_to_ref": 0.9839205741882324,
          "explained_variance": -2.623063802719116,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:10:32+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "fdd61c4458ceae892036a5c54a408067476096b976b563f4734a6b3715179334",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6128424980210215,
                    "test_auc": 0.6205806044507268,
                    "test_f1": 0.5959745774473204
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6170747715145863,
                    "test_auc": 0.6283252501789226,
                    "test_f1": 0.60026776545585
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6318974173392169,
                    "test_auc": 0.6514054620513933,
                    "test_f1": 0.614888519402617
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6318974173392169,
                  "test_auc": 0.6514054620513933,
                  "test_f1": 0.614888519402617
                },
                "best_minus_llm_auc": -0.041411004343321234
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:12:51+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "a94c560d79a26a6af16a3b001da2b94215c98db944a47bd0a65149d01c4ae989",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "e77898e809d3a19d0af3d53cb90609879eef6488ebde9107a24d288a3f35523d",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.08_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.373173317909242,
                "independent_score_mean_max": 9.58368507862091,
                "interpretability_score_mean_max": 8.772915959358215,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:12:51",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.373173317909242,
                "independent_score_mean_max": 9.58368507862091,
                "interpretability_score_mean_max": 8.772915959358215
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.138134112358095,
                "independent_score_mean_max": -41.41558126926422,
                "interpretability_score_mean_max": -39.17869562625885
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.041411004343321234,
          "cebench_delta": -39.17869562625885,
          "cebench_interpretability_max": 8.772915959358215,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9674173384793732,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 1.0,
              "alignment": 0.6685606060606061,
              "explained_variance": 0.516872855923726
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt",
          "alignment_to_ref": 0.983731210231781,
          "explained_variance": -2.6448686122894287,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:16:16+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "0ddfa8980699144721a75585b5b3c425053ecadd1693d4fb5a78094567733fd2",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6144496510710359,
                    "test_auc": 0.6206795133671118,
                    "test_f1": 0.5826807966087421
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.621280939471338,
                    "test_auc": 0.6369276022879068,
                    "test_f1": 0.5983685053844366
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6239888093854862,
                    "test_auc": 0.6513206842908162,
                    "test_f1": 0.6034041408368241
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6239888093854862,
                  "test_auc": 0.6513206842908162,
                  "test_f1": 0.6034041408368241
                },
                "best_minus_llm_auc": -0.04149578210389826
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:18:36+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "cb78cda2bce607ed8600d1d88e385113e7305c0b9875e1f3fef9f381c1f4f081",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "be3d1cbd329c5d2a2995a2399d0d49583ce943f47ad3d6aa383b33d04ebaf88e",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.333460154533386,
                "independent_score_mean_max": 9.871870572566985,
                "interpretability_score_mean_max": 8.67175435781479,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:18:36",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.333460154533386,
                "independent_score_mean_max": 9.871870572566985,
                "interpretability_score_mean_max": 8.67175435781479
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.17784727573395,
                "independent_score_mean_max": -41.12739577531815,
                "interpretability_score_mean_max": -39.279857227802275
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04149578210389826,
          "cebench_delta": -39.279857227802275,
          "cebench_interpretability_max": 8.67175435781479,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8811450487725544,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.9913566958319231,
              "cebench": 0.6823255819037752,
              "alignment": 0.0,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt",
          "alignment_to_ref": 0.9840144515037537,
          "explained_variance": -2.602682590484619,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:07:38+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "357b7f2858cf25858320ba3fb6cccd91699f1035044ba6f21163d42cc464a945",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6144931185952843,
                    "test_auc": 0.6193712919999841,
                    "test_f1": 0.5911847234401085
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6202802832815334,
                    "test_auc": 0.6343474960605368,
                    "test_f1": 0.5981638147080279
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6315813342483471,
                    "test_auc": 0.6500274693123005,
                    "test_f1": 0.6155606002196424
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6315813342483471,
                  "test_auc": 0.6500274693123005,
                  "test_f1": 0.6155606002196424
                },
                "best_minus_llm_auc": -0.042788997082414015
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:09:59+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "54a9f236b168791510247044769d6b945a1e351d12215f0d79010bd2de18af5a",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "7ead6aa5a5a1df7ae3dbce89cd92d8b754acf23f7d82e27783fcedfc0ec44520",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.08_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.908987884521485,
                "independent_score_mean_max": 9.48186628818512,
                "interpretability_score_mean_max": 8.454471678733826,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:09:59",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.908987884521485,
                "independent_score_mean_max": 9.48186628818512,
                "interpretability_score_mean_max": 8.454471678733826
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.60231954574585,
                "independent_score_mean_max": -41.51740005970001,
                "interpretability_score_mean_max": -39.49713990688324
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.042788997082414015,
          "cebench_delta": -39.49713990688324,
          "cebench_interpretability_max": 8.454471678733826,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.7847983663458734,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.8595102028608211,
              "cebench": 0.0,
              "alignment": 1.0,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt",
          "alignment_to_ref": 0.9838663339614868,
          "explained_variance": -2.6448638439178467,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:13:24+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "8592e3a38b3a1966363df9923197d64e90a0efbe710893cd34a347a2ec326361",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6140367022782678,
                    "test_auc": 0.6193655476308826,
                    "test_f1": 0.5876936801649649
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6161735978760723,
                    "test_auc": 0.6251952759332265,
                    "test_f1": 0.588112954146787
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6180647047436452,
                    "test_auc": 0.6415969722738214,
                    "test_f1": 0.5977376812346283
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6180647047436452,
                  "test_auc": 0.6415969722738214,
                  "test_f1": 0.5977376812346283
                },
                "best_minus_llm_auc": -0.051219494120893105
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:15:43+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "b7dd1da5a59b495c44334275d54c9971a922c158fd1ffc5b025809013edfa10c",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "738d461950cf5bc7e9f03aa8b742219c7b7ca3cffe73412d5440e34e64ed9f92",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.08_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.337759158611298,
                "independent_score_mean_max": 9.598845899105072,
                "interpretability_score_mean_max": 8.727591137886048,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:15:43",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.337759158611298,
                "independent_score_mean_max": 9.598845899105072,
                "interpretability_score_mean_max": 8.727591137886048
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.17354827165604,
                "independent_score_mean_max": -41.40042044878006,
                "interpretability_score_mean_max": -39.22402044773102
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.051219494120893105,
          "cebench_delta": -39.22402044773102,
          "cebench_interpretability_max": 8.727591137886048,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.10485380968491168,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.8576679682131508,
              "alignment": 0.4770622895622896,
              "explained_variance": 0.00011303202762502755
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
        "candidate_tag": "seed123",
        "saebench": {
          "timestamp_utc": "2026-02-18T02:10:32+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "fdd61c4458ceae892036a5c54a408067476096b976b563f4734a6b3715179334",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6128424980210215,
                "test_auc": 0.6205806044507268,
                "test_f1": 0.5959745774473204
              },
              {
                "k": 2,
                "test_accuracy": 0.6170747715145863,
                "test_auc": 0.6283252501789226,
                "test_f1": 0.60026776545585
              },
              {
                "k": 5,
                "test_accuracy": 0.6318974173392169,
                "test_auc": 0.6514054620513933,
                "test_f1": 0.614888519402617
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6318974173392169,
              "test_auc": 0.6514054620513933,
              "test_f1": 0.614888519402617
            },
            "best_minus_llm_auc": -0.041411004343321234
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T02:12:51+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "a94c560d79a26a6af16a3b001da2b94215c98db944a47bd0a65149d01c4ae989",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "e77898e809d3a19d0af3d53cb90609879eef6488ebde9107a24d288a3f35523d",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.08_seed123/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 9.373173317909242,
            "independent_score_mean_max": 9.58368507862091,
            "interpretability_score_mean_max": 8.772915959358215,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123",
            "sae_id": "custom_sae",
            "date": "2026-02-18 02:12:51",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 9.373173317909242,
            "independent_score_mean_max": 9.58368507862091,
            "interpretability_score_mean_max": 8.772915959358215
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.138134112358095,
            "independent_score_mean_max": -41.41558126926422,
            "interpretability_score_mean_max": -39.17869562625885
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8107100543566048,
        "ev_drop": 0.8500874519348143,
        "ev_neg_drop": -0.8500874519348143,
        "saebench_delta": -0.041411004343321234,
        "cebench_delta": -39.17869562625885,
        "cebench_interpretability_max": 8.772915959358215
      },
      "selection": {
        "joint_score": 0.6580321431949383,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    },
    {
      "lambda_consistency": 0.1,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9788384407758712,
        "std": 0.006614514059738005,
        "min": 0.9735570549964905,
        "max": 0.9866441190242767,
        "median": 0.9738956689834595,
        "ci95_low": 0.9749921846389771,
        "ci95_high": 0.9826941414177418,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.8194562092423439,
      "delta_pwmcc_ci_low_conservative": 0.8154919517971575,
      "ratio_pwmcc": 6.141452728812901,
      "explained_variance": {
        "mean": -2.4885371685028077,
        "std": 0.5077803603085385,
        "min": -2.7284700870513916,
        "max": -1.580458402633667,
        "median": -2.7121241092681885,
        "ci95_low": -2.723662519454956,
        "ci95_high": -2.0333708763122558,
        "n": 5
      },
      "mse": {
        "mean": 0.0028940031304955484,
        "std": 0.0004212393212176025,
        "min": 0.0021406884770840406,
        "max": 0.0030930284410715103,
        "median": 0.003079495392739773,
        "ci95_low": 0.0025162112433463335,
        "ci95_high": 0.0030890597961843015,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9865223914384842,
        "std": 9.653968341050701e-05,
        "min": 0.9864216446876526,
        "max": 0.9866440892219543,
        "median": 0.9865119159221649,
        "ci95_low": 0.9864481389522552,
        "ci95_high": 0.9866017252206802,
        "n": 4
      },
      "runtime_sec": 270.40073323249817,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9864746332168579,
          "mse": 0.003079495392739773,
          "explained_variance": -2.7121241092681885,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9153307746336968,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.815023952336223,
          "supervised_proxy_accuracy_eval": 0.24196414649486542,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9866440892219543,
          "mse": 0.0030669299885630608,
          "explained_variance": -2.6970090866088867,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9153897756089767,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.817760556384369,
          "supervised_proxy_accuracy_eval": 0.239957794547081,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9865491986274719,
          "mse": 0.0030898733530193567,
          "explained_variance": -2.7246241569519043,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9153193437183896,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8176178399611405,
          "supervised_proxy_accuracy_eval": 0.2411796599626541,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9864216446876526,
          "mse": 0.0030930284410715103,
          "explained_variance": -2.7284700870513916,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9151390490846502,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8158723872016975,
          "supervised_proxy_accuracy_eval": 0.24215853214263916,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9864746332168579,
        0.9866441190242767,
        0.9865491390228271,
        0.9864217042922974,
        0.9738341569900513,
        0.9736634492874146,
        0.9735570549964905,
        0.9739571809768677,
        0.9736941158771515,
        0.9735888540744781
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
      "selected_checkpoint_seed": 123,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
          "alignment_to_ref": 0.9864746332168579,
          "explained_variance": -2.7121241092681885,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:25:29+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "b99726e4c74e2840b0834339a452dc71ca4d38d15df6b091ff9a4e360596a142",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6127733046972033,
                    "test_auc": 0.6166040704693733,
                    "test_f1": 0.5858084643758337
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6174290751682622,
                    "test_auc": 0.6308304395327535,
                    "test_f1": 0.594891254280754
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.630347376204789,
                    "test_auc": 0.6538284846897228,
                    "test_f1": 0.6115256712833682
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.630347376204789,
                  "test_auc": 0.6538284846897228,
                  "test_f1": 0.6115256712833682
                },
                "best_minus_llm_auc": -0.03898798170499174
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:27:50+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "d5cb4a1c84d68d9b4fedea988ec158bde6c6cb0667f265baf028ed87827d2670",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "cca15283c6e1887c803c31558890cd50ab50c2215a2dfc9f464deb05e019107a",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.1_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.423079979419708,
                "independent_score_mean_max": 9.542028293609619,
                "interpretability_score_mean_max": 8.79195578098297,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:27:50",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.423079979419708,
                "independent_score_mean_max": 9.542028293609619,
                "interpretability_score_mean_max": 8.79195578098297
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.088227450847626,
                "independent_score_mean_max": -41.457238054275514,
                "interpretability_score_mean_max": -39.1596558046341
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.03898798170499174,
          "cebench_delta": -39.1596558046341,
          "cebench_interpretability_max": 8.79195578098297,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9503109306426519,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 1.0,
              "alignment": 0.23821007502679528,
              "explained_variance": 0.5195631910395053
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt",
          "alignment_to_ref": 0.9866440892219543,
          "explained_variance": -2.6970090866088867,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:19:08+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "d7293bd37632dffcf422953aa126641beb0be13fc44d1402cdc237cf77601b62",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6116017831481293,
                    "test_auc": 0.6178851906565316,
                    "test_f1": 0.5916254067406483
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6180227419781835,
                    "test_auc": 0.6264974814889942,
                    "test_f1": 0.5878748683420699
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6286962034480289,
                    "test_auc": 0.6497976857688603,
                    "test_f1": 0.6105809769570683
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6286962034480289,
                  "test_auc": 0.6497976857688603,
                  "test_f1": 0.6105809769570683
                },
                "best_minus_llm_auc": -0.04301878062585418
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:21:27+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "2daa9788cc15969eb2360fbd57132b0e4828748a4926c42809a140dbcb24ecf9",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "073fd9cde788de350534990dd20f8ea94e85d0d55a7a645b92fb81ce5dd819f8",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.1_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.869666619300842,
                "independent_score_mean_max": 9.462925579547882,
                "interpretability_score_mean_max": 8.417672142982482,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:21:27",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.869666619300842,
                "independent_score_mean_max": 9.462925579547882,
                "interpretability_score_mean_max": 8.417672142982482
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.64164081096649,
                "independent_score_mean_max": -41.536340768337254,
                "interpretability_score_mean_max": -39.53393944263458
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04301878062585418,
          "cebench_delta": -39.53393944263458,
          "cebench_interpretability_max": 8.417672142982482,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6152568401077271,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.6527522440338135,
              "cebench": 0.0,
              "alignment": 1.0,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt",
          "alignment_to_ref": 0.9864216446876526,
          "explained_variance": -2.7284700870513916,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:28:22+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "83134cee351a42f1f93a6563b1235deb4e9aa74219a32bdcaafbf86975480cc1",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6159903898711686,
                    "test_auc": 0.6213535672721163,
                    "test_f1": 0.5877971477390748
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6280376261856176,
                    "test_auc": 0.6369663028698589,
                    "test_f1": 0.6068774555129514
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6227623115830492,
                    "test_auc": 0.6434298407227366,
                    "test_f1": 0.5880194483596572
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6227623115830492,
                  "test_auc": 0.6434298407227366,
                  "test_f1": 0.5880194483596572
                },
                "best_minus_llm_auc": -0.049386625671977935
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:30:42+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "f40b9e55bb05b9d2dd962703853e1de7e9115b8400d31a46d0a719d290f8d6f4",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "ffae6187f51a5dab7afe10bffb37a3ffdff2ec0ace07aa682cb67bcbd7251d3b",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.211817078590393,
                "independent_score_mean_max": 9.850099985599519,
                "interpretability_score_mean_max": 8.580634999275208,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:30:42",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.211817078590393,
                "independent_score_mean_max": 9.850099985599519,
                "interpretability_score_mean_max": 8.580634999275208
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.299490351676944,
                "independent_score_mean_max": -41.14916636228561,
                "interpretability_score_mean_max": -39.370976586341854
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.049386625671977935,
          "cebench_delta": -39.370976586341854,
          "cebench_interpretability_max": 8.580634999275208,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.12896031542105563,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.10417119446517109,
              "cebench": 0.4353993595961533,
              "alignment": 0.0,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt",
          "alignment_to_ref": 0.9865491986274719,
          "explained_variance": -2.7246241569519043,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:22:01+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "862c24ead3160ea582ed2a7b47815a171349e26f418dfe77a02c79d7a6bff95a",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6137313871482782,
                    "test_auc": 0.6213659203877381,
                    "test_f1": 0.5831502372348302
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6206710878247801,
                    "test_auc": 0.6314086315556385,
                    "test_f1": 0.6007893382877508
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6141925833145672,
                    "test_auc": 0.6422206374060244,
                    "test_f1": 0.5956594054607046
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6141925833145672,
                  "test_auc": 0.6422206374060244,
                  "test_f1": 0.5956594054607046
                },
                "best_minus_llm_auc": -0.050595828988690084
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:24:57+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "980552145e20c45f9fdabd770f5981d37155fda9f7a72fc8e362f3ab3c90dab7",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "ce836abc08f8145f3d33851b2cd56c30d62443acee0aa2faa544822d215a321c",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.1_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.265457112789154,
                "independent_score_mean_max": 9.594468398094177,
                "interpretability_score_mean_max": 8.702605471611022,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:24:57",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.265457112789154,
                "independent_score_mean_max": 9.594468398094177,
                "interpretability_score_mean_max": 8.702605471611022
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.24585031747819,
                "independent_score_mean_max": -41.404797949790954,
                "interpretability_score_mean_max": -39.24900611400604
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.050595828988690084,
          "cebench_delta": -39.24900611400604,
          "cebench_interpretability_max": 8.702605471611022,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.10395418534007218,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.7612764751104913,
              "alignment": 0.5734190782422294,
              "explained_variance": 0.12224436748334684
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
        "candidate_tag": "seed123",
        "saebench": {
          "timestamp_utc": "2026-02-18T02:25:29+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "b99726e4c74e2840b0834339a452dc71ca4d38d15df6b091ff9a4e360596a142",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6127733046972033,
                "test_auc": 0.6166040704693733,
                "test_f1": 0.5858084643758337
              },
              {
                "k": 2,
                "test_accuracy": 0.6174290751682622,
                "test_auc": 0.6308304395327535,
                "test_f1": 0.594891254280754
              },
              {
                "k": 5,
                "test_accuracy": 0.630347376204789,
                "test_auc": 0.6538284846897228,
                "test_f1": 0.6115256712833682
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.630347376204789,
              "test_auc": 0.6538284846897228,
              "test_f1": 0.6115256712833682
            },
            "best_minus_llm_auc": -0.03898798170499174
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T02:27:50+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "d5cb4a1c84d68d9b4fedea988ec158bde6c6cb0667f265baf028ed87827d2670",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "cca15283c6e1887c803c31558890cd50ab50c2215a2dfc9f464deb05e019107a",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.1_seed123/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 9.423079979419708,
            "independent_score_mean_max": 9.542028293609619,
            "interpretability_score_mean_max": 8.79195578098297,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123",
            "sae_id": "custom_sae",
            "date": "2026-02-18 02:27:50",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 9.423079979419708,
            "independent_score_mean_max": 9.542028293609619,
            "interpretability_score_mean_max": 8.79195578098297
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.088227450847626,
            "independent_score_mean_max": -41.457238054275514,
            "interpretability_score_mean_max": -39.1596558046341
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8154919517971575,
        "ev_drop": 0.9194371700286865,
        "ev_neg_drop": -0.9194371700286865,
        "saebench_delta": -0.03898798170499174,
        "cebench_delta": -39.1596558046341,
        "cebench_interpretability_max": 8.79195578098297
      },
      "selection": {
        "joint_score": 0.7622241845913288,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    },
    {
      "lambda_consistency": 0.15,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9844789534807206,
        "std": 0.004897710891915029,
        "min": 0.980559766292572,
        "max": 0.990313708782196,
        "median": 0.9808094948530197,
        "ci95_low": 0.9816289275884629,
        "ci95_high": 0.9873358114808798,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.8250967219471932,
      "delta_pwmcc_ci_low_conservative": 0.8221286947466433,
      "ratio_pwmcc": 6.17684257528812,
      "explained_variance": {
        "mean": -2.6228448390960692,
        "std": 0.5831106460091582,
        "min": -2.912618637084961,
        "max": -1.580458402633667,
        "median": -2.8694798946380615,
        "ci95_low": -2.897904634475708,
        "ci95_high": -2.101074743270874,
        "n": 5
      },
      "mse": {
        "mean": 0.0030054086819291115,
        "std": 0.0004837241787473679,
        "min": 0.0021406884770840406,
        "max": 0.0032457925844937563,
        "median": 0.0032100051175802946,
        "ci95_low": 0.0025705245323479177,
        "ci95_high": 0.003233586996793747,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9901682585477829,
        "std": 0.00010138452077891467,
        "min": 0.9900867342948914,
        "max": 0.990313708782196,
        "median": 0.9901362955570221,
        "ci95_low": 0.9901003837585449,
        "ci95_high": 0.9902637898921967,
        "n": 4
      },
      "runtime_sec": 262.7422397136688,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9901140332221985,
          "mse": 0.0032100051175802946,
          "explained_variance": -2.8694798946380615,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9182703916707801,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8176790898044906,
          "supervised_proxy_accuracy_eval": 0.24187389016151428,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.990313708782196,
          "mse": 0.003199780359864235,
          "explained_variance": -2.8571486473083496,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9185301343461981,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8197697732183666,
          "supervised_proxy_accuracy_eval": 0.24027714133262634,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9901585578918457,
          "mse": 0.0032457925844937563,
          "explained_variance": -2.912618637084961,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9183936743410649,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8196849006193654,
          "supervised_proxy_accuracy_eval": 0.24020077288150787,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9900867342948914,
          "mse": 0.003230776870623231,
          "explained_variance": -2.8945186138153076,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9182685923210725,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8179253582601196,
          "supervised_proxy_accuracy_eval": 0.24147817492485046,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9901140332221985,
        0.990313708782196,
        0.9901585578918457,
        0.9900867640972137,
        0.9807675778865814,
        0.9806192517280579,
        0.980559766292572,
        0.980851411819458,
        0.9807397425174713,
        0.9805787205696106
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
      "selected_checkpoint_seed": 456,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
          "alignment_to_ref": 0.990313708782196,
          "explained_variance": -2.8571486473083496,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:31:16+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "17c436637b1860d904dbc6b2b6d3f25aa35483dfb3b21d0a52b79c0505280aa0",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6186525453979683,
                    "test_auc": 0.6204262495438384,
                    "test_f1": 0.5847039137990445
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6295869566056455,
                    "test_auc": 0.6416029824837811,
                    "test_f1": 0.6044037297966242
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6324830112901659,
                    "test_auc": 0.658527272010255,
                    "test_f1": 0.6128457716724294
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6324830112901659,
                  "test_auc": 0.658527272010255,
                  "test_f1": 0.6128457716724294
                },
                "best_minus_llm_auc": -0.03428919438445954
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:33:38+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "61fcfe4fe2431df1aa143ba25496680d6d56cad4d7eb9e2c764d28be1b01aa7c",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "3edcab31a013478eb28648c3d9c133354a523ee63c70f1e14090e84af1a33fd4",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.914502325057983,
                "independent_score_mean_max": 9.339038774967193,
                "interpretability_score_mean_max": 8.385907528400422,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:33:38",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.914502325057983,
                "independent_score_mean_max": 9.339038774967193,
                "interpretability_score_mean_max": 8.385907528400422
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.596805105209356,
                "independent_score_mean_max": -41.66022757291794,
                "interpretability_score_mean_max": -39.56570405721664
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.03428919438445954,
          "cebench_delta": -39.56570405721664,
          "cebench_interpretability_max": 8.385907528400422,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.0,
              "alignment": 1.0,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
          "alignment_to_ref": 0.9901140332221985,
          "explained_variance": -2.8694798946380615,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:37:03+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "9593422f3b11ce6476105b0e781c166ffa9f57d3ec6005ec3f55cae9b3cd7c72",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6159512520981157,
                    "test_auc": 0.6197763498570634,
                    "test_f1": 0.5879030266578763
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6285442338323799,
                    "test_auc": 0.6440351004826336,
                    "test_f1": 0.6069153331852646
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6321928943101278,
                    "test_auc": 0.6566222045522296,
                    "test_f1": 0.6134238265321097
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6321928943101278,
                  "test_auc": 0.6566222045522296,
                  "test_f1": 0.6134238265321097
                },
                "best_minus_llm_auc": -0.036194261842484865
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:39:23+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "f7aad5934967d6486f7e562b246d91d678ef05c5eb540a875746a35afce9a270",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "af0d8710e76b69d331f36e1620b48726373ba1c5695bbf86f73aaad433de52e2",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.389745931625367,
                "independent_score_mean_max": 9.589236640930176,
                "interpretability_score_mean_max": 8.73444492340088,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:39:23",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.389745931625367,
                "independent_score_mean_max": 9.589236640930176,
                "interpretability_score_mean_max": 8.73444492340088
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.12156149864197,
                "independent_score_mean_max": -41.41002970695496,
                "interpretability_score_mean_max": -39.21716666221619
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.036194261842484865,
          "cebench_delta": -39.21716666221619,
          "cebench_interpretability_max": 8.73444492340088,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8630099471428296,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.8866966054452565,
              "cebench": 1.0,
              "alignment": 0.12027310924369748,
              "explained_variance": 0.7776951576992839
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
          "alignment_to_ref": 0.9901585578918457,
          "explained_variance": -2.912618637084961,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:34:11+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "8ec02395cff28376cef045dda824466d32fa903f628f9297f82e0a6a744ca15b",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6072364014961638,
                    "test_auc": 0.6158422479252132,
                    "test_f1": 0.5774071030758309
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6226430373844046,
                    "test_auc": 0.6369499031597436,
                    "test_f1": 0.5982762282392745
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6274351321488251,
                    "test_auc": 0.6471052761712061,
                    "test_f1": 0.6049916010612982
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6274351321488251,
                  "test_auc": 0.6471052761712061,
                  "test_f1": 0.6049916010612982
                },
                "best_minus_llm_auc": -0.04571119022350845
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:36:30+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "1e2c1b29065c9e35b2ffe2edbf7752d56f4880897639c4e7a856591c72267de5",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "afb257f8f8a193a673676d263954deed93dfe991e40df51924f19e7df486f4b2",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.27641587972641,
                "independent_score_mean_max": 9.445425384044647,
                "interpretability_score_mean_max": 8.64591790676117,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:36:30",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.27641587972641,
                "independent_score_mean_max": 9.445425384044647,
                "interpretability_score_mean_max": 8.64591790676117
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.23489155054093,
                "independent_score_mean_max": -41.553840963840486,
                "interpretability_score_mean_max": -39.305693678855896
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04571119022350845,
          "cebench_delta": -39.305693678855896,
          "cebench_interpretability_max": 8.64591790676117,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.3502153834423737,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.32067975036651186,
              "cebench": 0.7460042511662388,
              "alignment": 0.3164390756302521,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
          "alignment_to_ref": 0.9900867342948914,
          "explained_variance": -2.8945186138153076,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:39:55+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "6957db2471ce8b0102650b1be48c85470c8baa8604cd2ee5b084d17af325dd19",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6127747220388311,
                    "test_auc": 0.6206160923563389,
                    "test_f1": 0.5793105215779103
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6217375314944588,
                    "test_auc": 0.6330082404807384,
                    "test_f1": 0.5911823535485532
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6193885733798464,
                    "test_auc": 0.6417134116178828,
                    "test_f1": 0.5994312217515192
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6193885733798464,
                  "test_auc": 0.6417134116178828,
                  "test_f1": 0.5994312217515192
                },
                "best_minus_llm_auc": -0.05110305477683175
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:42:14+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "cc5f03d2728fe198b507ab1bd8f3eee120a5c8b0a622469fbc49750d8e16889d",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "7ba66b8aadf67b0843a1ae57d0e708c44ff6ff2280818d7f748c4c80064856e0",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.27909141778946,
                "independent_score_mean_max": 9.879950060844422,
                "interpretability_score_mean_max": 8.667007133960723,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:42:14",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.27909141778946,
                "independent_score_mean_max": 9.879950060844422,
                "interpretability_score_mean_max": 8.667007133960723
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.23221601247788,
                "independent_score_mean_max": -41.11931628704071,
                "interpretability_score_mean_max": -39.28460445165634
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05110305477683175,
          "cebench_delta": -39.28460445165634,
          "cebench_interpretability_max": 8.667007133960723,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.09370332344924262,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.8065120402932153,
              "alignment": 0.0,
              "explained_variance": 0.32630298549802716
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
        "candidate_tag": "seed456",
        "saebench": {
          "timestamp_utc": "2026-02-18T02:31:16+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "17c436637b1860d904dbc6b2b6d3f25aa35483dfb3b21d0a52b79c0505280aa0",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6186525453979683,
                "test_auc": 0.6204262495438384,
                "test_f1": 0.5847039137990445
              },
              {
                "k": 2,
                "test_accuracy": 0.6295869566056455,
                "test_auc": 0.6416029824837811,
                "test_f1": 0.6044037297966242
              },
              {
                "k": 5,
                "test_accuracy": 0.6324830112901659,
                "test_auc": 0.658527272010255,
                "test_f1": 0.6128457716724294
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6324830112901659,
              "test_auc": 0.658527272010255,
              "test_f1": 0.6128457716724294
            },
            "best_minus_llm_auc": -0.03428919438445954
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T02:33:38+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "61fcfe4fe2431df1aa143ba25496680d6d56cad4d7eb9e2c764d28be1b01aa7c",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "3edcab31a013478eb28648c3d9c133354a523ee63c70f1e14090e84af1a33fd4",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed456/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 8.914502325057983,
            "independent_score_mean_max": 9.339038774967193,
            "interpretability_score_mean_max": 8.385907528400422,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
            "sae_id": "custom_sae",
            "date": "2026-02-18 02:33:38",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 8.914502325057983,
            "independent_score_mean_max": 9.339038774967193,
            "interpretability_score_mean_max": 8.385907528400422
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.596805105209356,
            "independent_score_mean_max": -41.66022757291794,
            "interpretability_score_mean_max": -39.56570405721664
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8221286947466433,
        "ev_drop": 1.053744840621948,
        "ev_neg_drop": -1.053744840621948,
        "saebench_delta": -0.03428919438445954,
        "cebench_delta": -39.56570405721664,
        "cebench_interpretability_max": 8.385907528400422
      },
      "selection": {
        "joint_score": 0.8,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    }
  ],
  "ranked": [
    {
      "lambda_consistency": 0.15,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9844789534807206,
        "std": 0.004897710891915029,
        "min": 0.980559766292572,
        "max": 0.990313708782196,
        "median": 0.9808094948530197,
        "ci95_low": 0.9816289275884629,
        "ci95_high": 0.9873358114808798,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.8250967219471932,
      "delta_pwmcc_ci_low_conservative": 0.8221286947466433,
      "ratio_pwmcc": 6.17684257528812,
      "explained_variance": {
        "mean": -2.6228448390960692,
        "std": 0.5831106460091582,
        "min": -2.912618637084961,
        "max": -1.580458402633667,
        "median": -2.8694798946380615,
        "ci95_low": -2.897904634475708,
        "ci95_high": -2.101074743270874,
        "n": 5
      },
      "mse": {
        "mean": 0.0030054086819291115,
        "std": 0.0004837241787473679,
        "min": 0.0021406884770840406,
        "max": 0.0032457925844937563,
        "median": 0.0032100051175802946,
        "ci95_low": 0.0025705245323479177,
        "ci95_high": 0.003233586996793747,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9901682585477829,
        "std": 0.00010138452077891467,
        "min": 0.9900867342948914,
        "max": 0.990313708782196,
        "median": 0.9901362955570221,
        "ci95_low": 0.9901003837585449,
        "ci95_high": 0.9902637898921967,
        "n": 4
      },
      "runtime_sec": 262.7422397136688,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9901140332221985,
          "mse": 0.0032100051175802946,
          "explained_variance": -2.8694798946380615,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9182703916707801,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8176790898044906,
          "supervised_proxy_accuracy_eval": 0.24187389016151428,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.990313708782196,
          "mse": 0.003199780359864235,
          "explained_variance": -2.8571486473083496,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9185301343461981,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8197697732183666,
          "supervised_proxy_accuracy_eval": 0.24027714133262634,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9901585578918457,
          "mse": 0.0032457925844937563,
          "explained_variance": -2.912618637084961,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9183936743410649,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8196849006193654,
          "supervised_proxy_accuracy_eval": 0.24020077288150787,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
          "lambda_consistency": 0.15,
          "alignment_to_ref": 0.9900867342948914,
          "mse": 0.003230776870623231,
          "explained_variance": -2.8945186138153076,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9182685923210725,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8179253582601196,
          "supervised_proxy_accuracy_eval": 0.24147817492485046,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9901140332221985,
        0.990313708782196,
        0.9901585578918457,
        0.9900867640972137,
        0.9807675778865814,
        0.9806192517280579,
        0.980559766292572,
        0.980851411819458,
        0.9807397425174713,
        0.9805787205696106
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
      "selected_checkpoint_seed": 456,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
          "alignment_to_ref": 0.990313708782196,
          "explained_variance": -2.8571486473083496,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:31:16+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "17c436637b1860d904dbc6b2b6d3f25aa35483dfb3b21d0a52b79c0505280aa0",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6186525453979683,
                    "test_auc": 0.6204262495438384,
                    "test_f1": 0.5847039137990445
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6295869566056455,
                    "test_auc": 0.6416029824837811,
                    "test_f1": 0.6044037297966242
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6324830112901659,
                    "test_auc": 0.658527272010255,
                    "test_f1": 0.6128457716724294
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6324830112901659,
                  "test_auc": 0.658527272010255,
                  "test_f1": 0.6128457716724294
                },
                "best_minus_llm_auc": -0.03428919438445954
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:33:38+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "61fcfe4fe2431df1aa143ba25496680d6d56cad4d7eb9e2c764d28be1b01aa7c",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "3edcab31a013478eb28648c3d9c133354a523ee63c70f1e14090e84af1a33fd4",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.914502325057983,
                "independent_score_mean_max": 9.339038774967193,
                "interpretability_score_mean_max": 8.385907528400422,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:33:38",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.914502325057983,
                "independent_score_mean_max": 9.339038774967193,
                "interpretability_score_mean_max": 8.385907528400422
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.596805105209356,
                "independent_score_mean_max": -41.66022757291794,
                "interpretability_score_mean_max": -39.56570405721664
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.03428919438445954,
          "cebench_delta": -39.56570405721664,
          "cebench_interpretability_max": 8.385907528400422,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.0,
              "alignment": 1.0,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
          "alignment_to_ref": 0.9901140332221985,
          "explained_variance": -2.8694798946380615,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:37:03+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "9593422f3b11ce6476105b0e781c166ffa9f57d3ec6005ec3f55cae9b3cd7c72",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6159512520981157,
                    "test_auc": 0.6197763498570634,
                    "test_f1": 0.5879030266578763
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6285442338323799,
                    "test_auc": 0.6440351004826336,
                    "test_f1": 0.6069153331852646
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6321928943101278,
                    "test_auc": 0.6566222045522296,
                    "test_f1": 0.6134238265321097
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6321928943101278,
                  "test_auc": 0.6566222045522296,
                  "test_f1": 0.6134238265321097
                },
                "best_minus_llm_auc": -0.036194261842484865
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:39:23+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "f7aad5934967d6486f7e562b246d91d678ef05c5eb540a875746a35afce9a270",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "af0d8710e76b69d331f36e1620b48726373ba1c5695bbf86f73aaad433de52e2",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.389745931625367,
                "independent_score_mean_max": 9.589236640930176,
                "interpretability_score_mean_max": 8.73444492340088,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:39:23",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.389745931625367,
                "independent_score_mean_max": 9.589236640930176,
                "interpretability_score_mean_max": 8.73444492340088
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.12156149864197,
                "independent_score_mean_max": -41.41002970695496,
                "interpretability_score_mean_max": -39.21716666221619
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.036194261842484865,
          "cebench_delta": -39.21716666221619,
          "cebench_interpretability_max": 8.73444492340088,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8630099471428296,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.8866966054452565,
              "cebench": 1.0,
              "alignment": 0.12027310924369748,
              "explained_variance": 0.7776951576992839
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
          "alignment_to_ref": 0.9901585578918457,
          "explained_variance": -2.912618637084961,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:34:11+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "8ec02395cff28376cef045dda824466d32fa903f628f9297f82e0a6a744ca15b",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6072364014961638,
                    "test_auc": 0.6158422479252132,
                    "test_f1": 0.5774071030758309
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6226430373844046,
                    "test_auc": 0.6369499031597436,
                    "test_f1": 0.5982762282392745
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6274351321488251,
                    "test_auc": 0.6471052761712061,
                    "test_f1": 0.6049916010612982
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6274351321488251,
                  "test_auc": 0.6471052761712061,
                  "test_f1": 0.6049916010612982
                },
                "best_minus_llm_auc": -0.04571119022350845
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:36:30+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "1e2c1b29065c9e35b2ffe2edbf7752d56f4880897639c4e7a856591c72267de5",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "afb257f8f8a193a673676d263954deed93dfe991e40df51924f19e7df486f4b2",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.27641587972641,
                "independent_score_mean_max": 9.445425384044647,
                "interpretability_score_mean_max": 8.64591790676117,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:36:30",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.27641587972641,
                "independent_score_mean_max": 9.445425384044647,
                "interpretability_score_mean_max": 8.64591790676117
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.23489155054093,
                "independent_score_mean_max": -41.553840963840486,
                "interpretability_score_mean_max": -39.305693678855896
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04571119022350845,
          "cebench_delta": -39.305693678855896,
          "cebench_interpretability_max": 8.64591790676117,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.3502153834423737,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.32067975036651186,
              "cebench": 0.7460042511662388,
              "alignment": 0.3164390756302521,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
          "alignment_to_ref": 0.9900867342948914,
          "explained_variance": -2.8945186138153076,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:39:55+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "6957db2471ce8b0102650b1be48c85470c8baa8604cd2ee5b084d17af325dd19",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6127747220388311,
                    "test_auc": 0.6206160923563389,
                    "test_f1": 0.5793105215779103
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6217375314944588,
                    "test_auc": 0.6330082404807384,
                    "test_f1": 0.5911823535485532
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6193885733798464,
                    "test_auc": 0.6417134116178828,
                    "test_f1": 0.5994312217515192
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6193885733798464,
                  "test_auc": 0.6417134116178828,
                  "test_f1": 0.5994312217515192
                },
                "best_minus_llm_auc": -0.05110305477683175
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:42:14+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "cc5f03d2728fe198b507ab1bd8f3eee120a5c8b0a622469fbc49750d8e16889d",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "7ba66b8aadf67b0843a1ae57d0e708c44ff6ff2280818d7f748c4c80064856e0",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.27909141778946,
                "independent_score_mean_max": 9.879950060844422,
                "interpretability_score_mean_max": 8.667007133960723,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:42:14",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.27909141778946,
                "independent_score_mean_max": 9.879950060844422,
                "interpretability_score_mean_max": 8.667007133960723
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.23221601247788,
                "independent_score_mean_max": -41.11931628704071,
                "interpretability_score_mean_max": -39.28460445165634
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05110305477683175,
          "cebench_delta": -39.28460445165634,
          "cebench_interpretability_max": 8.667007133960723,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.09370332344924262,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.8065120402932153,
              "alignment": 0.0,
              "explained_variance": 0.32630298549802716
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
        "candidate_tag": "seed456",
        "saebench": {
          "timestamp_utc": "2026-02-18T02:31:16+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "17c436637b1860d904dbc6b2b6d3f25aa35483dfb3b21d0a52b79c0505280aa0",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6186525453979683,
                "test_auc": 0.6204262495438384,
                "test_f1": 0.5847039137990445
              },
              {
                "k": 2,
                "test_accuracy": 0.6295869566056455,
                "test_auc": 0.6416029824837811,
                "test_f1": 0.6044037297966242
              },
              {
                "k": 5,
                "test_accuracy": 0.6324830112901659,
                "test_auc": 0.658527272010255,
                "test_f1": 0.6128457716724294
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6324830112901659,
              "test_auc": 0.658527272010255,
              "test_f1": 0.6128457716724294
            },
            "best_minus_llm_auc": -0.03428919438445954
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T02:33:38+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "61fcfe4fe2431df1aa143ba25496680d6d56cad4d7eb9e2c764d28be1b01aa7c",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "3edcab31a013478eb28648c3d9c133354a523ee63c70f1e14090e84af1a33fd4",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed456/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 8.914502325057983,
            "independent_score_mean_max": 9.339038774967193,
            "interpretability_score_mean_max": 8.385907528400422,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
            "sae_id": "custom_sae",
            "date": "2026-02-18 02:33:38",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 8.914502325057983,
            "independent_score_mean_max": 9.339038774967193,
            "interpretability_score_mean_max": 8.385907528400422
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.596805105209356,
            "independent_score_mean_max": -41.66022757291794,
            "interpretability_score_mean_max": -39.56570405721664
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8221286947466433,
        "ev_drop": 1.053744840621948,
        "ev_neg_drop": -1.053744840621948,
        "saebench_delta": -0.03428919438445954,
        "cebench_delta": -39.56570405721664,
        "cebench_interpretability_max": 8.385907528400422
      },
      "selection": {
        "joint_score": 0.8,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    },
    {
      "lambda_consistency": 0.1,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9788384407758712,
        "std": 0.006614514059738005,
        "min": 0.9735570549964905,
        "max": 0.9866441190242767,
        "median": 0.9738956689834595,
        "ci95_low": 0.9749921846389771,
        "ci95_high": 0.9826941414177418,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.8194562092423439,
      "delta_pwmcc_ci_low_conservative": 0.8154919517971575,
      "ratio_pwmcc": 6.141452728812901,
      "explained_variance": {
        "mean": -2.4885371685028077,
        "std": 0.5077803603085385,
        "min": -2.7284700870513916,
        "max": -1.580458402633667,
        "median": -2.7121241092681885,
        "ci95_low": -2.723662519454956,
        "ci95_high": -2.0333708763122558,
        "n": 5
      },
      "mse": {
        "mean": 0.0028940031304955484,
        "std": 0.0004212393212176025,
        "min": 0.0021406884770840406,
        "max": 0.0030930284410715103,
        "median": 0.003079495392739773,
        "ci95_low": 0.0025162112433463335,
        "ci95_high": 0.0030890597961843015,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9865223914384842,
        "std": 9.653968341050701e-05,
        "min": 0.9864216446876526,
        "max": 0.9866440892219543,
        "median": 0.9865119159221649,
        "ci95_low": 0.9864481389522552,
        "ci95_high": 0.9866017252206802,
        "n": 4
      },
      "runtime_sec": 270.40073323249817,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9864746332168579,
          "mse": 0.003079495392739773,
          "explained_variance": -2.7121241092681885,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9153307746336968,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.815023952336223,
          "supervised_proxy_accuracy_eval": 0.24196414649486542,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9866440892219543,
          "mse": 0.0030669299885630608,
          "explained_variance": -2.6970090866088867,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9153897756089767,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.817760556384369,
          "supervised_proxy_accuracy_eval": 0.239957794547081,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9865491986274719,
          "mse": 0.0030898733530193567,
          "explained_variance": -2.7246241569519043,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9153193437183896,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8176178399611405,
          "supervised_proxy_accuracy_eval": 0.2411796599626541,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt",
          "lambda_consistency": 0.1,
          "alignment_to_ref": 0.9864216446876526,
          "mse": 0.0030930284410715103,
          "explained_variance": -2.7284700870513916,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9151390490846502,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8158723872016975,
          "supervised_proxy_accuracy_eval": 0.24215853214263916,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9864746332168579,
        0.9866441190242767,
        0.9865491390228271,
        0.9864217042922974,
        0.9738341569900513,
        0.9736634492874146,
        0.9735570549964905,
        0.9739571809768677,
        0.9736941158771515,
        0.9735888540744781
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
      "selected_checkpoint_seed": 123,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
          "alignment_to_ref": 0.9864746332168579,
          "explained_variance": -2.7121241092681885,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:25:29+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "b99726e4c74e2840b0834339a452dc71ca4d38d15df6b091ff9a4e360596a142",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6127733046972033,
                    "test_auc": 0.6166040704693733,
                    "test_f1": 0.5858084643758337
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6174290751682622,
                    "test_auc": 0.6308304395327535,
                    "test_f1": 0.594891254280754
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.630347376204789,
                    "test_auc": 0.6538284846897228,
                    "test_f1": 0.6115256712833682
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.630347376204789,
                  "test_auc": 0.6538284846897228,
                  "test_f1": 0.6115256712833682
                },
                "best_minus_llm_auc": -0.03898798170499174
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:27:50+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "d5cb4a1c84d68d9b4fedea988ec158bde6c6cb0667f265baf028ed87827d2670",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "cca15283c6e1887c803c31558890cd50ab50c2215a2dfc9f464deb05e019107a",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.1_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.423079979419708,
                "independent_score_mean_max": 9.542028293609619,
                "interpretability_score_mean_max": 8.79195578098297,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:27:50",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.423079979419708,
                "independent_score_mean_max": 9.542028293609619,
                "interpretability_score_mean_max": 8.79195578098297
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.088227450847626,
                "independent_score_mean_max": -41.457238054275514,
                "interpretability_score_mean_max": -39.1596558046341
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.03898798170499174,
          "cebench_delta": -39.1596558046341,
          "cebench_interpretability_max": 8.79195578098297,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9503109306426519,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 1.0,
              "alignment": 0.23821007502679528,
              "explained_variance": 0.5195631910395053
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt",
          "alignment_to_ref": 0.9866440892219543,
          "explained_variance": -2.6970090866088867,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:19:08+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "d7293bd37632dffcf422953aa126641beb0be13fc44d1402cdc237cf77601b62",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6116017831481293,
                    "test_auc": 0.6178851906565316,
                    "test_f1": 0.5916254067406483
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6180227419781835,
                    "test_auc": 0.6264974814889942,
                    "test_f1": 0.5878748683420699
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6286962034480289,
                    "test_auc": 0.6497976857688603,
                    "test_f1": 0.6105809769570683
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6286962034480289,
                  "test_auc": 0.6497976857688603,
                  "test_f1": 0.6105809769570683
                },
                "best_minus_llm_auc": -0.04301878062585418
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:21:27+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "2daa9788cc15969eb2360fbd57132b0e4828748a4926c42809a140dbcb24ecf9",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "073fd9cde788de350534990dd20f8ea94e85d0d55a7a645b92fb81ce5dd819f8",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.1_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.869666619300842,
                "independent_score_mean_max": 9.462925579547882,
                "interpretability_score_mean_max": 8.417672142982482,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:21:27",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.869666619300842,
                "independent_score_mean_max": 9.462925579547882,
                "interpretability_score_mean_max": 8.417672142982482
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.64164081096649,
                "independent_score_mean_max": -41.536340768337254,
                "interpretability_score_mean_max": -39.53393944263458
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04301878062585418,
          "cebench_delta": -39.53393944263458,
          "cebench_interpretability_max": 8.417672142982482,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6152568401077271,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.6527522440338135,
              "cebench": 0.0,
              "alignment": 1.0,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt",
          "alignment_to_ref": 0.9864216446876526,
          "explained_variance": -2.7284700870513916,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:28:22+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "83134cee351a42f1f93a6563b1235deb4e9aa74219a32bdcaafbf86975480cc1",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6159903898711686,
                    "test_auc": 0.6213535672721163,
                    "test_f1": 0.5877971477390748
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6280376261856176,
                    "test_auc": 0.6369663028698589,
                    "test_f1": 0.6068774555129514
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6227623115830492,
                    "test_auc": 0.6434298407227366,
                    "test_f1": 0.5880194483596572
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6227623115830492,
                  "test_auc": 0.6434298407227366,
                  "test_f1": 0.5880194483596572
                },
                "best_minus_llm_auc": -0.049386625671977935
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:30:42+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "f40b9e55bb05b9d2dd962703853e1de7e9115b8400d31a46d0a719d290f8d6f4",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "ffae6187f51a5dab7afe10bffb37a3ffdff2ec0ace07aa682cb67bcbd7251d3b",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.211817078590393,
                "independent_score_mean_max": 9.850099985599519,
                "interpretability_score_mean_max": 8.580634999275208,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:30:42",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.211817078590393,
                "independent_score_mean_max": 9.850099985599519,
                "interpretability_score_mean_max": 8.580634999275208
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.299490351676944,
                "independent_score_mean_max": -41.14916636228561,
                "interpretability_score_mean_max": -39.370976586341854
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.049386625671977935,
          "cebench_delta": -39.370976586341854,
          "cebench_interpretability_max": 8.580634999275208,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.12896031542105563,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.10417119446517109,
              "cebench": 0.4353993595961533,
              "alignment": 0.0,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt",
          "alignment_to_ref": 0.9865491986274719,
          "explained_variance": -2.7246241569519043,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:22:01+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "862c24ead3160ea582ed2a7b47815a171349e26f418dfe77a02c79d7a6bff95a",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6137313871482782,
                    "test_auc": 0.6213659203877381,
                    "test_f1": 0.5831502372348302
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6206710878247801,
                    "test_auc": 0.6314086315556385,
                    "test_f1": 0.6007893382877508
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6141925833145672,
                    "test_auc": 0.6422206374060244,
                    "test_f1": 0.5956594054607046
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6141925833145672,
                  "test_auc": 0.6422206374060244,
                  "test_f1": 0.5956594054607046
                },
                "best_minus_llm_auc": -0.050595828988690084
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:24:57+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "980552145e20c45f9fdabd770f5981d37155fda9f7a72fc8e362f3ab3c90dab7",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "ce836abc08f8145f3d33851b2cd56c30d62443acee0aa2faa544822d215a321c",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.1_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.265457112789154,
                "independent_score_mean_max": 9.594468398094177,
                "interpretability_score_mean_max": 8.702605471611022,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:24:57",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.265457112789154,
                "independent_score_mean_max": 9.594468398094177,
                "interpretability_score_mean_max": 8.702605471611022
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.24585031747819,
                "independent_score_mean_max": -41.404797949790954,
                "interpretability_score_mean_max": -39.24900611400604
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.050595828988690084,
          "cebench_delta": -39.24900611400604,
          "cebench_interpretability_max": 8.702605471611022,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.10395418534007218,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.7612764751104913,
              "alignment": 0.5734190782422294,
              "explained_variance": 0.12224436748334684
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
        "candidate_tag": "seed123",
        "saebench": {
          "timestamp_utc": "2026-02-18T02:25:29+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "b99726e4c74e2840b0834339a452dc71ca4d38d15df6b091ff9a4e360596a142",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6127733046972033,
                "test_auc": 0.6166040704693733,
                "test_f1": 0.5858084643758337
              },
              {
                "k": 2,
                "test_accuracy": 0.6174290751682622,
                "test_auc": 0.6308304395327535,
                "test_f1": 0.594891254280754
              },
              {
                "k": 5,
                "test_accuracy": 0.630347376204789,
                "test_auc": 0.6538284846897228,
                "test_f1": 0.6115256712833682
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.630347376204789,
              "test_auc": 0.6538284846897228,
              "test_f1": 0.6115256712833682
            },
            "best_minus_llm_auc": -0.03898798170499174
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T02:27:50+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.1_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "d5cb4a1c84d68d9b4fedea988ec158bde6c6cb0667f265baf028ed87827d2670",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.1/sae_seed123.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "cca15283c6e1887c803c31558890cd50ab50c2215a2dfc9f464deb05e019107a",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.1_seed123/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 9.423079979419708,
            "independent_score_mean_max": 9.542028293609619,
            "interpretability_score_mean_max": 8.79195578098297,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.1_seed123",
            "sae_id": "custom_sae",
            "date": "2026-02-18 02:27:50",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 9.423079979419708,
            "independent_score_mean_max": 9.542028293609619,
            "interpretability_score_mean_max": 8.79195578098297
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.088227450847626,
            "independent_score_mean_max": -41.457238054275514,
            "interpretability_score_mean_max": -39.1596558046341
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.1/seed123/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8154919517971575,
        "ev_drop": 0.9194371700286865,
        "ev_neg_drop": -0.9194371700286865,
        "saebench_delta": -0.03898798170499174,
        "cebench_delta": -39.1596558046341,
        "cebench_interpretability_max": 8.79195578098297
      },
      "selection": {
        "joint_score": 0.7622241845913288,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    },
    {
      "lambda_consistency": 0.08,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9747705280780792,
        "std": 0.007844285995831132,
        "min": 0.9685008525848389,
        "max": 0.984014481306076,
        "median": 0.9689109027385712,
        "ci95_low": 0.9702102871984243,
        "ci95_high": 0.9793499407172204,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.8153882965445518,
      "delta_pwmcc_ci_low_conservative": 0.8107100543566048,
      "ratio_pwmcc": 6.115929728798082,
      "explained_variance": {
        "mean": -2.4191874504089355,
        "std": 0.4691919304665274,
        "min": -2.6448686122894287,
        "max": -1.580458402633667,
        "median": -2.623063802719116,
        "ci95_low": -2.6405057430267336,
        "ci95_high": -1.9977852821350097,
        "n": 5
      },
      "mse": {
        "mean": 0.0028364653699100018,
        "std": 0.0003892235598038787,
        "min": 0.0021406884770840406,
        "max": 0.003023694735020399,
        "median": 0.003005585866048932,
        "ci95_low": 0.0024868846405297516,
        "ci95_high": 0.0030200666282325984,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9838831424713135,
        "std": 0.00011833445094846322,
        "min": 0.983731210231781,
        "max": 0.9840144515037537,
        "median": 0.9838934540748596,
        "ci95_low": 0.9837785512208939,
        "ci95_high": 0.983977422118187,
        "n": 4
      },
      "runtime_sec": 268.2694137096405,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.9839205741882324,
          "mse": 0.003005585866048932,
          "explained_variance": -2.623063802719116,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9131930586537002,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8144381970719055,
          "supervised_proxy_accuracy_eval": 0.24164479970932007,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.9840144515037537,
          "mse": 0.0029886788688600063,
          "explained_variance": -2.602682590484619,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9131614778156357,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.816991641013711,
          "supervised_proxy_accuracy_eval": 0.24116577208042145,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.9838663339614868,
          "mse": 0.003023694735020399,
          "explained_variance": -2.6448638439178467,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9130703440556923,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.816312135645637,
          "supervised_proxy_accuracy_eval": 0.2415475994348526,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt",
          "lambda_consistency": 0.08,
          "alignment_to_ref": 0.983731210231781,
          "mse": 0.0030236789025366306,
          "explained_variance": -2.6448686122894287,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9128318099408514,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.81474747646738,
          "supervised_proxy_accuracy_eval": 0.241755872964859,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.98392054438591,
        0.984014481306076,
        0.9838663339614868,
        0.9837311804294586,
        0.9689271152019501,
        0.9686734676361084,
        0.9685624539852142,
        0.9688946902751923,
        0.9686141610145569,
        0.9685008525848389
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
      "selected_checkpoint_seed": 123,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
          "alignment_to_ref": 0.9839205741882324,
          "explained_variance": -2.623063802719116,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:10:32+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "fdd61c4458ceae892036a5c54a408067476096b976b563f4734a6b3715179334",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6128424980210215,
                    "test_auc": 0.6205806044507268,
                    "test_f1": 0.5959745774473204
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6170747715145863,
                    "test_auc": 0.6283252501789226,
                    "test_f1": 0.60026776545585
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6318974173392169,
                    "test_auc": 0.6514054620513933,
                    "test_f1": 0.614888519402617
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6318974173392169,
                  "test_auc": 0.6514054620513933,
                  "test_f1": 0.614888519402617
                },
                "best_minus_llm_auc": -0.041411004343321234
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:12:51+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "a94c560d79a26a6af16a3b001da2b94215c98db944a47bd0a65149d01c4ae989",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "e77898e809d3a19d0af3d53cb90609879eef6488ebde9107a24d288a3f35523d",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.08_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.373173317909242,
                "independent_score_mean_max": 9.58368507862091,
                "interpretability_score_mean_max": 8.772915959358215,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:12:51",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.373173317909242,
                "independent_score_mean_max": 9.58368507862091,
                "interpretability_score_mean_max": 8.772915959358215
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.138134112358095,
                "independent_score_mean_max": -41.41558126926422,
                "interpretability_score_mean_max": -39.17869562625885
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.041411004343321234,
          "cebench_delta": -39.17869562625885,
          "cebench_interpretability_max": 8.772915959358215,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9674173384793732,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 1.0,
              "alignment": 0.6685606060606061,
              "explained_variance": 0.516872855923726
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt",
          "alignment_to_ref": 0.983731210231781,
          "explained_variance": -2.6448686122894287,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:16:16+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "0ddfa8980699144721a75585b5b3c425053ecadd1693d4fb5a78094567733fd2",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6144496510710359,
                    "test_auc": 0.6206795133671118,
                    "test_f1": 0.5826807966087421
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.621280939471338,
                    "test_auc": 0.6369276022879068,
                    "test_f1": 0.5983685053844366
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6239888093854862,
                    "test_auc": 0.6513206842908162,
                    "test_f1": 0.6034041408368241
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6239888093854862,
                  "test_auc": 0.6513206842908162,
                  "test_f1": 0.6034041408368241
                },
                "best_minus_llm_auc": -0.04149578210389826
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:18:36+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "cb78cda2bce607ed8600d1d88e385113e7305c0b9875e1f3fef9f381c1f4f081",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "be3d1cbd329c5d2a2995a2399d0d49583ce943f47ad3d6aa383b33d04ebaf88e",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.333460154533386,
                "independent_score_mean_max": 9.871870572566985,
                "interpretability_score_mean_max": 8.67175435781479,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:18:36",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.333460154533386,
                "independent_score_mean_max": 9.871870572566985,
                "interpretability_score_mean_max": 8.67175435781479
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.17784727573395,
                "independent_score_mean_max": -41.12739577531815,
                "interpretability_score_mean_max": -39.279857227802275
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04149578210389826,
          "cebench_delta": -39.279857227802275,
          "cebench_interpretability_max": 8.67175435781479,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8811450487725544,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.9913566958319231,
              "cebench": 0.6823255819037752,
              "alignment": 0.0,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt",
          "alignment_to_ref": 0.9840144515037537,
          "explained_variance": -2.602682590484619,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:07:38+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "357b7f2858cf25858320ba3fb6cccd91699f1035044ba6f21163d42cc464a945",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6144931185952843,
                    "test_auc": 0.6193712919999841,
                    "test_f1": 0.5911847234401085
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6202802832815334,
                    "test_auc": 0.6343474960605368,
                    "test_f1": 0.5981638147080279
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6315813342483471,
                    "test_auc": 0.6500274693123005,
                    "test_f1": 0.6155606002196424
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6315813342483471,
                  "test_auc": 0.6500274693123005,
                  "test_f1": 0.6155606002196424
                },
                "best_minus_llm_auc": -0.042788997082414015
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:09:59+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "54a9f236b168791510247044769d6b945a1e351d12215f0d79010bd2de18af5a",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "7ead6aa5a5a1df7ae3dbce89cd92d8b754acf23f7d82e27783fcedfc0ec44520",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.08_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.908987884521485,
                "independent_score_mean_max": 9.48186628818512,
                "interpretability_score_mean_max": 8.454471678733826,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:09:59",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.908987884521485,
                "independent_score_mean_max": 9.48186628818512,
                "interpretability_score_mean_max": 8.454471678733826
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.60231954574585,
                "independent_score_mean_max": -41.51740005970001,
                "interpretability_score_mean_max": -39.49713990688324
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.042788997082414015,
          "cebench_delta": -39.49713990688324,
          "cebench_interpretability_max": 8.454471678733826,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.7847983663458734,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.8595102028608211,
              "cebench": 0.0,
              "alignment": 1.0,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt",
          "alignment_to_ref": 0.9838663339614868,
          "explained_variance": -2.6448638439178467,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:13:24+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "8592e3a38b3a1966363df9923197d64e90a0efbe710893cd34a347a2ec326361",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6140367022782678,
                    "test_auc": 0.6193655476308826,
                    "test_f1": 0.5876936801649649
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6161735978760723,
                    "test_auc": 0.6251952759332265,
                    "test_f1": 0.588112954146787
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6180647047436452,
                    "test_auc": 0.6415969722738214,
                    "test_f1": 0.5977376812346283
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6180647047436452,
                  "test_auc": 0.6415969722738214,
                  "test_f1": 0.5977376812346283
                },
                "best_minus_llm_auc": -0.051219494120893105
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:15:43+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "b7dd1da5a59b495c44334275d54c9971a922c158fd1ffc5b025809013edfa10c",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "738d461950cf5bc7e9f03aa8b742219c7b7ca3cffe73412d5440e34e64ed9f92",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.08_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.337759158611298,
                "independent_score_mean_max": 9.598845899105072,
                "interpretability_score_mean_max": 8.727591137886048,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:15:43",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.337759158611298,
                "independent_score_mean_max": 9.598845899105072,
                "interpretability_score_mean_max": 8.727591137886048
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.17354827165604,
                "independent_score_mean_max": -41.40042044878006,
                "interpretability_score_mean_max": -39.22402044773102
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.051219494120893105,
          "cebench_delta": -39.22402044773102,
          "cebench_interpretability_max": 8.727591137886048,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.10485380968491168,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.8576679682131508,
              "alignment": 0.4770622895622896,
              "explained_variance": 0.00011303202762502755
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
        "candidate_tag": "seed123",
        "saebench": {
          "timestamp_utc": "2026-02-18T02:10:32+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "fdd61c4458ceae892036a5c54a408067476096b976b563f4734a6b3715179334",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6128424980210215,
                "test_auc": 0.6205806044507268,
                "test_f1": 0.5959745774473204
              },
              {
                "k": 2,
                "test_accuracy": 0.6170747715145863,
                "test_auc": 0.6283252501789226,
                "test_f1": 0.60026776545585
              },
              {
                "k": 5,
                "test_accuracy": 0.6318974173392169,
                "test_auc": 0.6514054620513933,
                "test_f1": 0.614888519402617
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6318974173392169,
              "test_auc": 0.6514054620513933,
              "test_f1": 0.614888519402617
            },
            "best_minus_llm_auc": -0.041411004343321234
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T02:12:51+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.08_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "a94c560d79a26a6af16a3b001da2b94215c98db944a47bd0a65149d01c4ae989",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.08/sae_seed123.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "e77898e809d3a19d0af3d53cb90609879eef6488ebde9107a24d288a3f35523d",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.08_seed123/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 9.373173317909242,
            "independent_score_mean_max": 9.58368507862091,
            "interpretability_score_mean_max": 8.772915959358215,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.08_seed123",
            "sae_id": "custom_sae",
            "date": "2026-02-18 02:12:51",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 9.373173317909242,
            "independent_score_mean_max": 9.58368507862091,
            "interpretability_score_mean_max": 8.772915959358215
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.138134112358095,
            "independent_score_mean_max": -41.41558126926422,
            "interpretability_score_mean_max": -39.17869562625885
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.08/seed123/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8107100543566048,
        "ev_drop": 0.8500874519348143,
        "ev_neg_drop": -0.8500874519348143,
        "saebench_delta": -0.041411004343321234,
        "cebench_delta": -39.17869562625885,
        "cebench_interpretability_max": 8.772915959358215
      },
      "selection": {
        "joint_score": 0.6580321431949383,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    },
    {
      "lambda_consistency": 0.04,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9545239537954331,
        "std": 0.013875252132609919,
        "min": 0.9430154263973236,
        "max": 0.9710472226142883,
        "median": 0.9444089233875275,
        "ci95_low": 0.9464572265744209,
        "ci95_high": 0.9626533912122249,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.7951417222619057,
      "delta_pwmcc_ci_low_conservative": 0.7869569937326013,
      "ratio_pwmcc": 5.988898163937685,
      "explained_variance": {
        "mean": -2.2060025691986085,
        "std": 0.3498881411418583,
        "min": -2.382702589035034,
        "max": -1.580458402633667,
        "median": -2.3553390502929688,
        "ci95_low": -2.371536064147949,
        "ci95_high": -1.8907987117767333,
        "n": 5
      },
      "mse": {
        "mean": 0.002659630076959729,
        "std": 0.0002902619370049403,
        "min": 0.0021406884770840406,
        "max": 0.0028062264900654554,
        "median": 0.00278349663130939,
        "ci95_low": 0.0023979608435183764,
        "ci95_high": 0.002796950750052929,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9706359058618546,
        "std": 0.00041085226516615435,
        "min": 0.9702154397964478,
        "max": 0.9710472226142883,
        "median": 0.9706404805183411,
        "ci95_low": 0.9702863693237305,
        "ci95_high": 0.9709854423999786,
        "n": 4
      },
      "runtime_sec": 269.3000237941742,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
          "lambda_consistency": 0.04,
          "alignment_to_ref": 0.970923662185669,
          "mse": 0.0027825776487588882,
          "explained_variance": -2.354233503341675,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9027743291592708,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8109846128909677,
          "supervised_proxy_accuracy_eval": 0.24257507920265198,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt",
          "lambda_consistency": 0.04,
          "alignment_to_ref": 0.9710472226142883,
          "mse": 0.0027851611375808716,
          "explained_variance": -2.3572793006896973,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9024880815262871,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8129605129361153,
          "supervised_proxy_accuracy_eval": 0.24215853214263916,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt",
          "lambda_consistency": 0.04,
          "alignment_to_ref": 0.9703572988510132,
          "mse": 0.0028062264900654554,
          "explained_variance": -2.382702589035034,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9022240903642442,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.812351369195514,
          "supervised_proxy_accuracy_eval": 0.2431790679693222,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt",
          "lambda_consistency": 0.04,
          "alignment_to_ref": 0.9702154397964478,
          "mse": 0.00278349663130939,
          "explained_variance": -2.3553390502929688,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9013843169884274,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.810880299795557,
          "supervised_proxy_accuracy_eval": 0.24277640879154205,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.970923662185669,
        0.9710472226142883,
        0.9703572988510132,
        0.9702154695987701,
        0.9446422457695007,
        0.9436520338058472,
        0.9435916841030121,
        0.9441756010055542,
        0.943618893623352,
        0.9430154263973236
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
      "selected_checkpoint_seed": 123,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
          "alignment_to_ref": 0.970923662185669,
          "explained_variance": -2.354233503341675,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:47:37+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "48f91575a35b364341944e1515d9337cb1dbda85d9047b2fbf372511ae882494",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6146857625588232,
                    "test_auc": 0.6204569909261866,
                    "test_f1": 0.5895111258745126
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6248548346293367,
                    "test_auc": 0.6381960728564616,
                    "test_f1": 0.6040005402332591
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6277629996730051,
                    "test_auc": 0.6474857911964319,
                    "test_f1": 0.6084575154962668
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6277629996730051,
                  "test_auc": 0.6474857911964319,
                  "test_f1": 0.6084575154962668
                },
                "best_minus_llm_auc": -0.0453306751982826
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:49:56+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "20dd2d66de887e01e9abab7a7c66e346c72d8af99f7b0c434d6207ec66e458a4",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "456f8a0340751ae227dd0577967f5adfa34f1e906b4b9ec7fc9e5eebe523be25",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.04_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.344703226089477,
                "independent_score_mean_max": 9.525979993343354,
                "interpretability_score_mean_max": 8.744984805583954,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:49:56",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.344703226089477,
                "independent_score_mean_max": 9.525979993343354,
                "interpretability_score_mean_max": 8.744984805583954
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.16660420417786,
                "independent_score_mean_max": -41.47328635454178,
                "interpretability_score_mean_max": -39.20662678003311
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.0453306751982826,
          "cebench_delta": -39.20662678003311,
          "cebench_interpretability_max": 8.744984805583954,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9940580437119312,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 1.0,
              "alignment": 0.8514510927982802,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt",
          "alignment_to_ref": 0.9702154397964478,
          "explained_variance": -2.3553390502929688,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:53:20+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "a5f14c447f5126bd97d6ed5e862686e2eea4ebf7750f525b1161170d98213cd4",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6083871776451527,
                    "test_auc": 0.6125943116732853,
                    "test_f1": 0.5682157176288499
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6147171759871368,
                    "test_auc": 0.6267843826401306,
                    "test_f1": 0.5850996670594092
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6304372506547544,
                    "test_auc": 0.6452609426235408,
                    "test_f1": 0.611727303826725
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6304372506547544,
                  "test_auc": 0.6452609426235408,
                  "test_f1": 0.611727303826725
                },
                "best_minus_llm_auc": -0.04755552377117367
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:55:39+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "aee5f07065dc17f05f265f16db6f4ab2c4fe95bf8ef03da6f4a128bb7a5f74fb",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "5928420557585e19053e1b8859289128a1ec4034557050921e7503485c5664a5",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.094920408725738,
                "independent_score_mean_max": 9.751197476387023,
                "interpretability_score_mean_max": 8.47542240381241,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:55:39",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.094920408725738,
                "independent_score_mean_max": 9.751197476387023,
                "interpretability_score_mean_max": 8.47542240381241
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.416387021541595,
                "independent_score_mean_max": -41.248068871498106,
                "interpretability_score_mean_max": -39.476189181804656
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04755552377117367,
          "cebench_delta": -39.476189181804656,
          "cebench_interpretability_max": 8.47542240381241,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6451790010366498,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.6961888304841599,
              "cebench": 0.35857489799788705,
              "alignment": 0.0,
              "explained_variance": 0.9611667559962481
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt",
          "alignment_to_ref": 0.9703572988510132,
          "explained_variance": -2.382702589035034,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:50:29+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "47e4788e9babed3f9e1dbbcf33c16e7569d6fd46a299b7affbe8716f20902386",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6111614662553402,
                    "test_auc": 0.6163508920121484,
                    "test_f1": 0.5824876470857958
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6109982958814504,
                    "test_auc": 0.6244914730316864,
                    "test_f1": 0.5836271344307097
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6196722292231289,
                    "test_auc": 0.6435047653693398,
                    "test_f1": 0.5957830570252136
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6196722292231289,
                  "test_auc": 0.6435047653693398,
                  "test_f1": 0.5957830570252136
                },
                "best_minus_llm_auc": -0.04931170102537474
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:52:47+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "61ce832f9fbcde1269a369dbf8f6acbc7dd4f0bf405651b1780daa4caf6142ef",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "8033c23af26918c23da69a8dc767c4a0dba6ce63e89dbafe8237373c1ea17f2f",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.04_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.795378754138946,
                "independent_score_mean_max": 9.445503854751587,
                "interpretability_score_mean_max": 8.324729344844819,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:52:47",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.795378754138946,
                "independent_score_mean_max": 9.445503854751587,
                "interpretability_score_mean_max": 8.324729344844819
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.71592867612839,
                "independent_score_mean_max": -41.55376249313355,
                "interpretability_score_mean_max": -39.62688224077225
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04931170102537474,
          "cebench_delta": -39.62688224077225,
          "cebench_interpretability_max": 8.324729344844819,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.38105060446403716,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.45637643517015836,
              "cebench": 0.0,
              "alignment": 0.17054819061268361,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt",
          "alignment_to_ref": 0.9710472226142883,
          "explained_variance": -2.3572793006896973,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:44:43+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "38813e75ddb69db7062feb49ccf189853eafaf1a085662a346541e03462600ee",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.611097792433858,
                    "test_auc": 0.61463131202268,
                    "test_f1": 0.5903357252599749
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6121689491708484,
                    "test_auc": 0.6198665277563611,
                    "test_f1": 0.5894566907587226
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6255122302929822,
                    "test_auc": 0.6401626615812942,
                    "test_f1": 0.6083836575169431
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6255122302929822,
                  "test_auc": 0.6401626615812942,
                  "test_f1": 0.6083836575169431
                },
                "best_minus_llm_auc": -0.0526538048134203
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:47:03+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "3bb7b359ef9951bd112024b04360aa574daa69651e0ad2c93a7eb7be4afb88aa",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "5b471f4e1c5f7e2adffaf03a23ee1be6fa480a48e45b00baf742ad14748ff72d",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.04_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.917762355804443,
                "independent_score_mean_max": 9.434153938293457,
                "interpretability_score_mean_max": 8.407541389465331,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:47:03",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.917762355804443,
                "independent_score_mean_max": 9.434153938293457,
                "interpretability_score_mean_max": 8.407541389465331
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.593545074462895,
                "independent_score_mean_max": -41.56511240959168,
                "interpretability_score_mean_max": -39.544070196151736
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.0526538048134203,
          "cebench_delta": -39.544070196151736,
          "cebench_interpretability_max": 8.407541389465331,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.09542572274923866,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.19705168012537597,
              "alignment": 1.0,
              "explained_variance": 0.8930138684175265
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
        "candidate_tag": "seed123",
        "saebench": {
          "timestamp_utc": "2026-02-18T01:47:37+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "48f91575a35b364341944e1515d9337cb1dbda85d9047b2fbf372511ae882494",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6146857625588232,
                "test_auc": 0.6204569909261866,
                "test_f1": 0.5895111258745126
              },
              {
                "k": 2,
                "test_accuracy": 0.6248548346293367,
                "test_auc": 0.6381960728564616,
                "test_f1": 0.6040005402332591
              },
              {
                "k": 5,
                "test_accuracy": 0.6277629996730051,
                "test_auc": 0.6474857911964319,
                "test_f1": 0.6084575154962668
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6277629996730051,
              "test_auc": 0.6474857911964319,
              "test_f1": 0.6084575154962668
            },
            "best_minus_llm_auc": -0.0453306751982826
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T01:49:56+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.04_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "20dd2d66de887e01e9abab7a7c66e346c72d8af99f7b0c434d6207ec66e458a4",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.04/sae_seed123.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "456f8a0340751ae227dd0577967f5adfa34f1e906b4b9ec7fc9e5eebe523be25",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.04_seed123/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 9.344703226089477,
            "independent_score_mean_max": 9.525979993343354,
            "interpretability_score_mean_max": 8.744984805583954,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.04_seed123",
            "sae_id": "custom_sae",
            "date": "2026-02-18 01:49:56",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 9.344703226089477,
            "independent_score_mean_max": 9.525979993343354,
            "interpretability_score_mean_max": 8.744984805583954
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.16660420417786,
            "independent_score_mean_max": -41.47328635454178,
            "interpretability_score_mean_max": -39.20662678003311
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.04/seed123/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.7869569937326013,
        "ev_drop": 0.6369025707244873,
        "ev_neg_drop": -0.6369025707244873,
        "saebench_delta": -0.0453306751982826,
        "cebench_delta": -39.20662678003311,
        "cebench_interpretability_max": 8.744984805583954
      },
      "selection": {
        "joint_score": 0.49141810720430446,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    },
    {
      "lambda_consistency": 0.06,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9681186109781266,
        "std": 0.009838954662492403,
        "min": 0.9601444900035858,
        "max": 0.9797812402248383,
        "median": 0.9608248621225357,
        "ci95_low": 0.9623981320112943,
        "ci95_high": 0.9738675156235694,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.8087363794445992,
      "delta_pwmcc_ci_low_conservative": 0.8028978991694748,
      "ratio_pwmcc": 6.074194103465509,
      "explained_variance": {
        "mean": -2.329409646987915,
        "std": 0.4187447785603769,
        "min": -2.52327299118042,
        "max": -1.580458402633667,
        "median": -2.518995761871338,
        "ci95_low": -2.521308708190918,
        "ci95_high": -1.953693675994873,
        "n": 5
      },
      "mse": {
        "mean": 0.002762017771601677,
        "std": 0.0003473902750689829,
        "min": 0.0021406884770840406,
        "max": 0.0029228038620203733,
        "median": 0.0029193018563091755,
        "ci95_low": 0.0024503146298229693,
        "ci95_high": 0.002921218238770962,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9795472472906113,
        "std": 0.0001880140151201936,
        "min": 0.979352593421936,
        "max": 0.9797812700271606,
        "median": 0.9795275628566742,
        "ci95_low": 0.9794003665447235,
        "ci95_high": 0.9796979874372482,
        "n": 4
      },
      "runtime_sec": 268.9666953086853,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
          "lambda_consistency": 0.06,
          "alignment_to_ref": 0.9796069860458374,
          "mse": 0.0029205908067524433,
          "explained_variance": -2.520500898361206,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9097435071167571,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.812829249435001,
          "supervised_proxy_accuracy_eval": 0.24256813526153564,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt",
          "lambda_consistency": 0.06,
          "alignment_to_ref": 0.9797812700271606,
          "mse": 0.002906703855842352,
          "explained_variance": -2.5038201808929443,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9097489164279843,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8153301408445395,
          "supervised_proxy_accuracy_eval": 0.24207521975040436,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt",
          "lambda_consistency": 0.06,
          "alignment_to_ref": 0.979448139667511,
          "mse": 0.0029228038620203733,
          "explained_variance": -2.52327299118042,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9096436232190441,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8148281574249268,
          "supervised_proxy_accuracy_eval": 0.24182529747486115,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt",
          "lambda_consistency": 0.06,
          "alignment_to_ref": 0.979352593421936,
          "mse": 0.0029193018563091755,
          "explained_variance": -2.518995761871338,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.9091199791334845,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.8131889860939094,
          "supervised_proxy_accuracy_eval": 0.24274864792823792,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.979606956243515,
        0.9797812402248383,
        0.979448139667511,
        0.9793526232242584,
        0.9608666002750397,
        0.9604319036006927,
        0.9603134095668793,
        0.9607831239700317,
        0.9604576230049133,
        0.9601444900035858
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
      "selected_checkpoint_seed": 123,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
          "alignment_to_ref": 0.9796069860458374,
          "explained_variance": -2.520500898361206,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:59:01+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "1552d9a1971ecf45d4097317e2acf36feb378b5833ed3fb35d6d7de5136a7242",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.61076241259786,
                    "test_auc": 0.6192862990943566,
                    "test_f1": 0.5870402719274258
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6179064471544655,
                    "test_auc": 0.630808743734321,
                    "test_f1": 0.5973822557115149
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6235874590147227,
                    "test_auc": 0.6458201881628807,
                    "test_f1": 0.6035104425986537
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6235874590147227,
                  "test_auc": 0.6458201881628807,
                  "test_f1": 0.6035104425986537
                },
                "best_minus_llm_auc": -0.04699627823183383
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:01:21+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "cb57ba926c88ff2aa82149f75ac7d10b50ade76a43791f4314796cd4b9c68ce7",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "ffa38dd075098b784983a2a47415f8aaec1f77aea00f8d65393ca2e3b3c9f7c6",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.06_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.323262963294983,
                "independent_score_mean_max": 9.562152352333069,
                "interpretability_score_mean_max": 8.776485645771027,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:01:21",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.323262963294983,
                "independent_score_mean_max": 9.562152352333069,
                "interpretability_score_mean_max": 8.776485645771027
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.18804446697236,
                "independent_score_mean_max": -41.43711399555207,
                "interpretability_score_mean_max": -39.17512593984604
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04699627823183383,
          "cebench_delta": -39.17512593984604,
          "cebench_interpretability_max": 8.776485645771027,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9494376245913292,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 1.0,
              "alignment": 0.5934371523915462,
              "explained_variance": 0.14250346239168535
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt",
          "alignment_to_ref": 0.979448139667511,
          "explained_variance": -2.52327299118042,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:01:55+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "a7cdd629d2e2d545aee188a7bca75a99f5c60b3a6b7255c0cc050df7e47f37d2",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6093208201542288,
                    "test_auc": 0.6165606017089982,
                    "test_f1": 0.5806128648378149
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6173678296925773,
                    "test_auc": 0.6274434864562592,
                    "test_f1": 0.5882589810035678
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6184078786922815,
                    "test_auc": 0.6455708465147107,
                    "test_f1": 0.593947762209651
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6184078786922815,
                  "test_auc": 0.6455708465147107,
                  "test_f1": 0.593947762209651
                },
                "best_minus_llm_auc": -0.04724561988000375
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:04:13+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "ec69e07e80e52e2d29f3979b1611ee39519afd22ac3114e1c01ee2e2554741d0",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "a834c021912a17ea3fa9a7514f0ea76eb19ecb795f3d652a40a38a16ecf0df3e",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.06_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.306574618816375,
                "independent_score_mean_max": 9.626006660461426,
                "interpretability_score_mean_max": 8.73435683965683,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:04:13",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.306574618816375,
                "independent_score_mean_max": 9.626006660461426,
                "interpretability_score_mean_max": 8.73435683965683
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.20473281145096,
                "independent_score_mean_max": -41.373259687423705,
                "interpretability_score_mean_max": -39.21725474596023
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04724561988000375,
          "cebench_delta": -39.21725474596023,
          "cebench_interpretability_max": 8.73435683965683,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8860560367613738,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.9621726575052905,
              "cebench": 0.8815899598300908,
              "alignment": 0.2228865406006674,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt",
          "alignment_to_ref": 0.979352593421936,
          "explained_variance": -2.518995761871338,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T02:04:46+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "1ef94175a10e00c1f4ca0f17cc3d75f4917eca206d6fc44bee3f967002b9c3a6",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6121279219852305,
                    "test_auc": 0.616596364286113,
                    "test_f1": 0.5796602215545684
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6199687825338468,
                    "test_auc": 0.6299578455922862,
                    "test_f1": 0.597176245894299
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6261087658276124,
                    "test_auc": 0.6449032768370149,
                    "test_f1": 0.6043170151729031
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6261087658276124,
                  "test_auc": 0.6449032768370149,
                  "test_f1": 0.6043170151729031
                },
                "best_minus_llm_auc": -0.04791318955769963
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T02:07:06+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "c830f7240716f647cb77462598e14f771a2eb8c4bd09c677308a4f8ae643d4e6",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "0ebac0a93ed2490d0d4b82ac175b0818c84625975844bf8c6f92df659ff539fc",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.218267641067506,
                "independent_score_mean_max": 9.982866225242615,
                "interpretability_score_mean_max": 8.650985288619996,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 02:07:06",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.218267641067506,
                "independent_score_mean_max": 9.982866225242615,
                "interpretability_score_mean_max": 8.650985288619996
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.29303978919983,
                "independent_score_mean_max": -41.016400122642516,
                "interpretability_score_mean_max": -39.300626296997066
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04791318955769963,
          "cebench_delta": -39.300626296997066,
          "cebench_interpretability_max": 8.650985288619996,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.7794561729306902,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.8608964085407534,
              "cebench": 0.6472603023377689,
              "alignment": 0.0,
              "explained_variance": 0.21987719233739014
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt",
          "alignment_to_ref": 0.9797812700271606,
          "explained_variance": -2.5038201808929443,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:56:13+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "68510c1ed57c27ba91e30ee959c0f4fd6f7ab3f73225788ab8ef96d1eb647b72",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6182205159505856,
                    "test_auc": 0.6223844212885853,
                    "test_f1": 0.5968479814492081
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6187410749718603,
                    "test_auc": 0.6264093828065349,
                    "test_f1": 0.5957431482007058
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6271955407564472,
                    "test_auc": 0.6392286162541537,
                    "test_f1": 0.6094174026510344
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6271955407564472,
                  "test_auc": 0.6392286162541537,
                  "test_f1": 0.6094174026510344
                },
                "best_minus_llm_auc": -0.05358785014056078
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:58:28+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "4759dcda1efebf4a2f6e7fca64d4e78b6df9f5b4031d8d835496b2f6d131106e",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "396b40cf2277759332258975eff0afa91c61cc81bddbf811ae8f188448f6ceaa",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.06_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.87888109445572,
                "independent_score_mean_max": 9.479971313476563,
                "interpretability_score_mean_max": 8.42069819688797,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:58:28",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.87888109445572,
                "independent_score_mean_max": 9.479971313476563,
                "interpretability_score_mean_max": 8.42069819688797
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.632426335811616,
                "independent_score_mean_max": -41.51929503440857,
                "interpretability_score_mean_max": -39.5309133887291
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.05358785014056078,
          "cebench_delta": -39.5309133887291,
          "cebench_interpretability_max": 8.42069819688797,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.08,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.0,
              "alignment": 1.0,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
        "candidate_tag": "seed123",
        "saebench": {
          "timestamp_utc": "2026-02-18T01:59:01+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "1552d9a1971ecf45d4097317e2acf36feb378b5833ed3fb35d6d7de5136a7242",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.61076241259786,
                "test_auc": 0.6192862990943566,
                "test_f1": 0.5870402719274258
              },
              {
                "k": 2,
                "test_accuracy": 0.6179064471544655,
                "test_auc": 0.630808743734321,
                "test_f1": 0.5973822557115149
              },
              {
                "k": 5,
                "test_accuracy": 0.6235874590147227,
                "test_auc": 0.6458201881628807,
                "test_f1": 0.6035104425986537
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6235874590147227,
              "test_auc": 0.6458201881628807,
              "test_f1": 0.6035104425986537
            },
            "best_minus_llm_auc": -0.04699627823183383
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T02:01:21+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.06_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "cb57ba926c88ff2aa82149f75ac7d10b50ade76a43791f4314796cd4b9c68ce7",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.06/sae_seed123.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "ffa38dd075098b784983a2a47415f8aaec1f77aea00f8d65393ca2e3b3c9f7c6",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.06_seed123/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 9.323262963294983,
            "independent_score_mean_max": 9.562152352333069,
            "interpretability_score_mean_max": 8.776485645771027,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.06_seed123",
            "sae_id": "custom_sae",
            "date": "2026-02-18 02:01:21",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 9.323262963294983,
            "independent_score_mean_max": 9.562152352333069,
            "interpretability_score_mean_max": 8.776485645771027
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.18804446697236,
            "independent_score_mean_max": -41.43711399555207,
            "interpretability_score_mean_max": -39.17512593984604
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.06/seed123/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.8028978991694748,
        "ev_drop": 0.7603096485137937,
        "ev_neg_drop": -0.7603096485137937,
        "saebench_delta": -0.04699627823183383,
        "cebench_delta": -39.17512593984604,
        "cebench_interpretability_max": 8.776485645771027
      },
      "selection": {
        "joint_score": 0.4328521991514872,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    },
    {
      "lambda_consistency": 0.0,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.1639976441860199,
        "std": 0.00031743714213769815,
        "min": 0.1636180281639099,
        "max": 0.16453917324543,
        "median": 0.16395213454961777,
        "ci95_low": 0.1638154529593885,
        "ci95_high": 0.1641866184026003,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.004615412652492518,
      "delta_pwmcc_ci_low_conservative": 0.004315220117568991,
      "ratio_pwmcc": 1.0289581379811565,
      "explained_variance": {
        "mean": -1.5690999984741212,
        "std": 0.01972055792502961,
        "min": -1.5908684730529785,
        "max": -1.5404713153839111,
        "median": -1.574693202972412,
        "ci95_low": -1.5834693908691406,
        "ci95_high": -1.5521761894226074,
        "n": 5
      },
      "mse": {
        "mean": 0.0021312625613063574,
        "std": 1.6371495174561724e-05,
        "min": 0.002107499400153756,
        "max": 0.0021493355743587017,
        "median": 0.002135912189260125,
        "ci95_low": 0.0021172127686440944,
        "ci95_high": 0.002143192058429122,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.15734173730015755,
        "std": 0.0002745345560657119,
        "min": 0.1571110486984253,
        "max": 0.15770940482616425,
        "median": 0.15727324783802032,
        "ci95_low": 0.15713264048099518,
        "ci95_high": 0.15757061168551445,
        "n": 4
      },
      "runtime_sec": 187.082337141037,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.15739226341247559,
          "mse": 0.0021228771656751633,
          "explained_variance": -1.5590085983276367,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.791447404358122,
          "supervised_proxy_accuracy_eval": 0.24927452206611633,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.1571110486984253,
          "mse": 0.002107499400153756,
          "explained_variance": -1.5404713153839111,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.7927430832275637,
          "supervised_proxy_accuracy_eval": 0.24942030012607574,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.15770940482616425,
          "mse": 0.002135912189260125,
          "explained_variance": -1.574693202972412,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.791701413139149,
          "supervised_proxy_accuracy_eval": 0.24978825449943542,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 0.15715423226356506,
          "mse": 0.0021493355743587017,
          "explained_variance": -1.5908684730529785,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.791906225460547,
          "supervised_proxy_accuracy_eval": 0.2493925392627716,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.1638329178094864,
        0.1636180281639099,
        0.16430993378162384,
        0.16385231167078018,
        0.16425057500600815,
        0.16453917324543,
        0.16370029747486115,
        0.16405195742845535,
        0.164187453687191,
        0.163633793592453
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
      "selected_checkpoint_seed": 123,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
          "alignment_to_ref": 0.15739226341247559,
          "explained_variance": -1.5590085983276367,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:23:57+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "9257b944016719b7d6711961097ba7d5e0a826f11868c62ee621767907b0b93e",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6095639466639499,
                    "test_auc": 0.613725945597959,
                    "test_f1": 0.5715989710586425
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6191709406629907,
                    "test_auc": 0.637182756585181,
                    "test_f1": 0.5903520686254913
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6326485670979377,
                    "test_auc": 0.6503870215344647,
                    "test_f1": 0.6081474084577569
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6326485670979377,
                  "test_auc": 0.6503870215344647,
                  "test_f1": 0.6081474084577569
                },
                "best_minus_llm_auc": -0.0424294448602498
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:26:24+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "0291c26bd4a586a301f79711d9275ad7fae3be2bc574e0944e1584a5b1086234",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "0e5e0c58629761ae3d6d84d3af9509cb03ad019760c360741f8d698f082e2c10",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.0_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.021288571357728,
                "independent_score_mean_max": 9.214037716388702,
                "interpretability_score_mean_max": 8.566019394397735,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:26:24",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.021288571357728,
                "independent_score_mean_max": 9.214037716388702,
                "interpretability_score_mean_max": 8.566019394397735
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.49001885890961,
                "independent_score_mean_max": -41.78522863149643,
                "interpretability_score_mean_max": -39.38559219121933
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.0424294448602498,
          "cebench_delta": -39.38559219121933,
          "cebench_interpretability_max": 8.566019394397735,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.9382642792095021,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.7417808499290421,
              "alignment": 0.46997883202589963,
              "explained_variance": 0.6321760233890463
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt",
          "alignment_to_ref": 0.15770940482616425,
          "explained_variance": -1.574693202972412,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:19:44+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "38f8b1b9ee01b955240e5e010b05a34af09a2dd994ced6403f467785b41e36a1",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6158911174233761,
                    "test_auc": 0.6239583527794297,
                    "test_f1": 0.5888470688358332
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6184968313845628,
                    "test_auc": 0.6329032346480699,
                    "test_f1": 0.593792981172296
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6336536681132151,
                    "test_auc": 0.6474125626919695,
                    "test_f1": 0.6164575437282069
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6336536681132151,
                  "test_auc": 0.6474125626919695,
                  "test_f1": 0.6164575437282069
                },
                "best_minus_llm_auc": -0.04540390370274505
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:23:22+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "7b04d5f47dc2f1a39ab939ec5e646cf732df2f2e1f6ff3b4a942a9d44893df3d",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "ffae5c067f32a391900a401f3bf6b3832fba3a1dcc75b27059c4294160a94423",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.0_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.480449571609498,
                "independent_score_mean_max": 9.384900243282319,
                "interpretability_score_mean_max": 8.152732031345368,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:23:21",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.480449571609498,
                "independent_score_mean_max": 9.384900243282319,
                "interpretability_score_mean_max": 8.152732031345368
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -42.03085785865784,
                "independent_score_mean_max": -41.614366104602816,
                "interpretability_score_mean_max": -39.7988795542717
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04540390370274505,
          "cebench_delta": -39.7988795542717,
          "cebench_interpretability_max": 8.152732031345368,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6726408245731844,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.7558568105095648,
              "cebench": 0.0,
              "alignment": 1.0,
              "explained_variance": 0.3209559988835326
            }
          }
        },
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt",
          "alignment_to_ref": 0.15715423226356506,
          "explained_variance": -1.5908684730529785,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:26:59+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "39dee9b69d498b157e1431a1d65759e909de242aeed688060c7c9f6dc7b173c7",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6080592329131207,
                    "test_auc": 0.6107044843836973,
                    "test_f1": 0.5703834278935486
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6187726119813808,
                    "test_auc": 0.6283164334467757,
                    "test_f1": 0.594458324057106
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6240938620263734,
                    "test_auc": 0.6466313721281483,
                    "test_f1": 0.5918920671930044
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6240938620263734,
                  "test_auc": 0.6466313721281483,
                  "test_f1": 0.5918920671930044
                },
                "best_minus_llm_auc": -0.04618509426656625
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:29:30+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "1adebf7cbfefd34764bc9a3ae1fcc661c25ad3352b97d3b83ca4471fc80b2355",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "5b8bfcd586d6855945fd277b09d690907924cd724898905764e8b3bfb6c8da1b",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.043372192382812,
                "independent_score_mean_max": 9.96780168056488,
                "interpretability_score_mean_max": 8.709887642860412,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:29:30",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.043372192382812,
                "independent_score_mean_max": 9.96780168056488,
                "interpretability_score_mean_max": 8.709887642860412
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.467935237884525,
                "independent_score_mean_max": -41.03146466732025,
                "interpretability_score_mean_max": -39.24172394275665
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04618509426656625,
          "cebench_delta": -39.24172394275665,
          "cebench_interpretability_max": 8.709887642860412,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.6701109830884754,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.6917367920623964,
              "cebench": 1.0,
              "alignment": 0.07217033993276055,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt",
          "alignment_to_ref": 0.1571110486984253,
          "explained_variance": -1.5404713153839111,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:30:08+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "51ff97700d0a63663e3fe8abe3750a72df1bdba04e7d305403fde524389db1d4",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6134250718608376,
                    "test_auc": 0.6185233752075329,
                    "test_f1": 0.5881539110179038
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6130454144004632,
                    "test_auc": 0.6286125726786732,
                    "test_f1": 0.5788946870308778
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6194074983307263,
                    "test_auc": 0.6382037660903812,
                    "test_f1": 0.5873725860211302
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6194074983307263,
                  "test_auc": 0.6382037660903812,
                  "test_f1": 0.5873725860211302
                },
                "best_minus_llm_auc": -0.054612700304333295
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:32:34+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "83efb68178352d726429b1e0d3111910710ffc1e29ed6b2689d18d27280cfaa1",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "eab7ecb162bd0287c3971faf1bb062870edeea512789601307fe004374056347",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.0_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.945289239883422,
                "independent_score_mean_max": 9.859105889797211,
                "interpretability_score_mean_max": 8.491308145523071,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:32:34",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.945289239883422,
                "independent_score_mean_max": 9.859105889797211,
                "interpretability_score_mean_max": 8.491308145523071
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.566018190383915,
                "independent_score_mean_max": -41.14016045808792,
                "interpretability_score_mean_max": -39.460303440093995
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.054612700304333295,
          "cebench_delta": -39.460303440093995,
          "cebench_interpretability_max": 8.491308145523071,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.10076868063071812,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.6076868063071812,
              "alignment": 0.0,
              "explained_variance": 1.0
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
        "candidate_tag": "seed123",
        "saebench": {
          "timestamp_utc": "2026-02-18T01:23:57+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "9257b944016719b7d6711961097ba7d5e0a826f11868c62ee621767907b0b93e",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6095639466639499,
                "test_auc": 0.613725945597959,
                "test_f1": 0.5715989710586425
              },
              {
                "k": 2,
                "test_accuracy": 0.6191709406629907,
                "test_auc": 0.637182756585181,
                "test_f1": 0.5903520686254913
              },
              {
                "k": 5,
                "test_accuracy": 0.6326485670979377,
                "test_auc": 0.6503870215344647,
                "test_f1": 0.6081474084577569
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6326485670979377,
              "test_auc": 0.6503870215344647,
              "test_f1": 0.6081474084577569
            },
            "best_minus_llm_auc": -0.0424294448602498
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T01:26:24+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.0_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "0291c26bd4a586a301f79711d9275ad7fae3be2bc574e0944e1584a5b1086234",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.0/sae_seed123.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "0e5e0c58629761ae3d6d84d3af9509cb03ad019760c360741f8d698f082e2c10",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.0_seed123/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 9.021288571357728,
            "independent_score_mean_max": 9.214037716388702,
            "interpretability_score_mean_max": 8.566019394397735,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.0_seed123",
            "sae_id": "custom_sae",
            "date": "2026-02-18 01:26:24",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 9.021288571357728,
            "independent_score_mean_max": 9.214037716388702,
            "interpretability_score_mean_max": 8.566019394397735
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.49001885890961,
            "independent_score_mean_max": -41.78522863149643,
            "interpretability_score_mean_max": -39.38559219121933
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.0/seed123/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.004315220117568991,
        "ev_drop": 0.0,
        "ev_neg_drop": -0.0,
        "saebench_delta": -0.0424294448602498,
        "cebench_delta": -39.38559219121933,
        "cebench_interpretability_max": 8.566019394397735
      },
      "selection": {
        "joint_score": 0.3830015368682677,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    },
    {
      "lambda_consistency": 0.02,
      "d_sae": 2048,
      "k": 48,
      "n_models": 5,
      "seed_ref": 42,
      "train_seeds": [
        123,
        456,
        789,
        1011
      ],
      "trained_pwmcc": {
        "mean": 0.9154020756483078,
        "std": 0.025309991871390825,
        "min": 0.8939613997936249,
        "max": 0.9465415179729462,
        "median": 0.8970813900232315,
        "ci95_low": 0.9006726033240557,
        "ci95_high": 0.9302934140712023,
        "n": 10
      },
      "random_pwmcc": {
        "mean": 0.15938223153352737,
        "std": 0.00020371875871998027,
        "min": 0.15904445201158524,
        "max": 0.1597208008170128,
        "median": 0.15935933962464333,
        "ci95_low": 0.15926027780398724,
        "ci95_high": 0.15950023284181952,
        "n": 10
      },
      "delta_pwmcc": 0.7560198441147804,
      "delta_pwmcc_ci_low_conservative": 0.7411723704822362,
      "ratio_pwmcc": 5.743438693514247,
      "explained_variance": {
        "mean": -2.0178246974945067,
        "std": 0.24481421368811002,
        "min": -2.1441211700439453,
        "max": -1.580458402633667,
        "median": -2.1178841590881348,
        "ci95_low": -2.1358046531677246,
        "ci95_high": -1.7986218452453613,
        "n": 5
      },
      "mse": {
        "mean": 0.0025035038124769926,
        "std": 0.00020308462193059258,
        "min": 0.0021406884770840406,
        "max": 0.0026082710828632116,
        "median": 0.0025865095667541027,
        "ci95_low": 0.002320823073387146,
        "ci95_high": 0.0026013726368546487,
        "n": 5
      },
      "alignment_to_ref": {
        "mean": 0.9447744190692902,
        "std": 0.0013084077911017149,
        "min": 0.9435033798217773,
        "max": 0.9465415477752686,
        "median": 0.9445263743400574,
        "ci95_low": 0.9438296556472778,
        "ci95_high": 0.945945143699646,
        "n": 4
      },
      "runtime_sec": 268.68646478652954,
      "per_seed_metrics": [
        {
          "seed": 42,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed42.pt",
          "lambda_consistency": 0.0,
          "alignment_to_ref": 1.0,
          "mse": 0.0021406884770840406,
          "explained_variance": -1.580458402633667,
          "l0": 48.0,
          "assignment_alignment_mean_train": null,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 0,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.792019643993289,
          "supervised_proxy_accuracy_eval": 0.24938559532165527,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 123,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt",
          "lambda_consistency": 0.02,
          "alignment_to_ref": 0.9465415477752686,
          "mse": 0.0026082710828632116,
          "explained_variance": -2.1441211700439453,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.8829708685236121,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.806984913018015,
          "supervised_proxy_accuracy_eval": 0.24428291618824005,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 456,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt",
          "lambda_consistency": 0.02,
          "alignment_to_ref": 0.9448968172073364,
          "mse": 0.0025865095667541027,
          "explained_variance": -2.1178841590881348,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.8808948058048608,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.808379919440658,
          "supervised_proxy_accuracy_eval": 0.2445606142282486,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 789,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt",
          "lambda_consistency": 0.02,
          "alignment_to_ref": 0.9441559314727783,
          "mse": 0.002582294400781393,
          "explained_variance": -2.112809896469116,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.8815496075829422,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.808260926493892,
          "supervised_proxy_accuracy_eval": 0.2445397824048996,
          "supervised_proxy_num_classes": 80
        },
        {
          "seed": 1011,
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
          "lambda_consistency": 0.02,
          "alignment_to_ref": 0.9435033798217773,
          "mse": 0.002599755534902215,
          "explained_variance": -2.133849859237671,
          "l0": 48.0,
          "assignment_alignment_mean_train": 0.8799779883723844,
          "assignment_update_interval": 4,
          "assignment_hungarian_solves_train": 216,
          "train_steps": 864,
          "supervised_proxy_weight": 0.05,
          "supervised_proxy_loss_train": 2.806140339208974,
          "supervised_proxy_accuracy_eval": 0.24425514042377472,
          "supervised_proxy_num_classes": 80
        }
      ],
      "trained_pairwise_pwmcc_values": [
        0.9465415179729462,
        0.9448967576026917,
        0.9441559910774231,
        0.943503350019455,
        0.8977592885494232,
        0.8964034914970398,
        0.8961204886436462,
        0.8958680927753448,
        0.8948103785514832,
        0.8939613997936249
      ],
      "random_pairwise_pwmcc_values": [
        0.15957186371088028,
        0.1597208008170128,
        0.1593116819858551,
        0.15904445201158524,
        0.15939123928546906,
        0.15958896279335022,
        0.15914249420166016,
        0.15933214128017426,
        0.1593596339225769,
        0.15935904532670975
      ],
      "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
      "selected_checkpoint_seed": 1011,
      "selected_checkpoint_policy": "external_score",
      "external_candidate_evals": [
        {
          "seed": 1011,
          "candidate_tag": "seed1011",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
          "alignment_to_ref": 0.9435033798217773,
          "explained_variance": -2.133849859237671,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
            "candidate_tag": "seed1011",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:41:51+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "89c226380f3511f3ceb020051f106393eaa3819be62cbb679b6715cdbdbab1ee",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6066127580020733,
                    "test_auc": 0.6107881724887381,
                    "test_f1": 0.5726167192791645
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6139508276333686,
                    "test_auc": 0.6213140735358289,
                    "test_f1": 0.5897523618627115
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6292440448068571,
                    "test_auc": 0.6438836519134908,
                    "test_f1": 0.6100145438585959
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6292440448068571,
                  "test_auc": 0.6438836519134908,
                  "test_f1": 0.6100145438585959
                },
                "best_minus_llm_auc": -0.04893281448122366
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:44:10+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "a6e8948d969ac588ef09602b2067c0e13d8a99bdc75e0018b171c9fa682e51e3",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "8e2b1c288a298f73fcc5e0e4b8590b414c9734406ec74bcc014c88587d21a9d4",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.041743602752685,
                "independent_score_mean_max": 9.729872329235077,
                "interpretability_score_mean_max": 8.498405346870422,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:44:10",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.041743602752685,
                "independent_score_mean_max": 9.729872329235077,
                "interpretability_score_mean_max": 8.498405346870422
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.46956382751465,
                "independent_score_mean_max": -41.269394018650054,
                "interpretability_score_mean_max": -39.453206238746645
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04893281448122366,
          "cebench_delta": -39.453206238746645,
          "cebench_interpretability_max": 8.498405346870422,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8782350812219107,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.9858915633402866,
              "cebench": 0.5668244958707356,
              "alignment": 0.0,
              "explained_variance": 0.32803874239505365
            }
          }
        },
        {
          "seed": 789,
          "candidate_tag": "seed789",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt",
          "alignment_to_ref": 0.9441559314727783,
          "explained_variance": -2.112809896469116,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt",
            "candidate_tag": "seed789",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:38:59+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "4f61c2372b23c6819397f3324308921abc9394cf187f2c6956397884d2934f3e",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed789_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6164301740472958,
                    "test_auc": 0.6189447531222287,
                    "test_f1": 0.5802173923720336
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6211374955051561,
                    "test_auc": 0.6323487941504077,
                    "test_f1": 0.5905349037939289
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6208000524578717,
                    "test_auc": 0.644044479372317,
                    "test_f1": 0.5990724600859644
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6208000524578717,
                  "test_auc": 0.644044479372317,
                  "test_f1": 0.5990724600859644
                },
                "best_minus_llm_auc": -0.04877198702239749
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:41:19+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "a66b108aa44da4672be79b796974583a1d71831db97a807ad6e1a92cbbd81fd9",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed789.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "c518d144bc604c5f6b5f65a634994d0faf3d02d6840f437dd36d733798e123d1",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed789",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.02_seed789/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.74711392879486,
                "independent_score_mean_max": 9.405555453300476,
                "interpretability_score_mean_max": 8.29776478767395,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed789",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:41:19",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.74711392879486,
                "independent_score_mean_max": 9.405555453300476,
                "interpretability_score_mean_max": 8.29776478767395
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.76419350147248,
                "independent_score_mean_max": -41.59371089458466,
                "interpretability_score_mean_max": -39.65384679794312
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed789/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.04877198702239749,
          "cebench_delta": -39.65384679794312,
          "cebench_interpretability_max": 8.29776478767395,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8685913835046692,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 1.0,
              "cebench": 0.0,
              "alignment": 0.21478458761673075,
              "explained_variance": 1.0
            }
          }
        },
        {
          "seed": 123,
          "candidate_tag": "seed123",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt",
          "alignment_to_ref": 0.9465415477752686,
          "explained_variance": -2.1441211700439453,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt",
            "candidate_tag": "seed123",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:33:08+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "cc426ab7f12a9217f7db4ee601cbd6fbe19abd983ef9fa7fffddc1abc5a809d2",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed123_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6162019935830344,
                    "test_auc": 0.6199432689373412,
                    "test_f1": 0.5842961532193424
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6211300733157904,
                    "test_auc": 0.6380554320253848,
                    "test_f1": 0.5987463558363155
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6260852202172976,
                    "test_auc": 0.6422096255561176,
                    "test_f1": 0.6029368366203476
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6260852202172976,
                  "test_auc": 0.6422096255561176,
                  "test_f1": 0.6029368366203476
                },
                "best_minus_llm_auc": -0.0506068408385969
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:35:33+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "1a51837259096a4acdfb07df48563f5c68fa0ef5811c8ffed5e44324d2848d8b",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed123.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "1a750497966c2261094fcbbc1b0eecc7fd2d24e1e4e92e6654cc191007356735",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed123",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.02_seed123/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 9.296842222213746,
                "independent_score_mean_max": 9.369706768989563,
                "interpretability_score_mean_max": 8.651737773418427,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed123",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:35:33",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 9.296842222213746,
                "independent_score_mean_max": 9.369706768989563,
                "interpretability_score_mean_max": 8.651737773418427
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.21446520805359,
                "independent_score_mean_max": -41.62955957889557,
                "interpretability_score_mean_max": -39.29987381219864
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed123/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.0506068408385969,
          "cebench_delta": -39.29987381219864,
          "cebench_interpretability_max": 8.651737773418427,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.8280121317069195,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.8390391850084384,
              "cebench": 1.0,
              "alignment": 1.0,
              "explained_variance": 0.0
            }
          }
        },
        {
          "seed": 456,
          "candidate_tag": "seed456",
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt",
          "alignment_to_ref": 0.9448968172073364,
          "explained_variance": -2.1178841590881348,
          "external_eval": {
            "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt",
            "candidate_tag": "seed456",
            "saebench": {
              "timestamp_utc": "2026-02-18T01:36:07+00:00",
              "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
              "config": {
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt",
                "architecture_override": "topk",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "reg_type": "l1",
                "setting": "normal",
                "ks": [
                  1,
                  2,
                  5
                ],
                "dataset_names": [
                  "100_news_fake",
                  "105_click_bait",
                  "106_hate_hate",
                  "107_hate_offensive",
                  "110_aimade_humangpt3",
                  "113_movie_sent",
                  "114_nyc_borough_Manhattan",
                  "115_nyc_borough_Brooklyn",
                  "116_nyc_borough_Bronx",
                  "117_us_state_FL",
                  "118_us_state_CA",
                  "119_us_state_TX",
                  "120_us_timezone_Chicago",
                  "121_us_timezone_New_York",
                  "122_us_timezone_Los_Angeles",
                  "123_world_country_United_Kingdom"
                ],
                "dataset_names_inferred_from_cache": false,
                "dataset_count": 16,
                "binarize": false,
                "device": "cuda",
                "dtype": "float32",
                "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
                "model_cache_path": "/tmp/sae_bench_model_cache",
                "force_rerun": true
              },
              "config_hash": "bae70fede0570963a2bc7f84feeef726d5521a3541c2acf1e997d9ef2ed4e618",
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "summary": {
                "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed456_custom_sae",
                "llm_metrics": {
                  "llm_test_accuracy": 0.6605360072070458,
                  "llm_test_auc": 0.6928164663947145,
                  "llm_test_f1": 0.6491238078533221
                },
                "sae_metrics_by_k": [
                  {
                    "k": 1,
                    "test_accuracy": 0.6109195613778943,
                    "test_auc": 0.614928433559824,
                    "test_f1": 0.5865321377766118
                  },
                  {
                    "k": 2,
                    "test_accuracy": 0.6130554611053121,
                    "test_auc": 0.6221364904622736,
                    "test_f1": 0.5890425077562615
                  },
                  {
                    "k": 5,
                    "test_accuracy": 0.6192134282367925,
                    "test_auc": 0.6326450973780372,
                    "test_f1": 0.5965036409238097
                  }
                ],
                "best_by_auc": {
                  "k": 5,
                  "test_accuracy": 0.6192134282367925,
                  "test_auc": 0.6326450973780372,
                  "test_f1": 0.5965036409238097
                },
                "best_minus_llm_auc": -0.0601713690166773
              }
            },
            "cebench": {
              "timestamp_utc": "2026-02-18T01:38:26+00:00",
              "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
              "config_hash": "a1a1e35bec70a1c5905372dffdfd445a3b5b4f287827ffda99e784f135b06f85",
              "config": {
                "cebench_repo": "/workspace/CE-Bench",
                "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed456.pt",
                "architecture_override": "topk",
                "checkpoint_sha256": "ec8ea5eec33de59a953cf48bf6f0233b8b7488bdf1d030c355ec5be9a5db8bc1",
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed456",
                "model_name": "pythia-70m-deduped",
                "hook_layer": 0,
                "hook_name": "blocks.0.hook_resid_pre",
                "device": "cuda",
                "sae_dtype": "float32",
                "llm_batch_size": 512,
                "llm_dtype": "float32",
                "random_seed": 42,
                "dataset_name": "GulkoA/contrastive-stories-v4",
                "dataset_rows_total": 5000,
                "dataset_rows_used": 200,
                "max_rows": 200,
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench",
                "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
                "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
              },
              "sae_meta": {
                "architecture": "topk",
                "eval_architecture": "topk",
                "d_model": 512,
                "d_sae": 2048,
                "k": 48,
                "dead_features_repaired": 0,
                "decoder_norm_max_deviation": 1.1920928955078125e-07
              },
              "cebench_summary": {
                "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench",
                "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.02_seed456/custom_sae/results.json",
                "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 8.747363641262055,
                "independent_score_mean_max": 9.70739779472351,
                "interpretability_score_mean_max": 8.51431446313858,
                "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed456",
                "sae_id": "custom_sae",
                "date": "2026-02-18 01:38:25",
                "scores_dump_line_count": 200
              },
              "custom_metrics": {
                "contrastive_score_mean_max": 8.747363641262055,
                "independent_score_mean_max": 9.70739779472351,
                "interpretability_score_mean_max": 8.51431446313858
              },
              "matched_baseline_metrics": {
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066
              },
              "delta_vs_matched_baseline": {
                "contrastive_score_mean_max": -41.76394378900528,
                "independent_score_mean_max": -41.29186855316162,
                "interpretability_score_mean_max": -39.43729712247848
              },
              "matched_baseline_payload": {
                "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
                "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
                "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
                "total_rows": 200,
                "contrastive_score_mean_max": 50.51130743026734,
                "independent_score_mean_max": 50.99926634788513,
                "interpretability_score_mean_max": 47.951611585617066,
                "sae_release": "pythia-70m-deduped-res-sm",
                "sae_id": "blocks.0.hook_resid_pre",
                "date": "2026-02-13 18:59:31",
                "scores_dump_line_count": 200
              },
              "artifacts": {
                "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench/cebench_metrics_summary.json",
                "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench/cebench_metrics_summary.md"
              }
            },
            "saebench_returncode": 0,
            "cebench_returncode": 0,
            "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/saebench/husai_custom_sae_summary.json",
            "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed456/cebench/husai_custom_cebench_summary.json",
            "external_skip_reason": null
          },
          "saebench_delta": -0.0601713690166773,
          "cebench_delta": -39.43729712247848,
          "cebench_interpretability_max": 8.51431446313858,
          "selection": {
            "policy": "external_score",
            "checkpoint_score": 0.113040305796754,
            "passes_external_floor": false,
            "weights": {
              "saebench": 0.82,
              "cebench": 0.1,
              "alignment": 0.04,
              "explained_variance": 0.04
            },
            "normalized": {
              "saebench": 0.0,
              "cebench": 0.6117689320533495,
              "alignment": 0.45864396139056735,
              "explained_variance": 0.8379413533949089
            }
          }
        }
      ],
      "external_eval": {
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
        "candidate_tag": "seed1011",
        "saebench": {
          "timestamp_utc": "2026-02-18T01:41:51+00:00",
          "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
          "config": {
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
            "architecture_override": "topk",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "reg_type": "l1",
            "setting": "normal",
            "ks": [
              1,
              2,
              5
            ],
            "dataset_names": [
              "100_news_fake",
              "105_click_bait",
              "106_hate_hate",
              "107_hate_offensive",
              "110_aimade_humangpt3",
              "113_movie_sent",
              "114_nyc_borough_Manhattan",
              "115_nyc_borough_Brooklyn",
              "116_nyc_borough_Bronx",
              "117_us_state_FL",
              "118_us_state_CA",
              "119_us_state_TX",
              "120_us_timezone_Chicago",
              "121_us_timezone_New_York",
              "122_us_timezone_Los_Angeles",
              "123_world_country_United_Kingdom"
            ],
            "dataset_names_inferred_from_cache": false,
            "dataset_count": 16,
            "binarize": false,
            "device": "cuda",
            "dtype": "float32",
            "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
            "model_cache_path": "/tmp/sae_bench_model_cache",
            "force_rerun": true
          },
          "config_hash": "89c226380f3511f3ceb020051f106393eaa3819be62cbb679b6715cdbdbab1ee",
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "summary": {
            "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011_custom_sae",
            "llm_metrics": {
              "llm_test_accuracy": 0.6605360072070458,
              "llm_test_auc": 0.6928164663947145,
              "llm_test_f1": 0.6491238078533221
            },
            "sae_metrics_by_k": [
              {
                "k": 1,
                "test_accuracy": 0.6066127580020733,
                "test_auc": 0.6107881724887381,
                "test_f1": 0.5726167192791645
              },
              {
                "k": 2,
                "test_accuracy": 0.6139508276333686,
                "test_auc": 0.6213140735358289,
                "test_f1": 0.5897523618627115
              },
              {
                "k": 5,
                "test_accuracy": 0.6292440448068571,
                "test_auc": 0.6438836519134908,
                "test_f1": 0.6100145438585959
              }
            ],
            "best_by_auc": {
              "k": 5,
              "test_accuracy": 0.6292440448068571,
              "test_auc": 0.6438836519134908,
              "test_f1": 0.6100145438585959
            },
            "best_minus_llm_auc": -0.04893281448122366
          }
        },
        "cebench": {
          "timestamp_utc": "2026-02-18T01:44:10+00:00",
          "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
          "config_hash": "a6e8948d969ac588ef09602b2067c0e13d8a99bdc75e0018b171c9fa682e51e3",
          "config": {
            "cebench_repo": "/workspace/CE-Bench",
            "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.02/sae_seed1011.pt",
            "architecture_override": "topk",
            "checkpoint_sha256": "8e2b1c288a298f73fcc5e0e4b8590b414c9734406ec74bcc014c88587d21a9d4",
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011",
            "model_name": "pythia-70m-deduped",
            "hook_layer": 0,
            "hook_name": "blocks.0.hook_resid_pre",
            "device": "cuda",
            "sae_dtype": "float32",
            "llm_batch_size": 512,
            "llm_dtype": "float32",
            "random_seed": 42,
            "dataset_name": "GulkoA/contrastive-stories-v4",
            "dataset_rows_total": 5000,
            "dataset_rows_used": 200,
            "max_rows": 200,
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench",
            "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
            "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
          },
          "sae_meta": {
            "architecture": "topk",
            "eval_architecture": "topk",
            "d_model": 512,
            "d_sae": 2048,
            "k": 48,
            "dead_features_repaired": 0,
            "decoder_norm_max_deviation": 1.1920928955078125e-07
          },
          "cebench_summary": {
            "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench",
            "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011/custom_sae/results.json",
            "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 9.041743602752685,
            "independent_score_mean_max": 9.729872329235077,
            "interpretability_score_mean_max": 8.498405346870422,
            "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.02_seed1011",
            "sae_id": "custom_sae",
            "date": "2026-02-18 01:44:10",
            "scores_dump_line_count": 200
          },
          "custom_metrics": {
            "contrastive_score_mean_max": 9.041743602752685,
            "independent_score_mean_max": 9.729872329235077,
            "interpretability_score_mean_max": 8.498405346870422
          },
          "matched_baseline_metrics": {
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066
          },
          "delta_vs_matched_baseline": {
            "contrastive_score_mean_max": -41.46956382751465,
            "independent_score_mean_max": -41.269394018650054,
            "interpretability_score_mean_max": -39.453206238746645
          },
          "matched_baseline_payload": {
            "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
            "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
            "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
            "total_rows": 200,
            "contrastive_score_mean_max": 50.51130743026734,
            "independent_score_mean_max": 50.99926634788513,
            "interpretability_score_mean_max": 47.951611585617066,
            "sae_release": "pythia-70m-deduped-res-sm",
            "sae_id": "blocks.0.hook_resid_pre",
            "date": "2026-02-13 18:59:31",
            "scores_dump_line_count": 200
          },
          "artifacts": {
            "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/cebench_metrics_summary.json",
            "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/cebench_metrics_summary.md"
          }
        },
        "saebench_returncode": 0,
        "cebench_returncode": 0,
        "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/saebench/husai_custom_sae_summary.json",
        "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.02/seed1011/cebench/husai_custom_cebench_summary.json",
        "external_skip_reason": null
      },
      "selection_metrics": {
        "internal_lcb": 0.7411723704822362,
        "ev_drop": 0.4487246990203855,
        "ev_neg_drop": -0.4487246990203855,
        "saebench_delta": -0.04893281448122366,
        "cebench_delta": -39.453206238746645,
        "cebench_interpretability_max": 8.498405346870422
      },
      "selection": {
        "joint_score": 0.250468152530456,
        "is_pareto": true,
        "weights": {
          "internal_lcb": 0.2,
          "ev_neg_drop": 0.05,
          "saebench_delta": 0.6,
          "cebench_delta": 0.15
        }
      }
    }
  ],
  "selected": {
    "lambda_consistency": 0.15,
    "d_sae": 2048,
    "k": 48,
    "n_models": 5,
    "seed_ref": 42,
    "train_seeds": [
      123,
      456,
      789,
      1011
    ],
    "trained_pwmcc": {
      "mean": 0.9844789534807206,
      "std": 0.004897710891915029,
      "min": 0.980559766292572,
      "max": 0.990313708782196,
      "median": 0.9808094948530197,
      "ci95_low": 0.9816289275884629,
      "ci95_high": 0.9873358114808798,
      "n": 10
    },
    "random_pwmcc": {
      "mean": 0.15938223153352737,
      "std": 0.00020371875871998027,
      "min": 0.15904445201158524,
      "max": 0.1597208008170128,
      "median": 0.15935933962464333,
      "ci95_low": 0.15926027780398724,
      "ci95_high": 0.15950023284181952,
      "n": 10
    },
    "delta_pwmcc": 0.8250967219471932,
    "delta_pwmcc_ci_low_conservative": 0.8221286947466433,
    "ratio_pwmcc": 6.17684257528812,
    "explained_variance": {
      "mean": -2.6228448390960692,
      "std": 0.5831106460091582,
      "min": -2.912618637084961,
      "max": -1.580458402633667,
      "median": -2.8694798946380615,
      "ci95_low": -2.897904634475708,
      "ci95_high": -2.101074743270874,
      "n": 5
    },
    "mse": {
      "mean": 0.0030054086819291115,
      "std": 0.0004837241787473679,
      "min": 0.0021406884770840406,
      "max": 0.0032457925844937563,
      "median": 0.0032100051175802946,
      "ci95_low": 0.0025705245323479177,
      "ci95_high": 0.003233586996793747,
      "n": 5
    },
    "alignment_to_ref": {
      "mean": 0.9901682585477829,
      "std": 0.00010138452077891467,
      "min": 0.9900867342948914,
      "max": 0.990313708782196,
      "median": 0.9901362955570221,
      "ci95_low": 0.9901003837585449,
      "ci95_high": 0.9902637898921967,
      "n": 4
    },
    "runtime_sec": 262.7422397136688,
    "per_seed_metrics": [
      {
        "seed": 42,
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed42.pt",
        "lambda_consistency": 0.0,
        "alignment_to_ref": 1.0,
        "mse": 0.0021406884770840406,
        "explained_variance": -1.580458402633667,
        "l0": 48.0,
        "assignment_alignment_mean_train": null,
        "assignment_update_interval": 4,
        "assignment_hungarian_solves_train": 0,
        "train_steps": 864,
        "supervised_proxy_weight": 0.05,
        "supervised_proxy_loss_train": 2.792019643993289,
        "supervised_proxy_accuracy_eval": 0.24938559532165527,
        "supervised_proxy_num_classes": 80
      },
      {
        "seed": 123,
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
        "lambda_consistency": 0.15,
        "alignment_to_ref": 0.9901140332221985,
        "mse": 0.0032100051175802946,
        "explained_variance": -2.8694798946380615,
        "l0": 48.0,
        "assignment_alignment_mean_train": 0.9182703916707801,
        "assignment_update_interval": 4,
        "assignment_hungarian_solves_train": 216,
        "train_steps": 864,
        "supervised_proxy_weight": 0.05,
        "supervised_proxy_loss_train": 2.8176790898044906,
        "supervised_proxy_accuracy_eval": 0.24187389016151428,
        "supervised_proxy_num_classes": 80
      },
      {
        "seed": 456,
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
        "lambda_consistency": 0.15,
        "alignment_to_ref": 0.990313708782196,
        "mse": 0.003199780359864235,
        "explained_variance": -2.8571486473083496,
        "l0": 48.0,
        "assignment_alignment_mean_train": 0.9185301343461981,
        "assignment_update_interval": 4,
        "assignment_hungarian_solves_train": 216,
        "train_steps": 864,
        "supervised_proxy_weight": 0.05,
        "supervised_proxy_loss_train": 2.8197697732183666,
        "supervised_proxy_accuracy_eval": 0.24027714133262634,
        "supervised_proxy_num_classes": 80
      },
      {
        "seed": 789,
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
        "lambda_consistency": 0.15,
        "alignment_to_ref": 0.9901585578918457,
        "mse": 0.0032457925844937563,
        "explained_variance": -2.912618637084961,
        "l0": 48.0,
        "assignment_alignment_mean_train": 0.9183936743410649,
        "assignment_update_interval": 4,
        "assignment_hungarian_solves_train": 216,
        "train_steps": 864,
        "supervised_proxy_weight": 0.05,
        "supervised_proxy_loss_train": 2.8196849006193654,
        "supervised_proxy_accuracy_eval": 0.24020077288150787,
        "supervised_proxy_num_classes": 80
      },
      {
        "seed": 1011,
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
        "lambda_consistency": 0.15,
        "alignment_to_ref": 0.9900867342948914,
        "mse": 0.003230776870623231,
        "explained_variance": -2.8945186138153076,
        "l0": 48.0,
        "assignment_alignment_mean_train": 0.9182685923210725,
        "assignment_update_interval": 4,
        "assignment_hungarian_solves_train": 216,
        "train_steps": 864,
        "supervised_proxy_weight": 0.05,
        "supervised_proxy_loss_train": 2.8179253582601196,
        "supervised_proxy_accuracy_eval": 0.24147817492485046,
        "supervised_proxy_num_classes": 80
      }
    ],
    "trained_pairwise_pwmcc_values": [
      0.9901140332221985,
      0.990313708782196,
      0.9901585578918457,
      0.9900867640972137,
      0.9807675778865814,
      0.9806192517280579,
      0.980559766292572,
      0.980851411819458,
      0.9807397425174713,
      0.9805787205696106
    ],
    "random_pairwise_pwmcc_values": [
      0.15957186371088028,
      0.1597208008170128,
      0.1593116819858551,
      0.15904445201158524,
      0.15939123928546906,
      0.15958896279335022,
      0.15914249420166016,
      0.15933214128017426,
      0.1593596339225769,
      0.15935904532670975
    ],
    "selected_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
    "selected_checkpoint_seed": 456,
    "selected_checkpoint_policy": "external_score",
    "external_candidate_evals": [
      {
        "seed": 456,
        "candidate_tag": "seed456",
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
        "alignment_to_ref": 0.990313708782196,
        "explained_variance": -2.8571486473083496,
        "external_eval": {
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
          "candidate_tag": "seed456",
          "saebench": {
            "timestamp_utc": "2026-02-18T02:31:16+00:00",
            "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
            "config": {
              "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
              "architecture_override": "topk",
              "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
              "model_name": "pythia-70m-deduped",
              "hook_layer": 0,
              "hook_name": "blocks.0.hook_resid_pre",
              "reg_type": "l1",
              "setting": "normal",
              "ks": [
                1,
                2,
                5
              ],
              "dataset_names": [
                "100_news_fake",
                "105_click_bait",
                "106_hate_hate",
                "107_hate_offensive",
                "110_aimade_humangpt3",
                "113_movie_sent",
                "114_nyc_borough_Manhattan",
                "115_nyc_borough_Brooklyn",
                "116_nyc_borough_Bronx",
                "117_us_state_FL",
                "118_us_state_CA",
                "119_us_state_TX",
                "120_us_timezone_Chicago",
                "121_us_timezone_New_York",
                "122_us_timezone_Los_Angeles",
                "123_world_country_United_Kingdom"
              ],
              "dataset_names_inferred_from_cache": false,
              "dataset_count": 16,
              "binarize": false,
              "device": "cuda",
              "dtype": "float32",
              "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
              "model_cache_path": "/tmp/sae_bench_model_cache",
              "force_rerun": true
            },
            "config_hash": "17c436637b1860d904dbc6b2b6d3f25aa35483dfb3b21d0a52b79c0505280aa0",
            "sae_meta": {
              "architecture": "topk",
              "eval_architecture": "topk",
              "d_model": 512,
              "d_sae": 2048,
              "k": 48,
              "dead_features_repaired": 0,
              "decoder_norm_max_deviation": 1.1920928955078125e-07
            },
            "summary": {
              "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456_custom_sae",
              "llm_metrics": {
                "llm_test_accuracy": 0.6605360072070458,
                "llm_test_auc": 0.6928164663947145,
                "llm_test_f1": 0.6491238078533221
              },
              "sae_metrics_by_k": [
                {
                  "k": 1,
                  "test_accuracy": 0.6186525453979683,
                  "test_auc": 0.6204262495438384,
                  "test_f1": 0.5847039137990445
                },
                {
                  "k": 2,
                  "test_accuracy": 0.6295869566056455,
                  "test_auc": 0.6416029824837811,
                  "test_f1": 0.6044037297966242
                },
                {
                  "k": 5,
                  "test_accuracy": 0.6324830112901659,
                  "test_auc": 0.658527272010255,
                  "test_f1": 0.6128457716724294
                }
              ],
              "best_by_auc": {
                "k": 5,
                "test_accuracy": 0.6324830112901659,
                "test_auc": 0.658527272010255,
                "test_f1": 0.6128457716724294
              },
              "best_minus_llm_auc": -0.03428919438445954
            }
          },
          "cebench": {
            "timestamp_utc": "2026-02-18T02:33:38+00:00",
            "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
            "config_hash": "61fcfe4fe2431df1aa143ba25496680d6d56cad4d7eb9e2c764d28be1b01aa7c",
            "config": {
              "cebench_repo": "/workspace/CE-Bench",
              "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
              "architecture_override": "topk",
              "checkpoint_sha256": "3edcab31a013478eb28648c3d9c133354a523ee63c70f1e14090e84af1a33fd4",
              "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
              "model_name": "pythia-70m-deduped",
              "hook_layer": 0,
              "hook_name": "blocks.0.hook_resid_pre",
              "device": "cuda",
              "sae_dtype": "float32",
              "llm_batch_size": 512,
              "llm_dtype": "float32",
              "random_seed": 42,
              "dataset_name": "GulkoA/contrastive-stories-v4",
              "dataset_rows_total": 5000,
              "dataset_rows_used": 200,
              "max_rows": 200,
              "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench",
              "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
              "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
            },
            "sae_meta": {
              "architecture": "topk",
              "eval_architecture": "topk",
              "d_model": 512,
              "d_sae": 2048,
              "k": 48,
              "dead_features_repaired": 0,
              "decoder_norm_max_deviation": 1.1920928955078125e-07
            },
            "cebench_summary": {
              "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench",
              "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed456/custom_sae/results.json",
              "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/scores_dump.txt",
              "total_rows": 200,
              "contrastive_score_mean_max": 8.914502325057983,
              "independent_score_mean_max": 9.339038774967193,
              "interpretability_score_mean_max": 8.385907528400422,
              "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
              "sae_id": "custom_sae",
              "date": "2026-02-18 02:33:38",
              "scores_dump_line_count": 200
            },
            "custom_metrics": {
              "contrastive_score_mean_max": 8.914502325057983,
              "independent_score_mean_max": 9.339038774967193,
              "interpretability_score_mean_max": 8.385907528400422
            },
            "matched_baseline_metrics": {
              "contrastive_score_mean_max": 50.51130743026734,
              "independent_score_mean_max": 50.99926634788513,
              "interpretability_score_mean_max": 47.951611585617066
            },
            "delta_vs_matched_baseline": {
              "contrastive_score_mean_max": -41.596805105209356,
              "independent_score_mean_max": -41.66022757291794,
              "interpretability_score_mean_max": -39.56570405721664
            },
            "matched_baseline_payload": {
              "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
              "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
              "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
              "total_rows": 200,
              "contrastive_score_mean_max": 50.51130743026734,
              "independent_score_mean_max": 50.99926634788513,
              "interpretability_score_mean_max": 47.951611585617066,
              "sae_release": "pythia-70m-deduped-res-sm",
              "sae_id": "blocks.0.hook_resid_pre",
              "date": "2026-02-13 18:59:31",
              "scores_dump_line_count": 200
            },
            "artifacts": {
              "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.json",
              "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.md"
            }
          },
          "saebench_returncode": 0,
          "cebench_returncode": 0,
          "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/saebench/husai_custom_sae_summary.json",
          "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/husai_custom_cebench_summary.json",
          "external_skip_reason": null
        },
        "saebench_delta": -0.03428919438445954,
        "cebench_delta": -39.56570405721664,
        "cebench_interpretability_max": 8.385907528400422,
        "selection": {
          "policy": "external_score",
          "checkpoint_score": 0.9,
          "passes_external_floor": false,
          "weights": {
            "saebench": 0.82,
            "cebench": 0.1,
            "alignment": 0.04,
            "explained_variance": 0.04
          },
          "normalized": {
            "saebench": 1.0,
            "cebench": 0.0,
            "alignment": 1.0,
            "explained_variance": 1.0
          }
        }
      },
      {
        "seed": 123,
        "candidate_tag": "seed123",
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
        "alignment_to_ref": 0.9901140332221985,
        "explained_variance": -2.8694798946380615,
        "external_eval": {
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
          "candidate_tag": "seed123",
          "saebench": {
            "timestamp_utc": "2026-02-18T02:37:03+00:00",
            "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
            "config": {
              "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
              "architecture_override": "topk",
              "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed123",
              "model_name": "pythia-70m-deduped",
              "hook_layer": 0,
              "hook_name": "blocks.0.hook_resid_pre",
              "reg_type": "l1",
              "setting": "normal",
              "ks": [
                1,
                2,
                5
              ],
              "dataset_names": [
                "100_news_fake",
                "105_click_bait",
                "106_hate_hate",
                "107_hate_offensive",
                "110_aimade_humangpt3",
                "113_movie_sent",
                "114_nyc_borough_Manhattan",
                "115_nyc_borough_Brooklyn",
                "116_nyc_borough_Bronx",
                "117_us_state_FL",
                "118_us_state_CA",
                "119_us_state_TX",
                "120_us_timezone_Chicago",
                "121_us_timezone_New_York",
                "122_us_timezone_Los_Angeles",
                "123_world_country_United_Kingdom"
              ],
              "dataset_names_inferred_from_cache": false,
              "dataset_count": 16,
              "binarize": false,
              "device": "cuda",
              "dtype": "float32",
              "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
              "model_cache_path": "/tmp/sae_bench_model_cache",
              "force_rerun": true
            },
            "config_hash": "9593422f3b11ce6476105b0e781c166ffa9f57d3ec6005ec3f55cae9b3cd7c72",
            "sae_meta": {
              "architecture": "topk",
              "eval_architecture": "topk",
              "d_model": 512,
              "d_sae": 2048,
              "k": 48,
              "dead_features_repaired": 0,
              "decoder_norm_max_deviation": 1.1920928955078125e-07
            },
            "summary": {
              "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed123_custom_sae",
              "llm_metrics": {
                "llm_test_accuracy": 0.6605360072070458,
                "llm_test_auc": 0.6928164663947145,
                "llm_test_f1": 0.6491238078533221
              },
              "sae_metrics_by_k": [
                {
                  "k": 1,
                  "test_accuracy": 0.6159512520981157,
                  "test_auc": 0.6197763498570634,
                  "test_f1": 0.5879030266578763
                },
                {
                  "k": 2,
                  "test_accuracy": 0.6285442338323799,
                  "test_auc": 0.6440351004826336,
                  "test_f1": 0.6069153331852646
                },
                {
                  "k": 5,
                  "test_accuracy": 0.6321928943101278,
                  "test_auc": 0.6566222045522296,
                  "test_f1": 0.6134238265321097
                }
              ],
              "best_by_auc": {
                "k": 5,
                "test_accuracy": 0.6321928943101278,
                "test_auc": 0.6566222045522296,
                "test_f1": 0.6134238265321097
              },
              "best_minus_llm_auc": -0.036194261842484865
            }
          },
          "cebench": {
            "timestamp_utc": "2026-02-18T02:39:23+00:00",
            "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed123 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
            "config_hash": "f7aad5934967d6486f7e562b246d91d678ef05c5eb540a875746a35afce9a270",
            "config": {
              "cebench_repo": "/workspace/CE-Bench",
              "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed123.pt",
              "architecture_override": "topk",
              "checkpoint_sha256": "af0d8710e76b69d331f36e1620b48726373ba1c5695bbf86f73aaad433de52e2",
              "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed123",
              "model_name": "pythia-70m-deduped",
              "hook_layer": 0,
              "hook_name": "blocks.0.hook_resid_pre",
              "device": "cuda",
              "sae_dtype": "float32",
              "llm_batch_size": 512,
              "llm_dtype": "float32",
              "random_seed": 42,
              "dataset_name": "GulkoA/contrastive-stories-v4",
              "dataset_rows_total": 5000,
              "dataset_rows_used": 200,
              "max_rows": 200,
              "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench",
              "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
              "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
            },
            "sae_meta": {
              "architecture": "topk",
              "eval_architecture": "topk",
              "d_model": 512,
              "d_sae": 2048,
              "k": 48,
              "dead_features_repaired": 0,
              "decoder_norm_max_deviation": 1.1920928955078125e-07
            },
            "cebench_summary": {
              "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench",
              "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed123/custom_sae/results.json",
              "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/scores_dump.txt",
              "total_rows": 200,
              "contrastive_score_mean_max": 9.389745931625367,
              "independent_score_mean_max": 9.589236640930176,
              "interpretability_score_mean_max": 8.73444492340088,
              "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed123",
              "sae_id": "custom_sae",
              "date": "2026-02-18 02:39:23",
              "scores_dump_line_count": 200
            },
            "custom_metrics": {
              "contrastive_score_mean_max": 9.389745931625367,
              "independent_score_mean_max": 9.589236640930176,
              "interpretability_score_mean_max": 8.73444492340088
            },
            "matched_baseline_metrics": {
              "contrastive_score_mean_max": 50.51130743026734,
              "independent_score_mean_max": 50.99926634788513,
              "interpretability_score_mean_max": 47.951611585617066
            },
            "delta_vs_matched_baseline": {
              "contrastive_score_mean_max": -41.12156149864197,
              "independent_score_mean_max": -41.41002970695496,
              "interpretability_score_mean_max": -39.21716666221619
            },
            "matched_baseline_payload": {
              "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
              "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
              "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
              "total_rows": 200,
              "contrastive_score_mean_max": 50.51130743026734,
              "independent_score_mean_max": 50.99926634788513,
              "interpretability_score_mean_max": 47.951611585617066,
              "sae_release": "pythia-70m-deduped-res-sm",
              "sae_id": "blocks.0.hook_resid_pre",
              "date": "2026-02-13 18:59:31",
              "scores_dump_line_count": 200
            },
            "artifacts": {
              "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/cebench_metrics_summary.json",
              "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/cebench_metrics_summary.md"
            }
          },
          "saebench_returncode": 0,
          "cebench_returncode": 0,
          "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/saebench/husai_custom_sae_summary.json",
          "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed123/cebench/husai_custom_cebench_summary.json",
          "external_skip_reason": null
        },
        "saebench_delta": -0.036194261842484865,
        "cebench_delta": -39.21716666221619,
        "cebench_interpretability_max": 8.73444492340088,
        "selection": {
          "policy": "external_score",
          "checkpoint_score": 0.8630099471428296,
          "passes_external_floor": false,
          "weights": {
            "saebench": 0.82,
            "cebench": 0.1,
            "alignment": 0.04,
            "explained_variance": 0.04
          },
          "normalized": {
            "saebench": 0.8866966054452565,
            "cebench": 1.0,
            "alignment": 0.12027310924369748,
            "explained_variance": 0.7776951576992839
          }
        }
      },
      {
        "seed": 789,
        "candidate_tag": "seed789",
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
        "alignment_to_ref": 0.9901585578918457,
        "explained_variance": -2.912618637084961,
        "external_eval": {
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
          "candidate_tag": "seed789",
          "saebench": {
            "timestamp_utc": "2026-02-18T02:34:11+00:00",
            "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
            "config": {
              "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
              "architecture_override": "topk",
              "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed789",
              "model_name": "pythia-70m-deduped",
              "hook_layer": 0,
              "hook_name": "blocks.0.hook_resid_pre",
              "reg_type": "l1",
              "setting": "normal",
              "ks": [
                1,
                2,
                5
              ],
              "dataset_names": [
                "100_news_fake",
                "105_click_bait",
                "106_hate_hate",
                "107_hate_offensive",
                "110_aimade_humangpt3",
                "113_movie_sent",
                "114_nyc_borough_Manhattan",
                "115_nyc_borough_Brooklyn",
                "116_nyc_borough_Bronx",
                "117_us_state_FL",
                "118_us_state_CA",
                "119_us_state_TX",
                "120_us_timezone_Chicago",
                "121_us_timezone_New_York",
                "122_us_timezone_Los_Angeles",
                "123_world_country_United_Kingdom"
              ],
              "dataset_names_inferred_from_cache": false,
              "dataset_count": 16,
              "binarize": false,
              "device": "cuda",
              "dtype": "float32",
              "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
              "model_cache_path": "/tmp/sae_bench_model_cache",
              "force_rerun": true
            },
            "config_hash": "8ec02395cff28376cef045dda824466d32fa903f628f9297f82e0a6a744ca15b",
            "sae_meta": {
              "architecture": "topk",
              "eval_architecture": "topk",
              "d_model": 512,
              "d_sae": 2048,
              "k": 48,
              "dead_features_repaired": 0,
              "decoder_norm_max_deviation": 1.1920928955078125e-07
            },
            "summary": {
              "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed789_custom_sae",
              "llm_metrics": {
                "llm_test_accuracy": 0.6605360072070458,
                "llm_test_auc": 0.6928164663947145,
                "llm_test_f1": 0.6491238078533221
              },
              "sae_metrics_by_k": [
                {
                  "k": 1,
                  "test_accuracy": 0.6072364014961638,
                  "test_auc": 0.6158422479252132,
                  "test_f1": 0.5774071030758309
                },
                {
                  "k": 2,
                  "test_accuracy": 0.6226430373844046,
                  "test_auc": 0.6369499031597436,
                  "test_f1": 0.5982762282392745
                },
                {
                  "k": 5,
                  "test_accuracy": 0.6274351321488251,
                  "test_auc": 0.6471052761712061,
                  "test_f1": 0.6049916010612982
                }
              ],
              "best_by_auc": {
                "k": 5,
                "test_accuracy": 0.6274351321488251,
                "test_auc": 0.6471052761712061,
                "test_f1": 0.6049916010612982
              },
              "best_minus_llm_auc": -0.04571119022350845
            }
          },
          "cebench": {
            "timestamp_utc": "2026-02-18T02:36:30+00:00",
            "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed789 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
            "config_hash": "1e2c1b29065c9e35b2ffe2edbf7752d56f4880897639c4e7a856591c72267de5",
            "config": {
              "cebench_repo": "/workspace/CE-Bench",
              "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed789.pt",
              "architecture_override": "topk",
              "checkpoint_sha256": "afb257f8f8a193a673676d263954deed93dfe991e40df51924f19e7df486f4b2",
              "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed789",
              "model_name": "pythia-70m-deduped",
              "hook_layer": 0,
              "hook_name": "blocks.0.hook_resid_pre",
              "device": "cuda",
              "sae_dtype": "float32",
              "llm_batch_size": 512,
              "llm_dtype": "float32",
              "random_seed": 42,
              "dataset_name": "GulkoA/contrastive-stories-v4",
              "dataset_rows_total": 5000,
              "dataset_rows_used": 200,
              "max_rows": 200,
              "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench",
              "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
              "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
            },
            "sae_meta": {
              "architecture": "topk",
              "eval_architecture": "topk",
              "d_model": 512,
              "d_sae": 2048,
              "k": 48,
              "dead_features_repaired": 0,
              "decoder_norm_max_deviation": 1.1920928955078125e-07
            },
            "cebench_summary": {
              "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench",
              "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed789/custom_sae/results.json",
              "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/scores_dump.txt",
              "total_rows": 200,
              "contrastive_score_mean_max": 9.27641587972641,
              "independent_score_mean_max": 9.445425384044647,
              "interpretability_score_mean_max": 8.64591790676117,
              "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed789",
              "sae_id": "custom_sae",
              "date": "2026-02-18 02:36:30",
              "scores_dump_line_count": 200
            },
            "custom_metrics": {
              "contrastive_score_mean_max": 9.27641587972641,
              "independent_score_mean_max": 9.445425384044647,
              "interpretability_score_mean_max": 8.64591790676117
            },
            "matched_baseline_metrics": {
              "contrastive_score_mean_max": 50.51130743026734,
              "independent_score_mean_max": 50.99926634788513,
              "interpretability_score_mean_max": 47.951611585617066
            },
            "delta_vs_matched_baseline": {
              "contrastive_score_mean_max": -41.23489155054093,
              "independent_score_mean_max": -41.553840963840486,
              "interpretability_score_mean_max": -39.305693678855896
            },
            "matched_baseline_payload": {
              "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
              "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
              "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
              "total_rows": 200,
              "contrastive_score_mean_max": 50.51130743026734,
              "independent_score_mean_max": 50.99926634788513,
              "interpretability_score_mean_max": 47.951611585617066,
              "sae_release": "pythia-70m-deduped-res-sm",
              "sae_id": "blocks.0.hook_resid_pre",
              "date": "2026-02-13 18:59:31",
              "scores_dump_line_count": 200
            },
            "artifacts": {
              "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/cebench_metrics_summary.json",
              "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/cebench_metrics_summary.md"
            }
          },
          "saebench_returncode": 0,
          "cebench_returncode": 0,
          "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/saebench/husai_custom_sae_summary.json",
          "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed789/cebench/husai_custom_cebench_summary.json",
          "external_skip_reason": null
        },
        "saebench_delta": -0.04571119022350845,
        "cebench_delta": -39.305693678855896,
        "cebench_interpretability_max": 8.64591790676117,
        "selection": {
          "policy": "external_score",
          "checkpoint_score": 0.3502153834423737,
          "passes_external_floor": false,
          "weights": {
            "saebench": 0.82,
            "cebench": 0.1,
            "alignment": 0.04,
            "explained_variance": 0.04
          },
          "normalized": {
            "saebench": 0.32067975036651186,
            "cebench": 0.7460042511662388,
            "alignment": 0.3164390756302521,
            "explained_variance": 0.0
          }
        }
      },
      {
        "seed": 1011,
        "candidate_tag": "seed1011",
        "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
        "alignment_to_ref": 0.9900867342948914,
        "explained_variance": -2.8945186138153076,
        "external_eval": {
          "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
          "candidate_tag": "seed1011",
          "saebench": {
            "timestamp_utc": "2026-02-18T02:39:55+00:00",
            "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
            "config": {
              "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
              "architecture_override": "topk",
              "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011",
              "model_name": "pythia-70m-deduped",
              "hook_layer": 0,
              "hook_name": "blocks.0.hook_resid_pre",
              "reg_type": "l1",
              "setting": "normal",
              "ks": [
                1,
                2,
                5
              ],
              "dataset_names": [
                "100_news_fake",
                "105_click_bait",
                "106_hate_hate",
                "107_hate_offensive",
                "110_aimade_humangpt3",
                "113_movie_sent",
                "114_nyc_borough_Manhattan",
                "115_nyc_borough_Brooklyn",
                "116_nyc_borough_Bronx",
                "117_us_state_FL",
                "118_us_state_CA",
                "119_us_state_TX",
                "120_us_timezone_Chicago",
                "121_us_timezone_New_York",
                "122_us_timezone_Los_Angeles",
                "123_world_country_United_Kingdom"
              ],
              "dataset_names_inferred_from_cache": false,
              "dataset_count": 16,
              "binarize": false,
              "device": "cuda",
              "dtype": "float32",
              "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
              "model_cache_path": "/tmp/sae_bench_model_cache",
              "force_rerun": true
            },
            "config_hash": "6957db2471ce8b0102650b1be48c85470c8baa8604cd2ee5b084d17af325dd19",
            "sae_meta": {
              "architecture": "topk",
              "eval_architecture": "topk",
              "d_model": 512,
              "d_sae": 2048,
              "k": 48,
              "dead_features_repaired": 0,
              "decoder_norm_max_deviation": 1.1920928955078125e-07
            },
            "summary": {
              "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011_custom_sae",
              "llm_metrics": {
                "llm_test_accuracy": 0.6605360072070458,
                "llm_test_auc": 0.6928164663947145,
                "llm_test_f1": 0.6491238078533221
              },
              "sae_metrics_by_k": [
                {
                  "k": 1,
                  "test_accuracy": 0.6127747220388311,
                  "test_auc": 0.6206160923563389,
                  "test_f1": 0.5793105215779103
                },
                {
                  "k": 2,
                  "test_accuracy": 0.6217375314944588,
                  "test_auc": 0.6330082404807384,
                  "test_f1": 0.5911823535485532
                },
                {
                  "k": 5,
                  "test_accuracy": 0.6193885733798464,
                  "test_auc": 0.6417134116178828,
                  "test_f1": 0.5994312217515192
                }
              ],
              "best_by_auc": {
                "k": 5,
                "test_accuracy": 0.6193885733798464,
                "test_auc": 0.6417134116178828,
                "test_f1": 0.5994312217515192
              },
              "best_minus_llm_auc": -0.05110305477683175
            }
          },
          "cebench": {
            "timestamp_utc": "2026-02-18T02:42:14+00:00",
            "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
            "config_hash": "cc5f03d2728fe198b507ab1bd8f3eee120a5c8b0a622469fbc49750d8e16889d",
            "config": {
              "cebench_repo": "/workspace/CE-Bench",
              "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed1011.pt",
              "architecture_override": "topk",
              "checkpoint_sha256": "7ba66b8aadf67b0843a1ae57d0e708c44ff6ff2280818d7f748c4c80064856e0",
              "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011",
              "model_name": "pythia-70m-deduped",
              "hook_layer": 0,
              "hook_name": "blocks.0.hook_resid_pre",
              "device": "cuda",
              "sae_dtype": "float32",
              "llm_batch_size": 512,
              "llm_dtype": "float32",
              "random_seed": 42,
              "dataset_name": "GulkoA/contrastive-stories-v4",
              "dataset_rows_total": 5000,
              "dataset_rows_used": 200,
              "max_rows": 200,
              "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench",
              "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
              "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
            },
            "sae_meta": {
              "architecture": "topk",
              "eval_architecture": "topk",
              "d_model": 512,
              "d_sae": 2048,
              "k": 48,
              "dead_features_repaired": 0,
              "decoder_norm_max_deviation": 1.1920928955078125e-07
            },
            "cebench_summary": {
              "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench",
              "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011/custom_sae/results.json",
              "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/scores_dump.txt",
              "total_rows": 200,
              "contrastive_score_mean_max": 9.27909141778946,
              "independent_score_mean_max": 9.879950060844422,
              "interpretability_score_mean_max": 8.667007133960723,
              "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed1011",
              "sae_id": "custom_sae",
              "date": "2026-02-18 02:42:14",
              "scores_dump_line_count": 200
            },
            "custom_metrics": {
              "contrastive_score_mean_max": 9.27909141778946,
              "independent_score_mean_max": 9.879950060844422,
              "interpretability_score_mean_max": 8.667007133960723
            },
            "matched_baseline_metrics": {
              "contrastive_score_mean_max": 50.51130743026734,
              "independent_score_mean_max": 50.99926634788513,
              "interpretability_score_mean_max": 47.951611585617066
            },
            "delta_vs_matched_baseline": {
              "contrastive_score_mean_max": -41.23221601247788,
              "independent_score_mean_max": -41.11931628704071,
              "interpretability_score_mean_max": -39.28460445165634
            },
            "matched_baseline_payload": {
              "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
              "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
              "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
              "total_rows": 200,
              "contrastive_score_mean_max": 50.51130743026734,
              "independent_score_mean_max": 50.99926634788513,
              "interpretability_score_mean_max": 47.951611585617066,
              "sae_release": "pythia-70m-deduped-res-sm",
              "sae_id": "blocks.0.hook_resid_pre",
              "date": "2026-02-13 18:59:31",
              "scores_dump_line_count": 200
            },
            "artifacts": {
              "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.json",
              "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/cebench_metrics_summary.md"
            }
          },
          "saebench_returncode": 0,
          "cebench_returncode": 0,
          "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/saebench/husai_custom_sae_summary.json",
          "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed1011/cebench/husai_custom_cebench_summary.json",
          "external_skip_reason": null
        },
        "saebench_delta": -0.05110305477683175,
        "cebench_delta": -39.28460445165634,
        "cebench_interpretability_max": 8.667007133960723,
        "selection": {
          "policy": "external_score",
          "checkpoint_score": 0.09370332344924262,
          "passes_external_floor": false,
          "weights": {
            "saebench": 0.82,
            "cebench": 0.1,
            "alignment": 0.04,
            "explained_variance": 0.04
          },
          "normalized": {
            "saebench": 0.0,
            "cebench": 0.8065120402932153,
            "alignment": 0.0,
            "explained_variance": 0.32630298549802716
          }
        }
      }
    ],
    "external_eval": {
      "checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
      "candidate_tag": "seed456",
      "saebench": {
        "timestamp_utc": "2026-02-18T02:31:16+00:00",
        "command": "python scripts/experiments/run_husai_saebench_custom_eval.py --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --dtype float32 --results-path /tmp/husai_saebench_probe_results_cycle10_assignment --model-cache-path /tmp/sae_bench_model_cache --output-dir /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/saebench --dataset-names 100_news_fake,105_click_bait,106_hate_hate,107_hate_offensive,110_aimade_humangpt3,113_movie_sent,114_nyc_borough_Manhattan,115_nyc_borough_Brooklyn,116_nyc_borough_Bronx,117_us_state_FL,118_us_state_CA,119_us_state_TX,120_us_timezone_Chicago,121_us_timezone_New_York,122_us_timezone_Los_Angeles,123_world_country_United_Kingdom --force-rerun",
        "config": {
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
          "architecture_override": "topk",
          "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "reg_type": "l1",
          "setting": "normal",
          "ks": [
            1,
            2,
            5
          ],
          "dataset_names": [
            "100_news_fake",
            "105_click_bait",
            "106_hate_hate",
            "107_hate_offensive",
            "110_aimade_humangpt3",
            "113_movie_sent",
            "114_nyc_borough_Manhattan",
            "115_nyc_borough_Brooklyn",
            "116_nyc_borough_Bronx",
            "117_us_state_FL",
            "118_us_state_CA",
            "119_us_state_TX",
            "120_us_timezone_Chicago",
            "121_us_timezone_New_York",
            "122_us_timezone_Los_Angeles",
            "123_world_country_United_Kingdom"
          ],
          "dataset_names_inferred_from_cache": false,
          "dataset_count": 16,
          "binarize": false,
          "device": "cuda",
          "dtype": "float32",
          "results_path": "/tmp/husai_saebench_probe_results_cycle10_assignment",
          "model_cache_path": "/tmp/sae_bench_model_cache",
          "force_rerun": true
        },
        "config_hash": "17c436637b1860d904dbc6b2b6d3f25aa35483dfb3b21d0a52b79c0505280aa0",
        "sae_meta": {
          "architecture": "topk",
          "eval_architecture": "topk",
          "d_model": 512,
          "d_sae": 2048,
          "k": 48,
          "dead_features_repaired": 0,
          "decoder_norm_max_deviation": 1.1920928955078125e-07
        },
        "summary": {
          "result_key": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456_custom_sae",
          "llm_metrics": {
            "llm_test_accuracy": 0.6605360072070458,
            "llm_test_auc": 0.6928164663947145,
            "llm_test_f1": 0.6491238078533221
          },
          "sae_metrics_by_k": [
            {
              "k": 1,
              "test_accuracy": 0.6186525453979683,
              "test_auc": 0.6204262495438384,
              "test_f1": 0.5847039137990445
            },
            {
              "k": 2,
              "test_accuracy": 0.6295869566056455,
              "test_auc": 0.6416029824837811,
              "test_f1": 0.6044037297966242
            },
            {
              "k": 5,
              "test_accuracy": 0.6324830112901659,
              "test_auc": 0.658527272010255,
              "test_f1": 0.6128457716724294
            }
          ],
          "best_by_auc": {
            "k": 5,
            "test_accuracy": 0.6324830112901659,
            "test_auc": 0.658527272010255,
            "test_f1": 0.6128457716724294
          },
          "best_minus_llm_auc": -0.03428919438445954
        }
      },
      "cebench": {
        "timestamp_utc": "2026-02-18T02:33:38+00:00",
        "command": "python scripts/experiments/run_husai_cebench_custom_eval.py --cebench-repo /workspace/CE-Bench --checkpoint /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt --architecture topk --sae-release husai_assignv3_run_20260218T004251Z_lambda0.15_seed456 --model-name pythia-70m-deduped --hook-layer 0 --hook-name blocks.0.hook_resid_pre --device cuda --sae-dtype float32 --output-folder /workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench --artifacts-path /tmp/ce_bench_artifacts_cycle10_assignment --max-rows 200 --matched-baseline-summary /workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json",
        "config_hash": "61fcfe4fe2431df1aa143ba25496680d6d56cad4d7eb9e2c764d28be1b01aa7c",
        "config": {
          "cebench_repo": "/workspace/CE-Bench",
          "checkpoint": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
          "architecture_override": "topk",
          "checkpoint_sha256": "3edcab31a013478eb28648c3d9c133354a523ee63c70f1e14090e84af1a33fd4",
          "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
          "model_name": "pythia-70m-deduped",
          "hook_layer": 0,
          "hook_name": "blocks.0.hook_resid_pre",
          "device": "cuda",
          "sae_dtype": "float32",
          "llm_batch_size": 512,
          "llm_dtype": "float32",
          "random_seed": 42,
          "dataset_name": "GulkoA/contrastive-stories-v4",
          "dataset_rows_total": 5000,
          "dataset_rows_used": 200,
          "max_rows": 200,
          "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench",
          "artifacts_path": "/tmp/ce_bench_artifacts_cycle10_assignment",
          "matched_baseline_summary": "/workspace/HUSAI/docs/evidence/phase4e_cebench_matched200/cebench_matched200_summary.json"
        },
        "sae_meta": {
          "architecture": "topk",
          "eval_architecture": "topk",
          "d_model": 512,
          "d_sae": 2048,
          "k": 48,
          "dead_features_repaired": 0,
          "decoder_norm_max_deviation": 1.1920928955078125e-07
        },
        "cebench_summary": {
          "output_folder": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench",
          "results_json": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/interpretability_eval/husai_assignv3_run_20260218T004251Z_lambda0.15_seed456/custom_sae/results.json",
          "scores_dump": "/workspace/HUSAI/results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/scores_dump.txt",
          "total_rows": 200,
          "contrastive_score_mean_max": 8.914502325057983,
          "independent_score_mean_max": 9.339038774967193,
          "interpretability_score_mean_max": 8.385907528400422,
          "sae_release": "husai_assignv3_run_20260218T004251Z_lambda0.15_seed456",
          "sae_id": "custom_sae",
          "date": "2026-02-18 02:33:38",
          "scores_dump_line_count": 200
        },
        "custom_metrics": {
          "contrastive_score_mean_max": 8.914502325057983,
          "independent_score_mean_max": 9.339038774967193,
          "interpretability_score_mean_max": 8.385907528400422
        },
        "matched_baseline_metrics": {
          "contrastive_score_mean_max": 50.51130743026734,
          "independent_score_mean_max": 50.99926634788513,
          "interpretability_score_mean_max": 47.951611585617066
        },
        "delta_vs_matched_baseline": {
          "contrastive_score_mean_max": -41.596805105209356,
          "independent_score_mean_max": -41.66022757291794,
          "interpretability_score_mean_max": -39.56570405721664
        },
        "matched_baseline_payload": {
          "output_folder": "results/experiments/phase4e_external_benchmark_official/cebench_matched200",
          "results_json": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/interpretability_eval/pythia-70m-deduped-res-sm/blocks.0.hook_resid_pre/results.json",
          "scores_dump": "results/experiments/phase4e_external_benchmark_official/cebench_matched200/scores_dump.txt",
          "total_rows": 200,
          "contrastive_score_mean_max": 50.51130743026734,
          "independent_score_mean_max": 50.99926634788513,
          "interpretability_score_mean_max": 47.951611585617066,
          "sae_release": "pythia-70m-deduped-res-sm",
          "sae_id": "blocks.0.hook_resid_pre",
          "date": "2026-02-13 18:59:31",
          "scores_dump_line_count": 200
        },
        "artifacts": {
          "cebench_metrics_summary_json": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.json",
          "cebench_metrics_summary_md": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/cebench_metrics_summary.md"
        }
      },
      "saebench_returncode": 0,
      "cebench_returncode": 0,
      "saebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/saebench/husai_custom_sae_summary.json",
      "cebench_summary_path": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/external_eval/0.15/seed456/cebench/husai_custom_cebench_summary.json",
      "external_skip_reason": null
    },
    "selection_metrics": {
      "internal_lcb": 0.8221286947466433,
      "ev_drop": 1.053744840621948,
      "ev_neg_drop": -1.053744840621948,
      "saebench_delta": -0.03428919438445954,
      "cebench_delta": -39.56570405721664,
      "cebench_interpretability_max": 8.385907528400422
    },
    "selection": {
      "joint_score": 0.8,
      "is_pareto": true,
      "weights": {
        "internal_lcb": 0.2,
        "ev_neg_drop": 0.05,
        "saebench_delta": 0.6,
        "cebench_delta": 0.15
      }
    }
  },
  "acceptance": {
    "best_lambda": 0.15,
    "best_checkpoint": "results/experiments/phase4d_assignment_consistency_v3_cycle10_recovery/run_20260218T004251Z/checkpoints/lambda_0.15/sae_seed456.pt",
    "gate_internal_lcb": true,
    "gate_ev_drop": false,
    "gate_saebench": false,
    "gate_cebench": false,
    "min_internal_lcb": 0.0,
    "max_ev_drop": 0.05,
    "min_saebench_delta": -0.005,
    "min_cebench_delta": -35.0,
    "require_external": true,
    "pass_all": false
  }
}
